# AEM Live – Technical Notes
**Source:** [https://www.aem.live/](https://www.aem.live/)
DevelopersMany developers are stuck getting their sites to acceptable performance standards, and great performance seems out of reach. Adobe Experience Manager takes a performance-first approach to delivery, making lighthouse score 100 a reality.
Content OperationsBuilt with the needs of real-world mission-critical sites, AEM cracks the nuts of managing metadata at scale, delivering internationalized and localized content, optimizing for search engines, social sharing, testing, and experimentation.
## Develop Faster
## Everything modern web development needs, and not a single bit more
OperationsAEM is one less thing to be on call for. Incredible availability due to fully redundant architecture, endless scalability as a full software as a service and easy integrations with your existing CDN make go-live anxiety a thing of the past.
DevelopersAEM uses all the things modern web developers love: GitHub, local development with auto-reload, performance, simplicity – and none of the complications: no transpilation, no bundlers, no configurations, no overhead.
Quality EngineersAutomated assurance of performance, accessibility, SEO, and best practices thanks to built-in quality checks. Continuous assurance of real-world site performance and functionality through real user monitoring.
## Unmatched Speed
## Content At Scale
From simple sites to ten thousands of pages, AEM handles content at scale, across markets, languages, and countries. And even the biggest sites publish instantly with pushed cache purges.
## Uncertainty Eliminated
There’s no place for guesswork in authoring high-performing sites. Each preview generated by AEM offers 100% fidelity, and a unique, easily shareable URL for your reviewers.
Building great sites does not require complicated frameworks, tooling, or processes. AEM uses plain HTML, modern CSS, and vanilla JavaScript to create exceptional experiences without the usual overhead.
## Composability is Here
Headless or headful, your content can go farther with AEM’s composable architecture. Deliver the right content in the right format, and add the right decorations to make it an experience that stands out in any channel.
## Content First
## Peak Performance
Every great experience starts and ends with performance. Adobe continuously monitors the performance of your AEM site and lets you know when there are ways to improve. All you have to do is approve the pull request.
PGA TOUR Senior Vice President, Digital Operations
**Source:** [https://www.aem.live/home](https://www.aem.live/home)
**Source:** [https://www.aem.live/docs](https://www.aem.live/docs)
Block Collection
A collection of blocks considered a part of the product and are recommended as blueprints for blocks in your project.
Authoring content in AEM as a Cloud Service using the Universal Editor, you benefit from the power of AEM’s robust tool set for content management and the unparalleled performance of Edge Delivery Services.
Bulk Metadata
In some cases, it is useful to apply metadata en masse to a website.
Automatically generate sitemap files to be referenced from your robots.txt. This helps with SEO and the discovery of new content.
The go-live checklist is a summary of best practices to consider when launching a website.
Automatically purge content on your production CDN, whenever an author publishes content changes.
Adobe-managed CDN
Use the CDN included in your Adobe Experience Manager Sites as a Cloud Service license.
Sidekick
Install the AEM Sidekick to author and publish with Adobe Experience Manager.
Admin API
Reference documentation for the Admin API.
Architecture
Architecture Overview
Understand the basics of AEM architecture
Best practices for setting up environments
Integration Anti-Patterns
These integration patterns frequently cause issues, avoid them
How content is published from AEM Sites authoring to Edge Delivery Services
**Source:** [https://www.aem.live/docs/](https://www.aem.live/docs/)
**Source:** [https://www.aem.live/docs/sidekick](https://www.aem.live/docs/sidekick)
Using AEM Sidekick
AEM Sidekick provides content authors with a toolbar offering context-aware options so that you can edit, preview, and publish your content directly from the pages of your website.
The Sidekick is available for Chrome-based browsers (that includes Microsoft Edge). You can install it from the Chrome web store.
Microsoft Edge Installation
To install the Sidekick extension into your Microsoft Edge Browser, you need to enable the following option to "Allow extensions from other stores" under edge://extensions in your URL bar.
Once that setting is enabled the sidekick can be installed from the Chrome web store.
First use of the Sidekick
Once installed, the Sidekick appears as a toolbar hovering over the bottom portion of your content in the browser. If it is not showing, click the Sidekick icon in the browser toolbar. The Sidekick provides you with various tools and actions for navigating and publishing your content.
If your site has authentication for authors enabled, you will first need to click Sign in to authenticate before you can use the Sidekick.
Signing in is not required to use the Sidekick to switch between environments and preview or publish content. However if you wish to unpublish and delete pages, you must sign in.
Using the Sidekick
The Sidekick can be invoked in the following contexts:
A preview URL (the domain name ending in .aem.page)
A production URL (the domain name being your project’s public host name), custom preview URL, or custom live URL
The Sidekick extension can be toggled by clicking the Adobe Experience Cloud icon next to the address bar in your browser.
When editing your document and first using the Sidekick, you default to Source mode. Click the Source button to reveal the additional environments available.
The environment switcher on a Sidekick in Google Docs.
Preview (re)generates the preview page based on the current document and opens it in a separate tab.
Preview mode
The preview environment reflects the latest changes of the page rendered from the source document. Preview environments are indicated by a blue label. You can send preview URLs to stakeholders so they can review your content before it gets published. Note that this option is only enabled if the content you are looking at has been previewed before.
The preview URL follows the pattern https://branch--site--org.aem.page/path.
In Preview mode, the following actions are available:
For example if you have Source and Preview open in side-by-side tabs while working on the content.
The effect is identical to the Preview action in the editor.
Publish makes the current preview version of the page available in the live and production environments.
If you are previewing a sheet, note that there are additional options available.
Previewing Sheets
Preview mode for sheets works the same as other pages, however there are additional options available that make managing changes to sheets easier for the author. When previewing a page, the preview loads the sheet using the Adobe Experience Manager Sites Data Rendition tool, to show the resulting JSON in a user-friendly way.
The preview lazy loads the first 1000 rows. You can search the entirety of the spreadsheet using the Search field.
This creates a diff, showing what has changed in your sheet between the current published state of the sheet and the content you are previewing.
The live URL looks almost identical to the preview URL, the only difference being in the 1st level domain: https://main--site--org.aem.live/path
This environment can be a 3rd-party or “bring your own” CDN.
If you are using the Sidekick in the preview, live, or production environments, the source switcher will also offer an Open in option, which opens the online editor of the current page’s source (either a document or the AEM editor) in a separate window.
Open the Sidekick in Google Drive or Microsoft SharePoint and select one or more files to bulk preview and publish files and conveniently copy their URLs. The Sidekick counts the number of selected files and prompts you to confirm any bulk actions.
The Sidekick provides a status of ongoing bulk actions.
When the bulk actions are completed successfully, the Sidekick turns green and allows you to copy the URLs of the affected files via the Copy x URLs button or preview them via the Open x URLs button.
You can also use the bulk action feature to preview and publish media files. Adobe continues to extend the support for file formats that can be published directly from your content source (Microsoft SharePoint or Google Drive) based on popular use and security considerations. Currently the supported formats are MP4, PDF, SVG, JPG, PNG. You can learn more about file size limits here.
Limitation: in Microsoft SharePoint, large selections of more than 60 files may not be available to the Sidekick and may therefore need to be split into smaller badges.
Bulk Preview
Selecting multiple documents in Microsoft SharePoint or GDrive allows you to preview multiple documents en masse.
Selecting multiple documents in Microsoft SharePoint or GDrive allows you to publish multiple documents en masse. The Sidekick prompts you to confirm before performing bulk actions.
Use this feature to copy the preview, live or production URLs of one or multiple files.
Unpublishing content will remove the page from your live and production environments, but still keep it in the preview environment for reference or future republication.
Unpublishing and deleting content require you to be signed into the Sidekick. You must also have the appropriate roles assigned to your user.
Because unpublishing and deleting are not as common as previewing and publishing content, these options are kept behind an ellipsis menu, shown only when appropriate. Navigate to a published page or its preview and click the ellipsis button on the Sidekick to show the Unpublish option.
You can only delete pages from the preview environment. Deletion implicitly unpublishes the page if it has been published before.
The Sidekick is able to auto-detect if a URL belongs to your project. If you want the Sidekick to also recognize custom domains, such as your project’s production domain, custom preview domain, or custom live domain, you must add the project to the Sidekick.
Navigate to any source document associated with your project. Then click the context (≡) menu on the Sidekick and select Add this project.
Navigate to a project URL (similar to https://main--repo--owner.aem.page/) and click the context (≡) menu on the Sidekick and select Add this project.
You can remove projects from the Sidekick by following the same steps, but select Remove this project from the context menu instead.
If you have used a previous version of the Sidekick, you can migrate your previously-configured projects.
Enable both the previous version of the Sidekick and the new version in your browser.
Right-click the Sidekick plugin icon in your browser’s menu bar.
Select Import projects from AEM Sidekick v6 from the context menu.
Once you have added at least one project to your sidekick, you Then click the context (≡) menu on the Sidekick and select Manage projects to open the Project Admin.
The Project Admin page lists all projects you added to the sidekick.
Preview URL
Edit button to edit the name of the project within the Sidekick or to remove the project from the Sidekick.
For a complete catalog of error messages appearing in the Sidekick, review Sidekick Errors.
Customizing the Sidekick
If you are a developer, you can customize the Sidekick for your project.
Review AEM Sidekick Security for detailed information about how privacy and security are being handled in the Sidekick.
**Source:** [https://www.aem.live/blog](https://www.aem.live/blog)
When customers or partners ask me, “Should we write UI tests for our AEM projects?”, I usually say, “No, probably not.” But here’s the twist: when I’m working on something like Optel Explorer or AEM Sidekick, I write extensive tests.
Now picture writing UI tests for a visual component in AEM. A misaligned button or a slightly off layout might be annoying, but it rarely breaks the user experience. Setting up automated UI tests, however, is anything but simple. Frameworks like Playwright or Web Test Runner require significant setup, and the tests themselves are fragile - small, unrelated changes can cause them to fail. Maintaining them becomes a chore.
Components are rendered dynamically based on authored content, which can vary wildly. Different authors structure pages differently, introducing inconsistencies that automated tests struggle with. What works locally might fail in CI/CD due to rendering differences or timing issues.
The Architecture Problem That's Breaking AIs for Content Management (and the Secret Sauce to Fix It)
Imagine needing to launch four websites rapidly - while maintaining quality, consistency, and performance. One of our customers faced this exact challenge. They implemented AEM ...
**Source:** [https://www.aem.live/developer/tutorial](https://www.aem.live/developer/tutorial)
This tutorial will get you up-and-running with a new Adobe Experience Manager (AEM) project. In ten to twenty minutes, you will have created your own site and be able to create, preview, and publish your own content, styling, and add new blocks.
You have a GitHub account, and understand Git basics.
You have Node/npm installed for local development.
To get you to a live website as fast as possible, this tutorial uses Google Drive as the content source. Edge Delivery Services supports multiple content sources including Google Drive, Microsoft Sharepoint, Document Authoring, and AEM Universal Editor.
Get started with the boilerplate repository template
The fastest and easiest way to get started following AEM best practices is to create your repository using the Boilerplate GitHub repository as a template.https://github.com/adobe/aem-boilerplate
Click the Use this template button and select Create a new repository, and select the user org that owns the repository
We recommend that the repository is set to public.
The only remaining step in GitHub is to install the AEM Code Sync GitHub App on your repository by visiting this link: https://github.com/apps/aem-code-sync/installations/new
In the Repository access settings of the AEM Code Sync App, make sure you select Only select Repositories (not All Repositories). Then select your newly created repository, and click Save.
Note: If you are using Github Enterprise with IP filtering, you can add the following IP to the allow list: 3.227.118.73
In your fork of the Boilerplate GitHub repository, the site points to an existing content source in Google Drive. See this folder for some example content.
Now that you have your content, you need to connect that content to your GitHub repo. You do this by changing the reference in fstab.yaml in your GitHub repo to the folder you just shared.Copy/paste the folder URL from your Google Drive to fstab.yaml.
Be aware that after you make that change, you will see 404 not found errors as your content has not been previewed yet. Please refer to the next section to see how to start authoring and previewing your content. If you copied over index, nav and footer all three of those are separate documents with their own preview and publish cycles, so make sure you preview (and publish) all of them if needed.
Preview and publish your content
After completing the last step, your new content source is not empty, but no content has been promoted to the preview or live stages, which means your website serves 404s.To preview content, an author has to install the Sidekick Chrome extension. Find the Chrome extension in the Chrome Web Store.
As soon as the extension is installed and your project is added, you are ready to preview and publish your content from your Google Drive.Select all three docs and activate the AEM Sidekick by clicking on your pinned extension. A new toolbar will appear. Clicking the preview or publish buttons will trigger the corresponding operation.
Open the index doc and make some changes. Activate the Sidekick by clicking on your pinned extension and then click the Preview button which will trigger the preview operation and open a new tab with the preview rendition of the content.
From there change into your project folder and start your local development environment using the following.
This opens http://localhost:3000/ and you are ready to make changes.A good place to start is in the blocks folder which is where most of the styling and code lives for a project. Simply make a change in a .css or .js and you should see the changes in your browser immediately.
Once you are are ready to push your changes, simply use Git to add, commit, and push and your code to your preview (https://<branch>--<repo>--<owner>.aem.page/) and production (https://<branch>--<repo>--<owner>.aem.live/) sites.
**Source:** [https://www.aem.live/developer/anatomy-of-a-franklin-project](https://www.aem.live/developer/anatomy-of-a-franklin-project)
Git and GitHub
One of our defining philosophies is that it is easiest to allow users to work with the tools that they are familiar with. The overwhelming majority of developers manage their code in systems based on Git, so it only makes sense to allow developers to work with Git to manage and deploy their code.
We are using a buildless approach that runs directly from your GitHub repo. After installing the AEM GitHub bot on your repo, websites are automatically created for each of your branches for content preview on https://<branch>--<repo>--<owner>.aem.page/ and the production site on https://<branch>--<repo>--<owner>.aem.live/ for published content.
Every resource that you put into your GitHub repo is available on your website, so a file in your GitHub repo on the main branch in /scripts/scripts.js will be available on https://main--<repo>--<owner>.aem.page/scripts/scripts.jsThis should be very intuitive. There are few “special” files that Adobe Experience Manager uses to connect the content into your website.
We strongly recommend that repos are kept public on GitHub, to foster the community. For a public facing website there really is no need to keep the code hidden, as it is being served to the browsers of your website.
There are some files in your GitHub repo that have a special meaning to AEM and are processed in a special fashion. These files are in the root directory of your repo.
As you may have seen in the getting started guide the fstab.yaml file serves as the connection to your Google Drive or SharePoint folders that contain your content. This file is used as an indicator for how the code in your GitHub repo gets combined with the content in your content source.
The head.html file is the most important extension point to influence the markup of the content. The easiest way to think of it is that this file is injected on the server side as part of the <head> HTML tag and is combined with the metadata coming from the content.
The head.html should remain largely unchanged from the boilerplate and there are only very few legitimate reasons in a regular project to make changes. Those include remapping your project to a different base URL for the purposes of exposing your project in a different folder than the root folder of your domain on your CDN or to support legacy browsers which usually require scripts that are not loaded as modules.
Adding marketing technology like Adobe Web SDK, Google Tag Manager or other 3rd party scripts to your head.html file is strongly advised against due to performance impacts. Adding inline scripts or styles to head.html is also not advisable for performance and code management reasons, see the section Scripts and Styles below for more information about handling scripts and styles.
To create a custom 404 response, place a 404.html file into the root of your github repository. This will be served on any URL that doesn’t map to an existing resource in either content or code, and replaces the body of the out of the box minimalist 404 response.
A robots.txt file is generally a regular file that is served as you would expect on your production website on your own domain. To protect your preview and origin site from being indexed, your .page and .live sites will serve a robots.txt file that disallows all robots instead of the robots.txt file from your repo.
Complex sitemaps can automatically be created for you whenever authors publish new content, including flexible hreflang mappings where needed. This functionality is usually based on the indexing facility.See this GitHub issue for sitemap configuration options.
The common folders below are usually in the root directory of a project repo, but in cases where only a portion of a website is handled by AEM, they are often moved to a subfolder to reflect the mapping of the route of the origin in a CDN.
This means that in a case where for example only /en/blog/ is initially mapped to AEM from the CDN, all the folder structures below (eg. /scripts, /styles, /blocks etc.) are moved into a the /en/blog/ folder in GitHub to keep the CDN mapping as simple as possible.
scripts.js is where your global custom javascript code lives and is where the block loading code is triggered. styles.css hosts the global styling information for your site, and minimally contains the global layout information that is needed to display the Largest Contentful Paint (LCP).As all three files are loaded before the page can be displayed, it is important that they are kept relatively small and executed efficiently.Beyond styles.css, a lazy-styles.css file is commonly used, which is loaded after the LCP event, and therefore can contain slower/more CSS information. This could be a good place for fonts or global CSS that is below the fold.
Please see the document Keeping it 100, Web Performance for more information about optimizing your site performance.
Blocks
Most of the project-specific CSS and JavaScript code lives in blocks. Authors create blocks in their documents. Developers then write the corresponding code that styles the blocks with CSS and/or decorates the DOM to take the markup of a block and transform it to the structure that’s needed or convenient for desired styling and functionality.
The block name is used as both the folder name of a block as well as the filename for the .css and .js files that are loaded by the block loader when a block is used on a page.
The block name is also used as the CSS class name on the block to allow for intuitive styling. The javascript is loaded as a module (ESM) and exports a default function that is executed as part of the block loading.
A simple example is the Columns Block. It adds additional classes in JavaScript based on how many columns are in the respective instance created by the author. This allows it to be able to use flexible styling of content that is in two columns vs. three columns.
**Source:** [https://www.aem.live/developer/anatomy-of-a-project](https://www.aem.live/developer/anatomy-of-a-project)
**Source:** [https://www.aem.live/developer/block-collection](https://www.aem.live/developer/block-collection)
This is a collection of blocks considered a part of the AEM product and are recommended as blueprints for blocks in your project.
These blocks come from real production AEM projects. To be a part of this collection, a block needs to have a high use across a number of projects and provide enough abstract functionality and be general enough so it can be reused without having to change the underlying content model.
As the needs and designs of websites change, the block collection will change as well. Additions will be made to reflect emerging needs of projects, but blocks that are not used frequently enough will also be removed (deprecated).
There are few technical principles for the blocks in the collection:
Fast: No negative performance impact
All of the blocks can be considered as a basis for your own block development. It is very likely that you will change all the .css and .js code to meet your own project needs. The primary value of these blocks is the content structure they provide.Considering that the code of your block will be fully adapted to your project, there is no intent for the blocks in the collection to be backwards compatible to their respective older versions or to make them upgradable.
The most commonly used blocks (as well as default content types) are curated in the AEM Boilerplate and are a part of every AEM project. For a block to become a part of boilerplate it has to be used by the vast majority of all AEM projects.
The code base for all the blocks in AEM Boilerplate is open-source and can be found on GitHub adobe/aem-boilerplate
Blocks in AEM Boilerplate can be discovered using the sidekick library below, use the copy button to copy the corresponding content structure into your clipboard and paste into a document to see the content structure.
Block
Simple extensible footer block
Metadata
Add metadata to your page where needed
Section Metadata
The block collection contains blocks that are commonly-used, but are not so common to be considered boilerplate. As a rule-of-thumb, to be included in the block collection a block must be used on more than half of all AEM projects.
The block collection can be the entry path into boilerplate code. Likewise if a block in the boilerplate is no longer used as much, it can be moved to this collection.
The code base for all the blocks in AEM Block Collection is open-source and can be found on GitHub adobe/aem-block-collection
Blocks in AEM Block Collection can be discovered using the sidekick library below, use the copy button to copy the corresponding content structure into your clipboard and paste into a document to see the content structure.
Block Add-on
Autoblock
Block (Deprecated)
The block collection is continually evolving based on the feedback from the AEM community. If you think that there is a block that should be included in the block collection please speak to your AEM contact. Current candidates for inclusion in the block collection include:
If you have immediate need of a block that is not yet part of the collection, it is relatively easy to find AEM projects on GitHub that have example implementations for all of the above candidates.
Block Party
The Block Party is a place for the AEM developer community to showcase what they have built on AEM sites. It also allows others to avoid reinventing the wheel and reuse these blocks / code snippets / integrations built by the community and tweak the code as necessary to fit their own projects. See Block Party for everything it has to offer.
Note: While we love and support our AEM developer community, Adobe is not responsible for maintaining or updating the code that is showcased in Block Party. Please use the code at your own discretion.
**Source:** [https://www.aem.live/developer/spreadsheets](https://www.aem.live/developer/spreadsheets)
After a preview and publish via the sidekick, AEM translates this table to a JSON representation which is served to requests to the corresponding .json resource. The above example gets translated to:
**Source:** [https://www.aem.live/developer/indexing](https://www.aem.live/developer/indexing)
We will introduce the concept of creating a query index by previewing an Excel workbook or Google spreadsheet first. Note, that if you already have a custom query definition in a file called helix-query.yaml in your GitHub repository, it is no longer possible to create indexes that way. Every new index will have to be manually added to that helix-query.yaml.
For simple scenarios without custom index definition, pages that have robots metadata property set to noindex will automatically be omitted from indexing by AEM. (There are a few special scenarios here, for more details see the section Special Scenarios for Robots).
To activate your index, preview the spreadsheet using the sidekick. This will create an index configuration.
The Admin Service has an API endpoint where you can check the index representation of your page. Given your GitHub owner, repository, branch and owner, and a resource path to a page, its endpoint is:
The AEM CLI has a feature where it will print the index record whenever you change your query configuration, which assists in finding the correct CSS selectors:
Please see the AEM CLI GitHub documentation for more information and watch this video to learn more about this feature.
In the following 2 situations, setting robots to noindex on the page metadata would not prevent it from being indexed by AEM:
You have a helix-query.yaml in your Github repository i.e. you have defined a custom index definition.
If you do not have a custom index definition, it is recommended to not add a robots column to your index sheet unless you have a requirement for doing so.Adding robots column to your index sheet would cause a page to be indexed by AEM even though it may have robots metadata set to noindex.
If you do have a custom index definition, pages would get indexed by AEM irrespective of setting robots to noindex on the page metadata. If you want to prevent this from happening, you can use spreadsheet filters to omit pages from index that have robots metadata set to noindex. For more details, see the section titled "Enforcing noindex configuration with custom index definitions" below.
Modify your custom helix-query.yaml (it must be in your project’s Github repository) and add the robots property so that it gets indexed.
**Source:** [https://www.aem.live/developer/keeping-it-100](https://www.aem.live/developer/keeping-it-100)
Web Performance, Keeping your Lighthouse Score 100.
Adobe Experience Manager (AEM) is optimized to deliver excellent experiences and optimal web performance. With the Real Use Monitoring (RUM) operations data collection, information is continuously collected from field use and offers a way to iterate on real use performance measurements without having to wait for the CRuX data to show effects of code and deployment changes. It is common for field data collected in RUM to deviate from the lab results, as the network, geo-location and processing power for real devices are much more diverse than the simulated conditions in a lab.
The Google PageSpeed Insight Service is proven to be a great lab measurement tool. It can be used to avoid the slow deterioration of the performance and experience score of your website.
If you start your project with the Boilerplate as in the Developer Tutorial, you will get a very stable Lighthouse score on PageSpeed Insight for both Mobile and Desktop at 100. On every component of the lighthouse score there is some buffer for the project code to consume and still be within the boundaries of a perfect 100 lighthouse score.
Testing Your Pull Requests
It turns out that it is hard to improve your Lighthouse score once it is low, but it is not hard to keep it at 100 if you continuously test.
When you open a pull request (PR) on a project, the test URLs in the description of your project are used to run the PageSpeed Insights Service against. The AEM GitHub bot will automatically fail your PR if the score is below 100 with a little bit of buffer to account for some volatility of the results.
The results are for the mobile lighthouse score, as they tend to be harder to achieve than desktop.
Many teams and individuals use their own configurations for measuring Lighthouse scores. Different teams have developed their own test harnesses and use their own test tools with configurations that have been set up as part of their continuous monitoring and performance reporting practices.
The performance of a website impacts its rankings in search results, which is reflected by the Core Web Vitals in the crUX report. Google has a great handle on the relevant average combinations of device information (e.g. screen size) as well as network performance of those devices. But in the end, SEO is the ultimate arbiter of what good vs. bad web performance is. As the specific configuration is a moving target, performance practices should be aligned with the current average devices and network characteristics globally.
So instead of using a project specific configuration for Lighthouse testing, we use the continuously-updated configurations seen as part of the mobile and desktop strategies referenced in the latest versions of the Google PageSpeed Insights API.
While there may be additional insight that some developers feel they can collect from other ways of measuring Lighthouse scores, to be able to have a meaningful and comparable performance conversation across projects, there needs to be a way to measure performance universally. The default PageSpeed Insight Service is the most authoritative, most widely accepted lab test when it comes to measuring your performance.However it is important to remember that the recommendations that you get from PageSpeed Insights do not necessarily lead to better results, especially the closer you get to a lighthouse score of 100.Core Web Vitals (CWV) collected by the built-in RUM data collection play an important role in validating results. For minor changes, however, the variance of the results and the lack of sufficient data points (traffic) over a short period of time makes it impractical to get statistically relevant results in most cases.
Dissecting the payload that's on a web page into three phases makes it relatively straight-forward to achieve a clean lighthouse score and therefore set a baseline for a great customer experience.
In the eager phase, the first action is to “decorate” the DOM: the loading sequence makes few adjustments, mainly adds CSS classes to icons, buttons, blocks and sections and creates the auto-blocks. See the Markup, Sections, Blocks, and Auto Blocking page for more details on the resulting markup.
Then, the full first section is loaded with a priority given to the first image of this section, the “LCP candidate”. In theory, the fewer blocks the first section has, the faster LCP can be loaded.
Once the LCP candidate and all blocks of the section are loaded, the first section can be displayed and the fonts can start loading asynchronously.
In many cases the LCP element is contained in a block, where the block .js and and .css also have to be loaded.
There are situations where the actual LCP element is not included in the markup that is transmitted to the client. This happens when there is an indirection or lookup (for example a service that’s called, a fragment that’s loaded or a lookup that needs to happen in a .json) for the LCP element.In those situations, it is important that the page loading waits with guessing the LCP candidate (currently the first image on the page) until the first block has made the necessary changes to the DOM.
There are other situations where the content contains 2 hero images, one for desktop, one for mobile. Same as above, it is important to make sure that the correct image is considered as the LCP candidate and the “hero” block might need to be adjusted to remove the unnecessary image from the DOM (remove the desktop image on mobile devices or vice versa) to not load a bandwidth consuming image or even worse, load the unnecessary image first as the LCP candidate.
In the lazy phase, the portion of the payload is loaded that doesn't affect total blocking time (TBT) and ultimately first input delay (FID).
This includes things like loading the next sections and their blocks (JavaScript and CSS) as well as loading all the remaining images according to their loading="lazy" attribute and other JavaScript libraries that are not blocking. The lazy phase is generally everything that happens in the various blocks you are going to create to cover the project needs.
In the delayed phase, the parts of the payload are loaded that don't have an immediate impact to the experience and/or are not controlled by the project and come from third parties. Think of marketing tooling, consent management, extended analytics, chat/interaction modules etc. which are often deployed through tag management solutions.
The delayed phase is usually handled in delayed.js which serves as an initial catch-all for scripts that cause TBT. Ideally, the TBT problems are removed from the scripts in question either by loading them outside of the main thread (in a web worker) or by just removing the actual blocking time from the code. Once the problems are fixed, those libraries can easily be added to the lazy phase and be loaded earlier.
Ideally there is no blocking time in your scripts, which is sometimes hard to achieve as commonly used technology like tag managers or build tooling create large JavaScript files that are blocking as the browser is parsing them. From a performance perspective it is advisable to remove those techniques, make sure your individual scripts are not blocking and load them individually as separate smaller files.
The header and specifically the footer of the page are not in the critical path to the LCP, which is why they are loaded asynchronously in their respective blocks. Generally, resources that do not share the same life cycle (meaning that they are updated with authoring changes at different times) should be kept in separate documents to make the caching chain between the origins and the browser simpler and more effective. Keeping those resources separate increases cache hit ratios and reduces cache invalidation and cache management complexity.
By default, the AEM Boilerplate implements the font fallback technique to avoid CLS when the font is loaded. It would be counterproductive to preload the fonts (via Early hints, h2-push or markup) and largely impact the performances.
Common Sources of Performance Issues
Over time, we gathered a collection of anti-patterns that negatively impact performance, and need to be avoided to be compliant with the best practices in this document.
As a rule of thumb, to get an LCP to 100 on Mobile with PageSpeed Insight the network constraints are set up in a way that there can only be a single host with a network payload that's not exceeding 100kb, as the setup is largely bandwidth constrained. Early hints, h2-push and pre-connect consume that bandwidth, by downloading resources that are not required for LCP and therefore negatively impact the performance, and have to be removed.
If a visitor requests www.domain.com and gets redirected to www.domain.com/en and then to www.domain.com/en/home, they get a penalty for each redirect, i.e. performance is negatively impacted. This is mostly visible in Core Web Vitals measured via RUM or CrUX as lab results in PageSpeed Insights by default exclude redirect overhead from the lab test.
CDN client scripts injection
Our markup but also our .aem.page and .aem.live origins are optimized for performance and we are extremely careful with any part of the payload, as well as the loading sequence for resources.
Some CDN vendors and configurations inject scripts that are consuming bandwidth and create blocking time, before LCP with negative impacts performance. Those scripts should be disabled, or loaded appropriately in the loading sequence after LCP.
A comparison of a .aem.live origin of the PageSpeed Insight report, with the corresponding site that's fronted by a customers CDN (e.g. production site) will show the negative impact produced by a CDN outside of AEM's control.
CDN TTFB and Protocol Implementation Impact
Depending on the CDN vendor, there are differences in protocol implementations and performance characteristics for the pure delivery of the HTTP payload. Additional tooling like WAF and other network infrastructure upstream of AEM may also negatively impact performance.A comparison of a .aem.live origin of the PageSpeed Insight report, with the corresponding site that's fronted by a customers CDN (e.g. production site) will show the negative impact produced by a CDN outside of AEM's control.
**Source:** [https://www.aem.live/developer/markup-sections-blocks](https://www.aem.live/developer/markup-sections-blocks)
Markup, Sections, Blocks, and Auto Blocking
This means that it is strongly recommended to involve authors very early in the process. In many cases it is good practice to just let authors put the content that needs to go on to a page into a Google Doc or Word document without having any notion of blocks and section, and then try to make small structural changes and introduce sections and blocks only where necessary.
A page as authored in Word or a Google Doc document uses the well-understood semantic model like headings, body text, lists, images, links, etc. that is shared between HTML, markdown, and Google Doc / Word. We call this default content. In an ideal situation one would leave as much of the content authored as default content as possible, since this is the natural way for authors to treat documents.In addition to default content, we have a concept of page sections, separated by horizontal rules or --- to group certain elements of a page together. There may be both semantic and design reasons to group content together. A simple case could be that a section of a page has a different background color.In addition to that there is concept of blocks which are authored as a table with a heading as the first row that identifies the type of block. This concept is the easiest approach to componentize your code.
Sections can contain multiple blocks. Blocks should never be nested as it makes things very hard to use for authors.
The JavaScript library used in scripts.js takes the markup and enhances it into a DOM that is then used for most development tasks, specifically to build blocks. To create a DOM that’s easy to work with for custom project code, it is best to view it as a two-step process.
In the first step, we create the markup with sections, blocks, and default content that will look similar to this.
It primarily consists of introducing a wrapper <div> for blocks and default content and dynamically adding additional helpful CSS classes and data attributes that are used by the AEM block loader.
Sections are a way to group default content and blocks by the author. Most of the time section breaks are introduced based on visual differences between sections such as a different background color for a part of a page.
From a development perspective, there is usually not much interaction with sections beyond CSS styling.Sections can contain a special block called Section Metadata, which results in data attributes to a section. The names of the data attributes can be chosen by the authors, and the only well-known section metadata property is Style which will be turned into additional CSS classes added to the containing section element.
Blocks and default content are always wrapped in a section, even if the author doesn’t specifically introduce section breaks.
Most of the project-specific CSS and JavaScript lives in blocks. Authors create blocks in their documents and developers write the corresponding code that styles the blocks with CSS and/or decorates the DOM to take the markup of a block and transform it to the structure that’s needed or convenient for desired styling and functionality.
The block name is used as both the folder name of a block as well as the filename for the CSS and JavaScript files that are loaded by the block loader when a block is used on a page. The block name is also used as the CSS class name on the block to allow for intuitive styling.
The JavaScript is loaded as a Module (ESM) and exports a default function that is executed as part of the block loading.
All block level CSS should be scoped to the block to make sure that there are no side-effects for other parts of your project, which means that all selectors in a block should be prefixed with the corresponding block class. In certain cases it makes sense to use the block’s wrapper or containing section for the selector as well.
One of the most important tenets of a project is to keep things simple and intuitive for authors. Complicated blocks make it hard to author content, so it is important that developers absorb the complexity of translating an intuitive authoring experience into the DOM that is needed for layout or application logic. It is often tempting to delegate complexity to the author. Instead, developers should make sure that blocks do not become unwieldy to create for authors. An author should always be able to simply copy/paste a block and intuitively understand what it is about.
Blocks can be very simple or contain full application components or widgets and provide a way for the developer to componentize their codebase into small chunks of code that can be managed easily and can be loaded on to the web pages as needed.
A block’s content is rendered into the markup as nested <div> tags for the rows and columns that the author entered. In the simplest case, a block has only a single cell.
Block Options
If you need a block to look or behave slightly differently based on certain circumstances, but not different enough to become a new block in itself, you can let authors add block options to blocks in parentheses. These options add modified classes to the block. For example Columns (wide) in a table header will generate the following markup.
Block options can also contain multiple words. For example Columns (super wide) will be concatenated using hyphens.
If block options are comma-separated, such as Columns (dark, wide), they will be added as separate classes.
Auto Blocking
In an ideal scenario the majority of content is authored outside of blocks, as introducing tables into a document makes it harder to read and edit. Conversely blocks provide a great mechanism for developers to keep their code organized.
A frequently-used mechanism to get the best of both worlds is called auto blocking. Auto blocking turns default content and metadata into blocks without the author having to physically create them. Auto blocking happens very early in the page decoration process before blocks are loaded and is a practice that programmatically creates the DOM structure of a block as it would come as markup from the server.
Auto blocking is often used in combination with metadata, particularly the template property. If pages have a common template, meaning that they share a certain page design or functionality, that’s usually a good opportunity for auto blocking.
A good example is an article header of a blog post. It might contain information about the author, the title of the blog post, a hero image, as well as the publication date. Instead of having the author put together a block that contains all that information, an auto block (e.g. article-header block) would be programmatically added to the page based on the <h1>, the first image, the blog author, and publication date metadata.
This allows the content author to keep the information in its natural place, the document structure outside of a block. At the same time, the developer can keep all the layout and styling information in a block.
Another very common use case is to wrap blocks around links in a document. A good example is an author linking to a YouTube video by simply including a link, while the developer would like to keep all the code for the video inline embed in an embed block.
The code for your projects auto blocking lives in buildAutoBlocks() in your scripts.js.
Please see the following examples of auto blocking.
**Source:** [https://www.aem.live/developer/favicon](https://www.aem.live/developer/favicon)
Add a file called favicon.ico to the root folder in your GitHub repository. We recommend using the .ico format for best support across all major browsers. That’s all – your site now has a favicon!
**Source:** [https://www.aem.live/docs/custom-headers](https://www.aem.live/docs/custom-headers)
After you update the sheet, you need to preview (activate) it. Note that the headers are applied to both the preview and live versions of the content. Caches will be purged automatically, so your changes will take effect immediately. See the Admin API documentation for more information.
Note: If the changes apply to code resources, the changes won’t take effect until the code is synced again, either by updating the code in its repository or by manually updating via the Admin API.
**Source:** [https://www.aem.live/docs/dev-collab-and-good-practices](https://www.aem.live/docs/dev-collab-and-good-practices)
GitHub
Keep the repository public
Given that all project code is sent to the client-side and therefore accessible in everyone's browser, we recommend keeping the repository as public. Adobe has a longstanding history in the open-source community and generally advocates for code to be public unless there is a compelling reason to make it private.
Maintaining a public repository offers several benefits of open source projects like community code reviews, and developers are able to share knowledge and code, in turn fostering innovation and collaboration. Public repositories also make it quick and easy for Adobe and other developers to create free pull requests to help improve your project and automatic PSI checks (on the feature branches) are provided by Adobe, which are not enabled by default for private repositories.
If you still have a strong need to keep your repository private, be aware that certain features are only available in paid plans for private repositories, such as branch protection rules and limited CI/CD minutes. For more details, please see GitHub’s pricing page.
Create pull requests
Pull request etiquette
If you open a pull request, make sure that you include a URL to a page (or a number of links to pages) on your branch, where the reviewer can see your code in action. If you are updating code of an existing block, make sure to include the link that features the block you are updating as the reviewer may not know where this block is in use to test its functionality.
Keep the scope of your Pull Request to what’s in the title/description of the PR.
For work still in progress, opening a Draft Pull Request helps prevent wasting people's time with reviewing code still in flux as well as accidental merging.
The standard boilerplate setup runs the linting tools eslint (airbnb-base) and stylelint for each change in a Pull Request. Do not submit a Pull Request with linting errors for review.
Changing the linting configuration is not recommended unless you have a really good reason. Personal preference is not a good reason. Changing linting rules makes it difficult to reuse code from the AEM boilerplate, block collection or other open source AEM projects. Arguing if something is a good reason to change the linting rules is usually a lot more effort than just categorically saying no.
The AEM Code Sync GitHub app runs Google PageSpeed Insights for each change in a pull request to assess the impact on Web Performance, Accessibility, SEO and Best Practices. Do not submit a pull request for review that doesn’t have a green Lighthouse Score for mobile and desktop, ideally 100 for both.
It is good practice to have your code reviewed by the maintainer or main developer of the project you are working on. This can be encouraged by setting up branch protection on main to require pull requests with at least 1 approval before any code can be merged. You can still allow project administrators to bypass branch protection settings for emergencies.
It is good practice to consider branches for individual Pull Requests as private to the developer who created the branch. Do not just push into other developers’ branches without having been invited to do so. There are situations where people are collaborating on Pull Requests but it should be an explicit agreement.
Merging pull requests (deploying to production)
Merge your own pull requests only. If the person who opened the Pull Request has the ability to merge their own Pull Request, the author of the code is the ideal person to merge. There are situations where the author specifically states that this can and should be merged by someone else, and in those cases a maintainer (main developer) of the project should feel free to merge a Pull Request.
Even if a Pull Request is approved, you should always check with the author of the Pull Request if they are ready to merge.
The AEM Code Sync GitHub app will automatically deploy changes merged into the main branch to production.
For AEM projects with their built-in devops and CI/CD, we recommend following the scaled trunk-based development model. This means you merge small pull requests into production often, but the quality assurance & review efforts are limited to small change sets. Nobody wants to review and test large pull requests, and long-lived branches with lots of changes tend to be difficult (and dangerous) to merge.
CSS selector block isolation
AEM blocks most often operate as components collaboratively in the same DOM / CSSOM. This means that you should write your CSS selectors in a block .css in a way that isolates your CSS from impacting layout of elements outside your block. The easiest way to do this is by making sure that every CSS selector in the .css of a block only applies to the block.
Use your CSS classnames wisely. Some CSS classes and variables are used across different blocks, and others are not expected to be used outside your block. Prefixing classes and variables that are private to your block with the block name is good practice. Conversely, if there are CSS classes and CSS context that should be inherited (often those can be authored) those classes and variables should not be prefixed.
In many situations you will add ARIA Attributes for accessibility. Since those have well defined semantics like expanded or hidden that are understood by all developers, in most cases there is really no need to come up with additional classes in your vocabulary that have unknown semantics.
If you are working in the context of a bigger organization, make sure that you don’t introduce a dependency to any CSS preprocessor or framework of your personal preference without getting the buy-in from the entire team and organization. As there are a lot of differing personal preferences in this area, it makes code hard to maintain if every project or every block inside a project uses different technologies.The simplest solution is to rely on the growing CSS feature set which is supported by the browsers.
Modern CSS features
On most web sites, frameworks are overkill for simple layout problems outside of application-like functionality. Frameworks often introduce web performance issues (Lighthouse and Core Web Vitals), particularly if they are in the pathway of the LCP or introduce TBT, while trying to address trivial problems. Keep simple things simple.If you are using Javascript Frameworks make sure that you don’t introduce a dependency to any JS Framework or library of your personal preference without getting the buy-in from the entire team and organization. As there are a lot of personal preferences, it makes code hard to maintain if every project or every block inside a project uses different technologies.The simplest solution is to rely on the growing feature set supported by browsers.
Don’t add 3rd party libraries to your <head> via head.html as they will be in the critical path of loading content above the fold and will often be loaded when they are not needed. Add the dependencies where needed via loadScript() to the specific block that has the corresponding requirement.In case of larger 3rd party libraries, you may even want to consider using an IntersectionObserver to make sure you only load them when the block depending on it is actually being scrolled into view.
The AEM library (usually called aem.js in a boilerplate project) is currently not minified and obfuscated to make debugging easier. We discourage making changes to it on a project basis and instead recommend project specific extensions to be kept outside of the library. We welcome Pull Requests via GitHub, if you would like to propose changes or bug fixes that are universally applicable.
The <head> that is delivered from the server as part of the HTML markup should remain minimal and free of marketing technology like Adobe Web SDK, Google Tag Manager or other 3rd party scripts due to performance impacts. Adding inline scripts or styles to <head> is also not advisable for performance and code management reasons.
Typically this is additional complexity without much benefit unless you have really large JS/CSS files which again would be an anti-pattern. With Edge Delivery, the way the code is structured around blocks, the files should be usually small in size and minifying should not make much of a difference. To be sure, you can compare the Lighthouse Score pre/post minification.Minification makes code slightly harder to debug and you'd need sourcemaps. Also minifying requires an additional build step which can potentially slow down site development work. So you’d want to go there only if there is a tangible benefit of this additional complexity
Before writing a line of code, create your (sample) content in a Word or Google Doc (or spreadsheet). Make sure that it feels good for authoring and share it with people on your team that have experience supporting authors. It requires support experience to understand what content structures are easy for authors to understand and recreate. Once you have settled on a content structure that contains all elements you need for your block, and have it reviewed you can get started developing your CSS and JS code.
The content lifecycle is very different from the code life cycle. If you are proposing changes to an existing content structure in your code or come up with a new block, don’t just make those changes on the page you are working on. Copy the page into your /drafts/<yourname>/ folder and make changes there.Once your code changes are merged to main , you can have authors copy or merge your content with the content outside of your /drafts/ folder.
Especially in production environments it is important to keep your anticipated changes to the content structure backwards compatible with existing content. Ideally, code that is being merged should not have an impact on the website or require refactoring the content. Only when new content is put in place through a preview and publish cycle, the new functionality becomes available. This of course doesn’t apply to things like design changes across the existing content or functional bug fixes.
Generally, it is not a good idea to commit binaries into your GitHub repo. Even text-based static resources, for example HTML files or SVGs should only be put into GitHub in exceptional cases. A good reason to add an SVG to your git repo is if it is referenced from code. Don’t commit anything that is related to the content authoring process, or could be a part of an authoring process. There are some exceptions (usually related to legacy and non-browser clients) that require a certain set of fixed resources that cannot be produced and manipulated dynamically by AEM, but in general if you find a large set of static resources (e.g. images, etc.) or an HTML file in a PR it is most likely not a good practice.
**Source:** [https://www.aem.live/docs/integrations](https://www.aem.live/docs/integrations)
Integrations Overview
Adobe Experience Manager integrates with all technologies required to create and operate a high-performing website. For some of the key integrations, we have provided detailed guides.
CDN Integration Overview
A CDN is required to deliver content from AEM to your visitors under your domain. This overview links to guides for all supported CDNs.
Authoring Integration Overview
AEM Forms Integration
Adobe Experience Cloud Integration
Adobe Target Integration
Google Analytics & Tag Manager Integration
GitHub Actions Integration
GitHub Actions can be used to automate based on code and content changes.
In addition to supporting GitHub.com out of the box, other git providers can be integrated with AEM, too.
Unsupported Integrations
Some integrations have proven problematic in customer environments and are therefore unsupported or heavily discouraged.
**Source:** [https://www.aem.live/docs/authoring-guide](https://www.aem.live/docs/authoring-guide)
Edge Delivery Services has built-in support for a variety of different content sources. We've listed the most popular ones for you below. Pick the one best suited to your needs:
SharePoint is a widely used content repository for Word and Excel documents. Users are familiar with these tools, requiring no extra training.
Document Authoring for Edge Delivery Services offers a user-friendly, performant and highly available document-based authoring experience.
SharePoint is a widely used content repository for Word and Excel documents. Users are familiar with these tools, requiring no extra training. Despite some rate limiting, SharePoint remains a reliable option for content management.
AEM Content Fragment Editor is designed for the needs of headless applications, generating JSON for Edge Delivery Services, among other things. It requires authors to follow the content structure enforced by application developers and may therefore require additional training.
The Universal Editor in Adobe Experience Manager Sites offers live-preview of the content to be authored, combined with a structure-first approach to authoring, guided by tight field definitions. It requires initial training but provides great flexibility by mapping content to front-end blocks. Note that this is not the usual AEM Page Editor experience that some might be used to in AEM.
Document Authoring for Edge Delivery Services offers a user-friendly, high-performance, and highly available document-based authoring experience. It requires minimal training, though automation and workflows may need some customization.
**Source:** [https://www.aem.live/docs/authoring](https://www.aem.live/docs/authoring)
It is a good idea to set an alternative text for all images you add to the document, as this increases accessibility and helps search engines find your content.
Word and Google Docs do not allow you to just drag and drop videos, but you can add videos via SharePoint or Google Drive and add the resulting URL as a link to a suitable block in your document.
Links are an important part of every website and you can add them both in Word and Google Docs. If you are creating a link within your website, enter the URL as is, even if the page you are linking to is not public yet (e.g. a preview or live URL).
Metadata & SEO
Metadata is information about your page that is invisible to visitors, but important to search engines and social media sites that want to find your content or embed it.
To add metadata to your page, at the end of the document, create a table like the following. Creating a table works almost the same in Word and Google Docs. See the documentation of either product for more details.
The first row of the table should just contain the word “Metadata”. This tells the system that there is custom metadata for your document.
Then create one row for each metadata property. The left column contains the name of the metadata property, the right column the value. In most cases, values are plain text, but as you can see from the “image” row, sometimes other content can be used, too.
You’ve just created a metadata block. You can also create metadata for many pages at once. See the document Bulk Metadata for more information.
Special Metadata Properties
In addition to all well-known metadata properties, AEM also supports the following properties with special handling:
The canonical:extension property allows you to define the file extension for canonical URLs. This is useful for ensuring consistent and SEO-friendly canonical URLs across your site, even if the actual file paths do not include the extension.
To avoid having to repeat it for many documents, this property is best used in the bulk metadata sheet by adding a column named canonical:extension. For example, to give an .html extension to all canonical URLs on your site, add an entry like this:
If not specified, AEM will use the first image found on the page. If the page does not contain any images, the default value will be set to /default-meta-image.png. You can add this file via SharePoint, Google Drive, or GitHub, for example.
The title:suffix property enables you to automatically append a specified suffix to the title property of your pages. This is useful to apply branding, to add consistent information, or to meet specific SEO requirements across a set of pages.
To avoid having to repeat it for many documents, this property is best used in the bulk metadata sheet by adding a column named title:suffix. For instance, to append | Adobe to the end of all page titles, add an entry like this:
Note: consider other methods like client-side JavaScript or head.html to add a JSON schema to your page. In many cases, metadata is not the right approach.
Omitting Metadata Values
If you want to remove a metadata value, you can simply leave its value empty.
Blocks are a way to work with more structured content and add special functionality to your site. Which blocks are available to your site depends on what your development team has implemented and differs from site to site. The only block that is common to all sites is the metadata block described previously.
Regardless of site, the structure of a block is always the same: it is a table with a merged first row that serves as the block name (header row). The header row may have specific formatting like a background color to increase their discoverability and differentiation in a document.
Blocks usually contain content, configuration, or references to other pieces of content, be it from other documents, spreadsheets, or both.
As you can see from this example, you are free to put any kind of content into the cells of a block, and it is up to the block to either render the content or ignore it. If the site you are working on uses blocks extensively, then you will probably have a reference list of blocks you can use.
Blocks can have variants in parenthesis. For example, a Columns block can have a (highlight)option which passes a layout hint to the block display logic.
See the document The Block Collection to learn more about out-of-the-box blocks.
You can put content into spreadsheets and then the spreadsheet is automatically turned into an API that your developers can use. This allows you to use spreadsheets like a headless CMS for use in data tables, navigation, or feature comparisons, for example.
Preview and Publish Content
Once a document is created in Google Drive or Sharepoint, you can preview the corresponding web page and eventually publish the content to your production website.
The preview function is used to share pages with stakeholders before they are published and available to the general public on your website.
In order to preview, publish, or delete content, use the Sidekick that can be installed as a browser extension.
Preview
In Word or Google Docs, open the Sidekick, then click the “Preview” button. This will open a new browser window (check for the popup warning) that has the preview version of your site.
Although you can copy and share the URL of this preview, it is not meant for production. It does not have your domain name on it and is invisible to search engines. If the content is ready for publication, you can publish. If you need to make changes, open the Sidekick on the preview page and click “Edit” to go back to Word or Google Docs.
Publishing makes your content visible to everyone on the internet. To publish something, open the sidekick on a preview page (or follow the instructions above to open the preview again), then click “Publish”. After a few seconds, a new browser window will open, with your page on your public website.
Then open the page you want to delete on the preview site and open the sidekick. There will be two options: Delete and Unpublish.
Unpublish removes it from the public production website, but keeps the preview.
Delete removes the preview, too.
**Source:** [https://www.aem.live/docs/aem-authoring](https://www.aem.live/docs/aem-authoring)
Authoring with AEM for Edge Delivery Services
Authoring and persisting content in AEM as a Cloud Service using the Universal Editor, you benefit from the power of AEM’s robust tool set for managing your content such as multi-site, management, localization workflows, and launches, while at the same time your pages are delivered with unparalleled performance by Edge Delivery Services.
When using AEM as a Cloud Service for managing your content, the Universal Editor and Edge Delivery Services work together for a seamless authoring experience.
AEM renders the HTML but includes the scripts, styles, icons and other resources from Edge Delivery Services.
Content that you author with the Universal Editor and persist to AEM is published to Edge Delivery Services.
AEM renders semantic HTML that is needed for ingestion by Edge Delivery Services.
Content is published to Edge Delivery Services.
Edge Delivery Services ensure a 100% core web vitals score.
When authoring content using AEM and the Universal Editor, the same concepts of page blocks and sections used when authoring document-based content are used to structure your pages.
Blocks are fundamental components of a page delivered by Edge Delivery Services. Authors can choose from default blocks provided as standard by Adobe or from blocks customized for your project by your developers.
The Universal Editor provides a modern and intuitive GUI for authoring your content by adding and arranging blocks, which the Universal Editor refers to as components.
Details of the components can then be configured in the Properties panel.
If you wish to get started authoring content using AEM and the Universal Editor with Edge Delivery Services, please see the following documents.
Creating Blocks for use with the Universal Editor
Learn how to create blocks instrumented for the Universal Editor including definitions, block decoration, and styles.
Publish assets from AEM Assets along with content you edit in AEM to Edge Delivery Services.
**Source:** [https://www.aem.live/docs/bulk-metadata](https://www.aem.live/docs/bulk-metadata)
By default, metadata is managed at the page level. See Authoring and Publishing Content for more information.
In some cases, it is useful to apply metadata en masse to a website. Common use cases include:
Default metadata such an og:image should be applied to portions of the website.
If a certain portion of the website should not be indexed by robots, the metadata can be used to set the robots meta tag to noindex for a portion of the site.
If you want to create metadata for many pages at once, create a metadata sheet in the root folder of your website content.
Name the file metadata in Google Drive or AEM.
Name the file metadata.xlsx in SharePoint.
The column titled URL has the URL pattern of the pages that should get a particular metadata entry.
The metadata sheet is evaluated from top to bottom, site wide meta data set to ** must be before more specific entries.
For each metadata property, create a column in the worksheet and name it using the property you want to assign. Typical examples include template, theme, or robots.
Page-level metadata added via a metadata block takes precedence over bulk metadata. See Authoring and Publishing Content and Metadata (block) for more information.
Note: You need to preview and publish the metadata sheet in order to see changes reflected on your site.
To explicitly remove metadata a "" can be used as a value. This will remove the element or set the corresponding attribute to "" for a particular path.
The example above will remove the <link rel="canonical"> from all pages by default, unless there is a specific override for example from a page metadata block.
Additional Metadata
When having metadata that is managed by several teams it is not practical to keep them all in the same metadata files. Multi metadata support is possible by configuring the all the metadata files that need to be taken into account in the /.helix/config.xlsx file:
The order of the entries in the list dictates the order of how the data is applied. The final order of the metadata is as follows:
If there is metadata configured in the /.helix/config.xlsx:
Page level metadata block wins over
Folder-mapped metadata sheet wins over
Metadata sheet(s) in configured order
Bulk metadata sheet (/metadata.xlsx)
Note that individual metadata properties are overwritten but never deleted. For example, if the /metadata.json defines a property title, the same property in /metadata-2nd.json will overwrite the value, but only if it is not empty.
**Source:** [https://www.aem.live/docs/placeholders](https://www.aem.live/docs/placeholders)
After making changes to your placeholder spreadsheet, you can preview your changes via the sidekick and have your stakeholders check that the new placeholders are working on your .page preview website before publishing the placeholder changes to your production website. See the Sidekick documentation for more information about switching between environments.
**Source:** [https://www.aem.live/developer/sitemap](https://www.aem.live/developer/sitemap)
Create automatically generated sitemap files to be referenced from your robots.txt. This helps with SEO and the discovery of new content. AEM can generate three types of sitemaps: without any configuration, based solely on a query index or based on a manual sitemap configuration. A single sitemap must be limited to 50,000 URLs and 50MB (uncompressed) in size - see Limits.
If you started with another type of sitemap and would like to switch to this type, you’ll have to delete the helix-sitemap.yaml configuration file - either manually defined in GitHub or automatically generated - and reindex your site.
To customize the domain used in creating external URLs, add a property named cdn.prod.host in your project configuration.
It is recommended that you create a sitemap-index.xml file that references all your sitemaps and keep that as part of your project code in your github repo. This way it is easy to add new sitemaps as the project expands.
Note: When using a manually configured index and sitemap (e.g. your code repo includes a helix-query.yaml and helix-sitemap.yaml file) your index definition must include the robots property to ensure the sitemap excludes pages with robots: noindex metadata. When using auto-generated index definitions, simply follow the recommendations in the indexing documentation so those pages are excluded from the index.
There might be situations where you have alternate versions of a page, but you’re unable to use a common suffix to identify them, possibly because you’re porting a legacy website that should not have its paths changed. In that situation, you can specify a primary-language-url for the alternate location, in the metadata of the document.
First, we add that information to the document at /fr/bienvenu in its metadata:
This can also be added to a global metadata sheet, as shown in Bulk Metadata.
**Source:** [https://www.aem.live/docs/setup-customer-sharepoint](https://www.aem.live/docs/setup-customer-sharepoint)
After that, update the source in your site config service via the API accordingly.
In order for the AEM service to access the authored content it needs a couple of information and setup. The AEM service (a cloud function) accesses the MS Graph API on behalf of an application (or configured user). In order to do so, it needs to authenticate first in the context of an Application. This is important because the scopes given to the application define what permission the service has on the MS Graph API. For example, it should be allowed to read and write documents, but not to alter access control.
Go to https://admin.hlx.page/register, enter the github url of the project or the org/site values of your site config.
AEM Content Integration Registration visible in UI
Note that the AEM Content Integration Registration (e34c45c4-0919-43e1-9436-448ad8e81552) application is only needed during registration to verify that the user has read access to the sharepoint. It has the following delegated permissions:
Adding the AEM Content Integration App with application permissions
When logged in the registration portal, the content source that is used by the project needs to be connected to an oauth grant for the AEM Content Integration application. This is needed, so that the system can access the documents in sharepoint and convert them to an internal format (markdown) and store it in Adobe’s storage (S3/R2) for fast delivery.
Same as above, the Enterprise application for the AEM Content Integration (83ab2922-5f11-4e4d-96f3-d1e0ff152856) is not present in Azure yet,In order to add it, use the graph explorer or powershell to add it:
Now the enterprise application AEM Content Integration is visible in azure. But it doesn’t have any Sites.Selected application permissions.
Find the service principal of the Microsoft Graph API (resourceId)
Find the principal of the enterprise application for AEM Content Integration :
Find the service principal of the Microsoft Graph API
Substitute the resourceId with the service principal of the Microsoft Graph API as obtained from the previous step.
The content source can't be found or you don't have permission to access it. Please check that the URL is correct, the app "AEM Content Integration (83ab2922-5f11-4e4d-96f3-d1e0ff152856)" has the right permissions, and that the user is allowed to access it..
**Source:** [https://www.aem.live/docs/go-live-checklist](https://www.aem.live/docs/go-live-checklist)
The go-live checklist is a summary of best practices to consider when launching a website. These steps are generally good practices but have some aspects specific to Adobe Experience Manager.
Make sure that your content and design conforms to the specifications and that you are happy with the website you see on your projects .aem.live domain. This may include checks for specific accessibility and SEO requirements of your project.
Performance Validation
Every AEM project should produce a lighthouse score of 100 for mobile and desktop from Google Pagespeed insights on its respective .aem.live site.
See the document Keeping it 100, Web Performance for more information.
Make sure that all your analytics setup and the rest of your martech stack is firing as expected and visitor data is visible in your reporting dashboards.In any relaunch of a website the analytics instrumentation will change based on loading sequence and performance.
To be able to see performance impact quickly and reliably and to compare before / after launch metrics we recommend instrumenting your website before launch with Real Use Monitoring (RUM), ideally as early as possible. Adding RUM to your existing site is trivial and can give you important operational insights even before launch.
In most migrations there are legacy URLs that are retired. Make sure those are reflected in your redirects spreadsheet (redirects.xlsx in sharepoint or redirects in google), found in your project content folder. Check Google Search Console for the most impactful backlinks (in terms of SEO) to create redirects for.
For most websites with a significant number of pages, a sitemap is desirable. AEM automatically generates sitemaps from the query index. For multilingual sites, adding hreflang to the sitemap ensures that the website correctly targets the appropriate geographic and language audience, which is essential for SEO and prevents issues like duplicate content across different language versions (aka SEO cannibalisation) and improves the search engine's ability to serve the right version of the content to the right users.
Make sure canonical URLs return 2xx HTML response status code (not 3xx or 4xx) and that they are correctly implemented, which is crucial for preventing duplicate content issues across the site. Proper canonicalization helps search engines understand which versions of similar pages to index and display in search results, directly impacting SEO performance.
By default, authors don’t need to be logged in to use AEM Sidekick. If you decide you want to control who can preview and publish documents this can be configured.
CDN Configuration
One of the last steps in a go-live is usually to update your CDN to point to your aem.live endpoint.
You can either use your existing, self-managed CDN or an Adobe-managed CDN included in your license. See here for details on supported CDN options.
Ideally the CDN configuration is tested in a staging environment to make sure everything works as expected, which includes redirects from www to APEX and vice-versa.
Make sure push invalidation is properly set up according to the document Configuring Push Invalidation for BYO Production CDN. Test the setup by publishing a small change and verifying that the change is visible on the production domain.
Notifying the Edge Delivery Services team about your upcoming go-live helps our on-call engineers proactively monitor logs during the event and quickly reach out if any issues arise that we can assist with.
Top-level URL(s) that will be going live on Edge Delivery Services
Validate that the performance is still at a lighthouse score of 100 via pagespeed insights on the production environment. Introducing a CDN layer can have adverse performance effects that are usually visible on the protocol layer. Typical culprits are running HTTP/1.1 or ineffective origin caching as well as bot detection or other libraries injected by the CDN configuration.
If you have an active Google Search Console with your sitemap uploaded, it may be valuable to get a coverage report and make sure that indexing works as expected. The Google Search Console should be monitored for the weeks after a go-live to track the indexing status of new and updated pages, ensuring they are properly recognized by Google. It's crucial to check for total clicks, total impressions, backlinks changes and crawl errors, as these can significantly impact the site's SEO performance and authority.
After a website has been migrated there is usually a set of 404 Not Founds, which should be monitored after the go-live and redirected to popular page URLs. This information can be pulled from your site analytics and the respective Slack bot report. Monitoring this for the weeks after a go-live is recommended.
**Source:** [https://www.aem.live/docs/setup-byo-cdn-push-invalidation](https://www.aem.live/docs/setup-byo-cdn-push-invalidation)
Configuring push invalidation for BYO production CDN
Push invalidation automatically purges content on the customer's production CDN (e.g. www.yourdomain.com), whenever an author publishes content changes or a developer pushes code changes to the main branch (changes on other branches do not trigger push invalidation).
Content is purged by url and by cache tag/key.
Push invalidation is currently supported for CDNs of the following vendors:
Create a Fastly API Token
go to Personal API Tokens,
enter a name (e.g. "Production Site Purge Token"),
check the "Purge select content (purge_select) — Purge by URL or surrogate key" check box,
Push invalidation uses the Akamai Fast Purge API, specifically Delete by URL and Delete by cache tag.
The Fast Purge API credentials consist of
They can be generated by following the instructions at Create an API client with custom permissions.
Create API client
only enterprise plan supports purge-by-tag
Create an API Token
go to API Tokens
enter a token name (e.g. "Production Site Purge Token"),
Permissions: "Zone", "Cache Purge", "Purge"
Note that only sites on the enterprise plan will be surgically purged by url and cache key. A Purge All will be performed instead on non-enterprise sites every time an author publishes a content change.You can validate the credentials with this tool.
NB: CloudFront does NOT support purging by cache tag/key. Purge by cache tag/key always triggers a purge all.
The production CDN needs to send the following opt-in header to the origin in order to enable long cache TTLs:
**Source:** [https://www.aem.live/docs/byo-cdn-cloudflare-worker-setup](https://www.aem.live/docs/byo-cdn-cloudflare-worker-setup)
This setup can be completely done in the browser by using the Cloudflare Dashboard only. If you are already familiar with Cloudflare Workers, Wrangler & GitHub and not afraid of entering commands in a terminal window you might want to follow the instructions for Cloudflare with wrangler instead.
Push invalidation automatically purges content on the customer's production CDN (e.g. www.yourdomain.com), whenever an author publishes content changes.
If you are using the configuration service, see here how to update the CDN configuration.
Otherwise, see here for document-based CDN configuration.
To create an API Token,
Select SSL/TLS from the left pane and Edge Certificates in the dropdown list. On the right side, scroll down to Always Use HTTPS and enable the setting:
Configure Caching
Navigate to Caching → Configuration and adjust following settings:
Caching Level: Standard
Browser Cache TTL: Respect Existing Headers
Create Cache Rules
Next browse to Caching → Cache Rules and create a new cache rule
Note: Enable Origin Cache Control option is only available for enterprise accounts. Free, Pro, and Business customers have this option enabled by default and cannot disable it.
Then: Eligible for cache
Enter a name for the worker (e.g. aem-worker) and click on “Deploy”:
Click on “Deploy”
Confirm with "Save and Deploy"
Note: If you are using the recommended content-security-policy with ‘strict-dynamic’ and (cached) nonce , please make sure to use the latest worker code, which removes the header in 304 responses, to ensure that there is no mismatch between the nonce cached in your site user’s browser and the one returned by the server.
Apply the changes by clicking "Deploy".
Confirm by clicking "Deploy"
Search engines often penalize sites for duplicate content, so it's important to make sure your content is not available on the web elsewhere. Cloudflare, unfortunately, has a default setting that will expose your site on additional network ports. In paid Cloudflare plans you can block traffic on these additional ports. This is a recommended setting for production sites.
**Source:** [https://www.aem.live/docs/byo-cdn-akamai-setup](https://www.aem.live/docs/byo-cdn-akamai-setup)
The following screenshots illustrate how to use the Akamai Property Manager to configure a property to deliver content from AEM using your Akamai CDN setup. Essential settings are marked with a red circle.
Add/Modify Behavior: Caching
This setting will ensure that Akamai authenticates requests from your CDN to the AEM Origin, which validates the token received in the Authorization header.
Do not enable Akamai mPulse Real Usage Monitoring. While the performance impact on most sites is negligible, for sites built for consistent high performance, enabling it will prevent reaching a Lighthouse Score of 100. In AEM, you have a Real Use Monitoring service built-in, so that dual instrumentation will be unnecessary and is strongly discouraged.
Also, do not enable Akamai Bot Manager Premier (also called “Transactional Endpoint Protection”) or similar Web Application Firewall offerings, as they markedly interfere with rendering performance and user experience. Your site on AEM is protected against bot attacks on the backend, so that this performance cost comes with negligible benefit.
AEM push invalidation uses the Akamai Fast Purge API, specifically Delete by URL and Delete by cache tag.
Create API client:
Special Mention - Akamai Edge-Control Headers
AEM uses a fine tuned, production hardened way to supply caching information that applies to the specific CDN, in conjunction with our reliable push invalidation. This allows us to improve cache efficiency and consistency over traditional TTL based approaches.
Every CDN vendor supports a way to directly influence how to instruct caching and we are excited to see standardization efforts like "Targeted Cache Control" (TCC) being on the roadmap for Akamai (see: https://www.akamai.com/blog/news/targeted-cache-control), in the meantime we are using Akamai's long-term supported Edge-Control header.
**Source:** [https://www.aem.live/docs/byo-cdn-fastly-setup](https://www.aem.live/docs/byo-cdn-fastly-setup)
To create a Fastly API Token,
Go to the Fastly Management UI and select Create Service, CDN.
Note: The X-Push-Invalidation: enabled request header enables the push invalidation including long cache TTLs.
Your Fastly setup should not use Fastly’s Next Generation Web Application Firewall for requests that are going against aem.live or any other Edge Delivery Services origin. Enabling WAF with Edge Delivery Services can lead to erroneous content being delivered.
Edge Delivery Services needs no Web Application Firewall, as it is running on hardened, shared, and ultra-scalable infrastructure. Requests that a WAF would typically intercept are terminated in our CDNs.
**Source:** [https://www.aem.live/docs/redirects](https://www.aem.live/docs/redirects)
After making changes to your redirects spreadsheet, you can preview your changes via the sidekick and have your stakeholders check that the redirects are working on your .page preview website before publishing the redirect changes to your production website. See the Sidekick documentation for more information about switching between environments.Redirects take precedence over existing content, which means that if you have an existing page with a given URL, defining a redirect for that same URL will serve the redirect for that page and “hide” the existing page. Conversely if a redirect that has been set up on an existing page is removed, the existing page will be served again, unless the page was unpublished.
However there are some cases where individually managed redirects are inflating the list of redirects, and for practical or perceived initial simplicity reasons it may be compelling to use pattern based redirects. For example, you might want to apply a redirect to all pages under a specific path, regardless of the exact URL. This is where using wildcards in your CDN can be helpful. Wildcards allow you to match multiple URLs under a common path, simplifying the redirection of entire sections of your site.
Example: If you want to redirect all URLs under /old-path/ to /new-path/, including any subpages (e.g., /old-path/page1, /old-path/page2), you can configure a wildcard redirect in your CDN.
Note: The specifics of configuring these redirects depend on the CDN provider you are using. Different vendors may have their own syntax, interface, and capabilities for handling wildcards and advanced redirect rules. Always consult the documentation of your specific CDN for guidance on how to implement wildcard redirects.
Site Migrations and SEO
When migrating your site to AEM Edge Delivery Services, this may necessitate some changes to the URLs your site uses. This can have an impact on SEO, so it is important that you plan for this carefully to avoid any disruption. We recommend the following steps to handle the most common scenarios:
If the change to URLs follows a common pattern, for example, removing .html from all urls, set this up as a wildcard redirect at your CDN
**Source:** [https://www.aem.live/docs/auditlog](https://www.aem.live/docs/auditlog)
Here are some examples of how common operations triggered via Sidekick will be reflected in the audit log:
Edge Delivery Services audit logs are kept indefinitely, or as long as the customer wants to keep them.
**Source:** [https://www.aem.live/docs/sidekick-security](https://www.aem.live/docs/sidekick-security)
AEM Sidekick Security
This page describes security aspects of the Sidekick such as required browser permissions, privacy and network requests being made during operation.
The manifest file on GitHub (open source)
The Sidekick requires the following browser permissions as defined in its manifest file to function as expected:
The Sidekick collects user activity allowing Adobe to:
The Sidekick performs HTTPS request to the following hosts:
You can restrict the Sidekick’s access to certain hosts for all users in your enterprise by defining the runtime_blocked_hosts and runtime_allowed_hosts settings in your enterprise’s Chrome profile. See Google’s documentation on Managing Extensions in Your Enterprise for more information.
This would prevent the Sidekick extension from interacting with any URL matching https://intranet.example.com/* or https://extranet.example.com/*.
This would prevent the Sidekick extension from interacting with any URL, except the ones matching a pattern defined in runtime_allowed_hosts. This example uses a combination of the host_permissions in the manifest file and the list of URLs from the chapter Network Requests above to ensure maximum functionality and an optimal user experience.
The Sidekick’s entire source code is publicly available and – like all of AEM – subject to regular audits performed by 3rd party security researchers. Reports can be shared with customers and prospects under NDA.
**Source:** [https://www.aem.live/developer/sidekick-development](https://www.aem.live/developer/sidekick-development)
Extending the Sidekick
The goal of this document is to explain how developers can interact with the sidekick, and how it can be customized at a project level.
The sidekick emits the following events:
(object) config: The sidekick configuration
In your project code (e.g. in /scripts/scripts.js), you can react to sidekick events as follows (replace foo with the name of the event you want to listen for):
You can customize the sidekick for your project. You can add a /tools/sidekick/config.json configuration file to your project's GitHub repository or use the configuration service.
Note: The following host properties are optional in the sidekick configuration and should only be used to explicitly override the CDN settings in your site configuration:
host (string) The host name of the production website (overrides cdn.prod.host)
previewHost (string) The host name of the preview environment (overrides cdn.preview.host, defaults to *.aem.page)
liveHost (string) The host name of the live environment (overrides cdn.live.host, defaults to *.aem.live)
reviewHost (string) The host name of the review environment (overrides cdn.review.host, defaults to *.aem.reviews)
Plugins allow you to add custom functionality to the sidekick, enhancing your users’ experience.
id (string) is mandatory and must be unique within a sidekick configuration.
environments (string[]) specifies where the plugin should appear (dev, edit, admin, preview, live, or prod).
Alternatively, you can specify the name of an event to be fired when the plugin button is clicked. This allows the execution of custom JavaScript code in the context of your page by listening for the event on the sidekick element. Custom events will have a custom: prefix. For your convenience, the custom event dispatched contains a copy of the current sidekick state.
Note: Event-based plugins can only be used in the following environments: Development, Preview, Live and Production. Executing custom code is not possible in Edit or Admin.
A theme query parameter is appended to the URL to style the iframe in line with the current sidekick theme. If no background color is set on the content’s body, it will inherit the popover’s translucent background.
Badges allow you to add labels to the sidekick under certain conditions. They will be rendered on the right hand side of the toolbar. Badges have a merley decorative purpose and can’t be clicked.
The following example adds a “Stage” badge to the sidekick in the preview environment:
If your project does not use SharePoint or Google Drive as content source, you can tell the sidekick how to link to your custom editing environment when the user clicks Edit.
You can specify a special view for the sidekick to redirect to when the current tab’s URL matches a certain pattern. This can help you provide a seamless user experience across different media types, and also enables the execution of custom code (event-based plugins). The original resource URL will be available in a url query parameter.
The properties path and viewer are mandatory. Optionally, you can specify a title that will be shown at the top, and you can provide localized titles in a titleI18n object:
At the path specified by viewer, add an HTML file to your GitHub repository, for example:
The following workflows are designed for detached sidekick development to prevent unintentional disruptions for the authors on your production site:
If your site’s configuration is stored in the Configuration Service, you can use temporary site copies for sidekick development:
Open the preview URL for site1-dev in your browser: https://main--site1-dev--org.aem.page.
Make your desired changes to the sidekick object in the site1-dev configuration.
When done, copy the sidekick object from site1-dev to the site1 configuration to roll your changes out to all authors.
Note: When using the sidekick in an editor environment (Google Drive or Microsoft Sharepoint), it will load the config from the original site by default. If you want the sidekick to let you choose which configuration to load, first add the new site to your sidekick from the preview or live URL. Now the sidekick will display a picker with all matching sites.
Using a Repository Branch
If your site’s configuration is not stored in the Configuration Service, you can use a branch in GitHub for sidekick development:
On your site’s GitHub repository, create a branch from main. For this example, we’ll use dev as the branch name.
Open the preview URL for the dev branch in your browser: https://dev--site1--org.aem.page.
Open or create the following file in your repository: /tools/sidekick/config.json.
Make your desired changes to the sidekick configuration file and push changes to the dev branch.
When done, create a pull request and merge the changes to the main branch of your repository.
Caution: Never commit directly to the main branch in your original repository. Always create a branch and ask for a review of your changes via pull request before merging into main.
**Source:** [https://www.aem.live/docs/sidekick-library](https://www.aem.live/docs/sidekick-library)
What is the Sidekick Library?
The Sidekick Library is an extension for the AEM Sidekick that enables developers to create UI-driven tooling for content authors. It includes a built-in blocks plugin that can display a list of all blocks to authors in an intuitive manner, removing the need for authors to remember or search for every variation of a block. Developers can also write their own plugins for the sidekick library.
How to use the Sidekick Library?
The steps below detail how to setup the sidekick library and configure the blocks plugin.
The sidekick library is populated with your plugins and plugin content using a sheet.
Blocks Plugin
The Sidekick library comes with a blocks plugin.
Blocks Plugin Setup
To generate content for the blocks plugin, you need to prepare a separate Word document for each block you want to include.
> Since the example blocks are being published you should use bulk metadata to exclude the content inside of /tools/** from being indexed.
Library Metadata
The blocks plugins supports a special type of block called library metadata which provides a way for developers to tell the blocks plugin some information about the block or how it should be rendered.
Supported library metadata options
Default Library metadata vs Library metadata
There are two types of library metadata. Library metadata that lives within a section containing the block, or default library metadata that applies to the document as a whole and lives in a section on it's own (a block called library metadata as the only child in a section).
Let's take an example of a hero block that has 5 variants. Suppose you want to add the same description for each variation of the block, rather than duplicating the library metadata with the description into each section containing the variations. You could instead use default library metadata to apply the same description to every variation of the block. If you decide that one variation actually needs a slightly different description you could add library metadata to the section containing the variation and it would override the default library metadata description when it's rendered within the blocks plugin.
Authoring block names and descriptions using Library Metadata
By default the block name (with variation) will be used to render the item in the blocks plugin. For example, if the name of the block is columns (center, background) then that name will be used as the label when it’s rendered in the blocks plugin. This can be customized by creating a library metadata section within the same section as the block. Library metadata can also be used to author a description of the block as well as adding searchTags to include an alias for the block when using the search feature.
Example block with custom name and description
Autoblocks and Default Content
The blocks plugin is capable of rendering default content and autoblocks. In order to achieve this, it is necessary to place your default content or autoblock within a dedicated section, which should include a library metadata table defining a name property, as previously described. If no name is specified in the library metadata, the item will be labeled as "Unnamed Item."
Blocks composed of content in subsequent sections
There are situations where developers may want a block to consist of content from subsequent sections. This pattern is discouraged for reasons stated here, but if you choose to use it the blocks plugin can render these items using the include next sections property in library metadata.
Templates are a way to group an entire document into a single element in the sidekick library. To mark a document as a template set type to template in default library metadata.
> Important, the library metadata needs to be in it's own section and be the only child to be considered default library metadata.
Supporting metadata is also desirable for templates. To add a metadata table to the template you can use a Page metadata block.
When the template is copied a metadata with the values will be added along with the content to the clipboard.
Sidekick plugin setup
Since the sidekick library is hosted on the same origin as the content, a static HTML page needs to be created to load and configure the content.
In the code above we load the sidekick library from aem.live and then create a custom sidekick-library element and add it to the page. The sidekick-library element accepts a config object that is required to configure the sidekick library.
The blocks plugin supports the following configuration properties that can be set using the plugins object.
Blocks plugin configuration parameters
You can customize the table header background and foreground color when pasting a block, section metadata or metadata that was copied from the blocks plugin.
These values can be overridden using library metadata.
> Depending on the system color scheme selected for the users computer (dark mode), Word may alter the chosen colors in an attempt to improve accessibility.
In some cases merging two block libraries may be desirable. When an extended library is defined the sidekick library application will merge the base library and the extended library together into a single library list for authors.
> The Access-Control-Allow-Origin headers will need to be set on the library.json and blocks of the extended library in order for them to load in the sidekick library. See Custom HTTP Response Headers for more info.
> Due to same-origin policies enforced by browsers on iframes a preview of an extended block cannot be loaded at this time.
Sidekick config.json setup
Next, in order for the sidekick library to appear in the sidekick a config file needs to be created at tools/sidekick/config.json. This config file needs to be created in the code bus and should be checked into github.
The url property in the plugin configuration indicates the location from which the sidekick should load the plugin. This should point to the library.html file we previously created.
> The sidekick config must be checked into the main branch in order to for the plugin to appear in the sidekick.
> If the tools/sidekick/config.json file does not exist in your github repository, it must be created. For more information on sidekick plugin configuration options, see the docs.
Considerations when building blocks for the library
The sidekick library renders blocks by first fetching the plain.html rendition of the the block and then strips it of any other blocks in the content (for example if there are multiple variations of a block in the response). It then requests the same page (without .plain.html) and replaces the main element with the stripped block and loads the entire document into an iframe using the srcdoc attribute.
Since the block is loaded in an iframe using the srcdoc attribute, the instance of the window.location object used by your sites code will not contain the typical values you would expect to see.
For this reason, if your block requires use of the window.location object we recommend adding the following functions to your scripts.js file and importing them into your function for use.
Checking for the presence of the sidekick library
Sometimes you may want to know if the page or the block is running in the sidekick library. To do this there are a couple of options.
Developing a plugin is similar to constructing a block in AEM. Once a user tries to load the plugin, the sidekick library will trigger the decorate() method on your plugin. This method receives the container to render the plugin in and any data that is included in the plugins sheet.
The default export from a plugin allows authors to customize the plugin name displayed in the header upon loading, as well as activate the search functionality within the sidekick library.
Plugin web components
Plugin authors can utilize a select set of web components from Spectrum when building a custom plugin.
The following components from Spectrum are available
Plugin authors can dispatch events from their plugin to the parent sidekick library in order to display a loader or to show a toast message.
Plugin API Example
**Source:** [https://www.aem.live/docs/faq](https://www.aem.live/docs/faq)
Why was this site renamed from Helix to Franklin to Edge Delivery Services?
Franklin and Helix were internal project names for the Adobe Experience Manager engineering team’s initiative to develop an innovative publishing and delivery service situated at the edge. Between 2022 and 2023, Adobe worked with select clients to test these capabilities, focusing on integrating diverse content sources and delivering web experiences that surpass the performance of a significant majority.
In October 2023, Adobe officially introduced Edge Delivery Services and document-based authoring as part of Adobe Experience Manager, marking the transition from the Franklin and Helix project names to a fully integrated solution.
What makes Edge Delivery Services websites so fast?
Edge Delivery Services optimizes web performance through a combination of caching and real-time content rendering at the edge. To maintain high speed, it continuously monitors site performance using strictly necessary operational telemetry and enforces automated performance checks via Google PageSpeed Insights on every code update (pull request).
Is Edge Delivery Services a Static Site Generator (SSG)?
No, Edge Delivery Services is not a Static Site Generator. Unlike traditional SSGs that require a full rebuild to update content, Edge Delivery Services dynamically renders and serves content at the edge, enabling instant updates without the need for a time-consuming build process.
Is Edge Delivery Services a Headless CMS, like AEM?
Edge Delivery Services is not a Headless CMS but rather the “head,” leveraging a CMS or document-based authoring as the content source.
While Edge Delivery Services primarily delivers fast-loading HTML experiences, it can also provide structured content in JSON format for applications that require it. Content authored in Edge Delivery Services can be aggregated into indices and delivered as JSON, making it compatible with headless implementations.
What is a good Lighthouse score?
Every Edge Delivery Services site can and should achieve a Lighthouse score of 100. AEM’s strictly necessary operational telemetry provides insights into actual site performance over time, allowing you to assess whether your site continues to meet that score.
Want to keep your Lighthouse score at 100? Check out the Keeping It 100 guide.
aem.page provides an up-to-date preview of unpublished content. aem.live serves published content and is used as the origin for your production CDN.
Take a look at our architecture diagram for more information on how content gets published.
Edge Delivery Services supports all modern browsers, including Google Chrome, Apple Safari, and Microsoft Edge. Internet Explorer (IE) is not supported.
How much does Edge Delivery Services cost?
Does Edge Delivery Services require an Enterprise license?
Edge Delivery Services is part of AEM Sites and requires an AEM Sites license. Development access to the service does not require a separate license and is available for free.
Can I run Edge Delivery Services without full AEM Sites?
Yes, Edge Delivery Services can run independently without requiring an AEM Sites author or publish instance. If you want to use AEM authoring, an AEM Sites author instance is required.
Is Edge Delivery Services better for large or small sites?
Edge Delivery Services is a great solution for both small and large sites. Small sites benefit from its ease of setup, while large sites can take advantage of its ability to support many authors, frequent updates, and high traffic.
How big are the biggest Edge Delivery Services sites?
Is Edge Delivery Services a good solution for landing pages?
Yes, Edge Delivery Services is well-suited for landing pages. Adobe uses pages.adobe.com to manage hundreds of landing pages, each owned and maintained by independent teams.
Is Edge Delivery Services a good fit for sites with dozens or hundreds of local markets, languages, or sub-brands?
Yes, Edge Delivery Services is a great solution for global enterprises managing multiple markets, languages, and sub-brands. It supports centralized content management and inheritance, enabling global updates while allowing local teams to make adjustments. Content rollout and localization can be integrated with existing translation memory systems in content sources like SharePoint and Google Drive.
Is Edge Delivery Services a suitable platform for small e-commerce websites?
Yes, Edge Delivery Services can be used for e-commerce websites. It supports integration with payment services like Stripe and Square.
Can Edge Delivery Services generate content for external platforms like GitBook?
Yes, but Edge Delivery Services no longer natively supports Markdown documents in GitHub as a content source. To publish content from GitHub, Markdown documents must first be copied to a supported authoring environment where they can be previewed and published.
Does Edge Delivery Services support content approval workflows?
Edge Delivery Services does not provide built-in content approval workflows, but instead delegates workflow management to the content source.
Edge Delivery Services allows customers to use their own CDN to deliver content under their own domains or subdomains (BYO Production CDN).
Sites can be created with different code repositories or via repoless and point the site configuration to different CDN endpoints for Push Invalidation.
Learn more on the BYO CDN Setup page.
How does Edge Delivery Services handle inheritance and rollouts across multiple sites?
Edge Delivery Services has a broad range of facilities for centralized content and code management, allowing updates to be shared across multiple sites while still allowing for localized adjustments. AEM Universal Editor or Document Authoring have out of the box solutions for existing inheritance and content rollouts.
Can Edge Delivery Services be used along other CMS platforms on the same site?
Yes, Edge Delivery Services can be used alongside other CMS platforms when managed at the CDN tier. Many large, mature sites combine content from multiple origins, allowing different sections to be powered by separate AEM projects or external CMS solutions.
It helps to have top-level paths (sections of a site) be delivered from the same CMS so that CDN configurations will be easier to manage as opposed to a random list of URLs with no common parent in the URL.
Can Edge Delivery Services support secure content access for intranets, portals, or closed user groups?
Yes, Edge Delivery Services can support secure content access for intranets, portals, and closed user groups. Customer-specific authentication and authorization are typically enforced at the CDN tier, where all CDN vendors offer a broad set of integrations with existing identity providers.
In Edge Delivery Services, access to .page and .live origins can be restricted (independently), ensuring that content is only accessible through the CDN with the necessary authentication in place.
How does Edge Delivery Services handle access control and multi-tenant authoring?
Edge Delivery Services follows the access control model of its connected content source. For example, SharePoint and Google Drive provide robust enterprise-level permissions that users and system administrators are already familiar with. For partial page access control, fragments are recommended to isolate content with different access control into separate documents. Separate teams can control their own content within their assigned folders, ensuring isolated workflows.
Access to specific blocks can be restricted (via the content library) and blocks can also be configured to prevent rendering in specific sections of a site.
The client (browser) requests data from backend systems. If authentication is required, a middleware layer running on the Edge/CDN (e.g., Edge Workers) acts as an intermediary, managing authentication and facilitating communication between the client and backend.
Browser → Middleware (Edge Worker) → Backend
Does Edge Delivery Services support server-side customizations or includes (SSI/ESI)?
Edge Delivery Services renders semantic markup (excluding fragments) on the server-side, but it does not support any server-side customizations or includes. Instead, it generates optimized, static markup that can be adjusted on the client side for styling, functionality, and personalization. While some customer CDNs support ESI, it generally introduces performance and complexity trade-offs and we have found no benefit to metrics like Largest Contentful Paint (LCP) or Cumulative Layout Shift (CLS) when using ESI over client-side includes. Because of this, we do not recommend using ESI and advise against it.
How does Edge Delivery Services support taxonomy management?
Edge Delivery Services supports taxonomy management through structured metadata and hierarchical tagging. Common approaches include managing taxonomies in spreadsheets or documents to define hierarchical structures and adding tags to metadata of pages or content fragments.
External taxonomy systems or APIs can be embedded into the authoring environment as a Sidekick plugin. AI-based tagging can be implemented as an authoring plugin or directly in the delivery tier, depending on the use case.
How does Edge Delivery Services handle caching and content invalidation?
Edge Delivery Services uses caching to optimize performance while ensuring content updates are reflected quickly. When authors publish changes, the system automatically, and surgically purges cached content at multiple levels, including the CDN.
For BYO CDNs (including Cloudflare, Fastly, Akamai, and CloudFront), push invalidation can be enabled to purge content by URL and cache key whenever updates are published. Learn more on the Configuring Push Invalidation page.
You can use the CDN Setup tool to confirm that your CDN automatically purges outdated content when content changes are published. This tool validates your project’s vendor-specific properties and credentials.
See Best Practices and Anatomy of a Project for more details.
Is Edge Delivery Services down right now?
Edge Delivery Services is probably not down, but you can always check Adobe’s status page for real-time service updates and interruption notifications.
Indexing and SEO
What are the best practices for search engine optimization (SEO)?
Add metadata to your pages using the metadata block and metadata sheet to improve indexing. Ensure your site achieves strong Core Web Vitals (CWV) scores for fast loading and a smooth user experience. Use clear headings, alt text for images, and descriptive URLs.
How do I optimize Edge Delivery Services pages for social media sharing on platforms like Facebook and Twitter?
Set a default placeholder image to ensure consistent previews. Use the metadata block and metadata sheet to define the title, description, and other page metadata.
Yes, Edge Delivery Services can generate an index (or multiple indices) of pages within a folder, storing the data in a spreadsheet and serving it as JSON.
How does Google index Edge Delivery Services pages?
Search engines, like Google, index Edge Delivery Services pages the same way they index traditional web pages by crawling the published content and evaluating metadata, page structure, and performance metrics like Core Web Vitals.
Can Google index Edge Delivery Services pages that load content fragments dynamically?
Yes, Google can index Edge Delivery Services pages that load content fragments dynamically via the fetch API. However, to avoid duplicate indexing issues, it is recommended to disable indexing for fragment URLs using the noindex directive in metadata.
Edge Delivery Services supports querying specific fields within a single index and suggests creating additional indexes when needed. Best practices include creating one index per language and additional dedicated indexes for common queries.
Edge Delivery Services supports indexing parts of the site by configuring an index at that path of the content or via a custom index configuration.
The indexing service captures the non-decorated DOM from the initial page load, before JavaScript executes. Content added dynamically won’t be indexed by default, but can be included by combining it with the indexing sheet via formulas or API calls depending on where the data needs to surface.
To prevent individual pages from being indexed, add the noindex directive in the metadata block. To exclude larger site sections, configure exclusions in the bulk metadata sheet.
What strategies should I use to manage URLs and prevent SEO ranking loss?
Does Edge Delivery Services support RSS feeds?
Edge Delivery Services does not have built-in RSS or Atom feed publishing. However, the Sidekick is extensible and it can be configured to generate Atom feeds for RSS readers from a page index.
What localization (l10n) capabilities does Edge Delivery Services support?
Edge Delivery Services supports localization by leveraging the built-in translation tools of your chosen content source. This allows customers to use familiar systems for content authoring and translation.
What are the best practices for handling localized or country-specific sites?
Does Edge Delivery Services support HREFLang?
Yes, Edge Delivery Services supports HREFLang as part of sitemaps (sitemap.xml). It can be configured to reference different locales where needed.
Performance and Monitoring
Operational Telemetry is a service that measures how fast your site loads for actual visitors, what errors users experience, and where interactions are broken. Unlike lab-based tools like Lighthouse, Operational telemetry provides more accurate real-world performance data.
To enable operational telemetry, contact the AEM engineering team. They will open a pull request (PR) with the necessary JavaScript. All operational telemetry data is GDPR-compliant and does not collect personally identifiable information (PII).
Learn more on the Developing Real Use Monitoring page.
Edge Delivery Services supports tracking page KPIs through operational telemetry. Operational telemetry collection can be extended with custom checkpoints to track specific conversion events. Note that operational telemetry only samples visitor interactions and does not track individual users.
Learn more on the Developing Real Use Monitoring: Checkpoints page.
Edge Delivery Services is agnostic to whichever authoring source you would like to use, but we recommend picking the right one for the actual authors who need to update content every day.
Where can I find the Edge Delivery Services URL of my document?
To find the URL of your document, open the Sidekick in your content editor and select “Preview”. This will take you to the preview URL of your page.
Edge Delivery Services supports content editing in Microsoft Word and Excel, Google Docs and Sheets, AEM’s Universal Editor, as well as custom authoring environments.
To publish a page in Edge Delivery Services, open the Sidekick on the preview URL of your page and select “Publish”. This will make the page publicly available on your site.
Learn more on the Preview and Publish Content page.
Why are my changes in Microsoft Word not appearing on my site after previewing or publishing?
The SharePoint API can sometimes introduce a delay of up to three minutes before changes made in Microsoft Word become visible in Edge Delivery Services. To ensure changes appear immediately, manually save the document using CMD+S (Mac) or CTRL+S (Windows) before previewing and publishing.
You can also click on ‘Update’ in the Sidekick on the Preview page to get the latest saved content.
To unpublish a page, first delete the corresponding source document. Then, open the Sidekick on the preview site. The “Unpublish” button will now appear, allowing you to remove the page from the public site while keeping it available in preview.
To delete a page, first delete the corresponding source document. Then, open the Sidekick on the preview site. The “Delete” button will now appear, allowing you to remove the page from both the public site and the preview environment.
New documents do not automatically generate a preview URL. To create one, open the Sidekick in the editor and click “Preview”.
How do I schedule content publication in Edge Delivery Services?
Edge Delivery Services allows you to schedule API-driven publication using spreadsheets. For large-scale launches, such as a rebrand or product launch, best practices include using GitHub branches or forks and copies of large content folders to coordinate and time content changes effectively.
Edge Delivery Services has APIs to support the concept of Snapshots that allow customers to Add/Remove individual pages to a collection called a “Snapshot Manifest”. The Snapshot can then be reviewed and approved/rejected. Publishing a Snapshot will take everything from the Snapshot Manifest and publish it at the same time immediately. You can use the Snapshot Admin tool to manage Snapshots.
First, ensure that any recent changes to the content have been saved in your authoring environment. Then, open the Sidekick and select “Preview” to refresh the preview of your page. You can also click on ‘Update’ on the Sidekick if you are in the Preview URL
How does Edge Delivery Services generate URLs? What characters are allowed?
Edge Delivery Services constructs page URLs based on document and folder names. To maintain clean and easy-to-type URLs, only lowercase letters (a-z), numbers (0-9), and dashes (-) are allowed. Unsupported characters are automatically transformed.
Does Edge Delivery Services have a WYSIWYG editor for in-browser editing?
Edge Delivery Services supports multiple authoring environments, including AEM Universal Editor, Adobe Document Authoring, and commonly used existing tools like Microsoft Word, Excel, Google Docs, and Google Sheets.
Does Edge Delivery Services support inline text styling within a paragraph?
Edge Delivery Services supports inline text styling with semantic formatting: bold, italic, underline, strikethrough, subscript, superscript, and code. Colors and font settings (like font face and size) must be defined explicitly in CSS.
Edge Delivery Services automatically optimizes image sizes, so authors do not need to manually set dimensions. Developers can use existing helper functions to get the appropriate size of the image they want to use.
Other authoring environments may have different interfaces for adding alt text. It’s important to ensure alt text is properly set wherever content is authored to improve accessibility and SEO of your page.
Can a metadata block be used as the first block in a document?
Yes, a metadata block can be placed anywhere in a document, including as the first block.
What is the metadata spreadsheet and how is it used?
The metadata spreadsheet is a centralized sheet for managing site-wide metadata for SEO. It allows you to set default metadata, exclude specific page sections from indexing, and more.
Learn more on the Bulk Metadata page.
Edge Delivery Services automatically generates id attributes for all headings. For example, a heading titled “This is a Title” will be accessible via the URL fragment #this-is-a-title, eliminating the need to manually add anchors.
Does Edge Delivery Services support videos as source content?
Yes, short videos can be uploaded to your authoring environment. After previewing and publishing the video with Sidekick, a URL will be generated that can be referenced in the source document.
Yes, the embed block supports embedding content from external sources, including iframes, such as YouTube videos.
Many external tools, such as DiffSite, can also be used to compare differences between the preview and publish states of a page.
Does Edge Delivery Services offer content reporting or a search-and-replace feature?
Edge Delivery Services has APIs and tools like Image Audit or Page Status to help with common content reporting needs in addition to what the source content repositories provide.
How are internal and external links handled in Edge Delivery Services?
What is the AEM Sidekick?
The AEM Sidekick is a browser extension that provides editing, previewing, and publishing capabilities for your Edge Delivery Services site. It can support multiple projects.
How do I install the Sidekick?
The Sidekick is available for Chrome-based browsers (including Microsoft Edge) from the Chrome web store.
What should I do if my Sidekick isn’t working?
If your Sidekick is not functioning, we recommend you reinstall the Sidekick for your project by visiting the AEM Sidekick Configurator.
With a Dynamic Media license, can authors select different asset variations in the Sidekick?
Currently, the Asset Selector Sidekick Plugin does not provide an option to pick a variation. If the customer has a Dynamic Media (DM) license with DM Open API access, they can configure the Asset Selector to copy the DM asset link as a reference. Authors can then modify the copied DM URL by appending query parameters to retrieve different asset variations.
Development and Deployment
How do I set up a local development environment?
To develop Edge Delivery Services pages locally, install Node.js and run npm install -g @adobe/aem-cli && aem up. This starts a local server that updates with code changes in real time and uses production content for accurate previews.
Edge Delivery Services is fully serverless, eliminating the need for dedicated environments. To try new functionality, simply create a branch in your GitHub repository.
How does Edge Delivery Services handle concurrent code editing by multiple developers?
As long as you are developing locally, your code remains on your machine and only content is shared. When you commit code to a GitHub repository, Git manages version control and merges changes from multiple developers.
Does Edge Delivery Services support private GitHub repositories?
Yes, Edge Delivery Services supports private GitHub repositories. As with public repositories, The AEM Code Sync bot needs to be installed on the repository.
Can Edge Delivery Services integrate with GitHub Enterprise?
Edge Delivery Services supports GitHub Enterprise Cloud but does not support GitHub Enterprise Server (because Edge Delivery Services requires access to a public GitHub API).
Does Edge Delivery Services support alternative Git repository hosts, like Bitbucket?
A GitHub repository is mandatory. However, since Git is a distributed version control system (DVCS), you can host your codebase on other platforms (like Bitbucket) and push branches to GitHub for deployment.Note: There is now the new BYOGIT feature as early access technology. It allows to directly use a bitbucket, gitlab and soon azure repos repository directly with EDS. see https://www.aem.live/developer/byo-git
fstab.yaml is a configuration file that defines the content source for your site. It specifies a mountpoint using sharing URLs from your authoring environment, determining where Edge Delivery Services pulls content from. Its format is similar to an fstab file in UNIX.
With Helix 5, fstab.yaml is no longer required. Content sources can now be configured via the Configuration Service API, allowing the same code repository can be reused across multiple sites in a repoless fashion.
Does Edge Delivery Services support multiple content mountpoints in fstab.yaml?
When code is pushed to any branch in GitHub, the AEM Code Sync app automatically syncs it to the Codebus, making it available on both .page and .live.
How is continuous integration and deployment (CI/CD) configured?
Edge Delivery Services works in a scaled trunk-based development model. Since there is no build process required, it makes developer velocity much faster. Customers can add their internal processes via Github Actions and Workflows to also trigger other processes and build checks needed during Pull Requests.
How does Edge Delivery Services handle caching for head.html updates? Do I need to clear the cache manually?
When you update head.html, Edge Delivery Services automatically purges the cache for all HTML pages, ensuring that changes take effect immediately. Manual cache clearing is not required.
Do I need to protect against DOS attacks with a WAF on our CDN?
Edge Delivery Services origins are designed to withstand common internet attacks, including typical scripted and DOS attacks. The AEM security and operations team continuously implements countermeasures to mitigate risks. Because your CDN may also connect to other origins beyond Edge Delivery Services, you may still want to use WAF services to protect those additional origins.
Should redirects be managed on the CDN, or does Edge Delivery Services handle them?
Edge Delivery Services supports redirect management through a “redirects” spreadsheet stored in the root folder of your project in your authoring environment. This allows for centralized control of URL redirects without requiring CDN-level configuration.
When an asset is previewed, it is uploaded to the media bus, which stores it immutably. To maintain a human-readable filename, the asset can still be addressed by its original name. During delivery, the request is redirected (via 301) to the immutable media bus URL for retrieval.
Edge Delivery Services only supports 301 (permanently moved) redirects through the redirects spreadsheet file to optimize caching. Other kinds of redirects must be configured at the CDN level.
Edge Delivery Services subdomains follow the format branch--repo--owner. The combined length of the branch, repository, and owner name (including the two required separators [--]) cannot exceed 63 characters. This is a DNS limitation and is not specific to Edge Delivery Services.
Edge Delivery Services does not process cookies on the server side. We recommend using URL parameters to store application state.
Content Blocks
Does Edge Delivery Services have something like components?
Yes, Edge Delivery Services uses “blocks” as our components. A block is a reusable section of a page. By default, Edge Delivery Services displays document content as-is, but blocks allow for specific functionality and styling.
How do I create a block?
To create a block, place your content inside a table with a header row containing the block name. Edge Delivery Services will recognize this structure and apply the corresponding functionality or styling.
Learn more on the Exploring Blocks: How They Work page.
Where can I find a list of available blocks?
Available blocks vary by project. Many projects maintain a block inventory (or “kitchen sink”) page that showcases the available blocks and their structure.
Edge Delivery Services boiler plate code includes a set of commonly used blocks. Apart from that there is Block Collection boilerplate that includes additional blocks .
Learn more about Block Collection
Does Edge Delivery Services support nested blocks?
No, Edge Delivery Services does not support nested blocks to keep authoring simple and manageable. However, nested structures can be achieved in other author-friendly ways. For example, nested fragments can be used for more complex layouts.
To implement a design system in Edge Delivery Services, leverage (or expand) the existing CSS variables for design tokens and ensure blocks are reusable across pages.
How can I reuse content across multiple pages in Edge Delivery Services, like AEM’s Content and Experience Fragments?
Edge Delivery Services supports centrally managed content reuse through the fragment block, which embeds content from one page into another. Edge Delivery Services loads headers and footers as fragments by default.
What is the equivalent of Core Components in Edge Delivery Services?
The Block Collection serves as the equivalent of Core Components in Edge Delivery Services. The collection provides a set of pre-built, extensible blocks designed for modern websites, providing an easily customizable foundation for any project.
How do blocks compare to Web Components?
Blocks are a core feature of Edge Delivery Services, integrating seamlessly with minimal setup. They are easy to author, optimized for performance, and are built using standard HTML, CSS, and JavaScript.
Web Components provide encapsulation and cross-platform reusability, making them valuable for design systems. However, they require careful lifecycle and performance management to avoid unnecessary overhead.
Are Web Components recommended for Edge Delivery Services projects?
Web Components can be used in Edge Delivery Services projects, but they are not the default recommendation. While they offer modularity and reusability, they require careful optimization to avoid impacting performance.
Learn more on the Web Components page.
Can I integrate Web Components from a design system into Edge Delivery Services?
Yes, Edge Delivery Services supports integrating Web Components from design systems. Web Components should be initialized within blocks and only loaded when needed to avoid unnecessary overhead.
Edge Delivery Services does not require a specific frontend framework, but supports integration with frameworks like React, Angular, Vue, and Svelte. The recommended approach is to use technologies such as React Portals or Web Components within application-centric blocks while keeping simpler blocks in plain CSS and JavaScript for optimal web performance.
When loading external components that are render-critical for the largest contentful paint (LCP), make sure to load them from the same host as the main website, so you avoid the performance penalty of a second DNS lookup and TLS handshake. This can be accomplished by mapping the path in the CDN or pushing the required components into the site's git repository.
Yes, CSS frameworks like Less, PostCSS, and TailwindCSS can be used in Edge Delivery Services. CSS frameworks should be used thoughtfully, balancing page speed with layout shifts while keeping styling readable and maintainable. Usually, using any framework also adds a build step that can slow down development velocity and is not as instantaneous anymore which is a big advantage of going without a framework.
Does Edge Delivery Services support server-side rendering (SSR) for Lit-based Web Components?
No, Edge Delivery Services does not support any server-side customizations. Instead, it generates optimized, semantic markup that can be decorated on the client side for styling, functionality, and personalization. This ensures flexibility while maintaining optimized performance.
Integrations and Third-Party Tools
What are the performance considerations when integrating with third-party tools?
Integrating third-party tools can impact performance, especially if they block rendering or delay LCP (Largest Contentful Paint). Avoid adding scripts in <head.html> to keep the critical rendering path clear. Instead, load scripts only when needed using loadScript() within specific blocks or IntersectionObserver to defer execution. Defer non-essential integrations and tools, such as analytics or tag managers, until after page load to reduce Total Blocking Time (TBT) and improve user experience.
Want to maintain high performance? Check out the Keeping It 100 guide.
Yes, Edge Delivery Services can be seamlessly integrated. Edge Delivery Services is a part of AEM Sites!
Yes, Edge Delivery Services is compatible with Adobe Target. Learn more at the Configuring Adobe Target Integration page.
Additionally, Edge Delivery Services features a built-in experimentation framework that enables quick test creation, execution without performance impact, and fast deployment of test winners.
Yes, Adobe Analytics can be integrated with Edge Delivery Services just like on any other website.
Yes, Adobe Launch can be integrated with Edge Delivery Services just like on any other website.
Yes, with a valid AEM Forms license, Edge Delivery Services supports AEM Forms through the Adaptive Forms Block, allowing you to create, style, and manage forms within your site.
Yes, Marketo forms can be embedded in Edge Delivery Services pages using the Marketo Forms API or iframe embed codes.
No, Edge Delivery Services does not include a default forms capability that sends emails on submission. However, you can integrate services like AEM Forms, Adobe Campaign, Workfront, or external email APIs to handle form submissions and email notifications.
Yes, AEM Assets can be used in Edge Delivery Services by configuring the AEM Assets Sidekick plugin. This allows authors to access and use AEM Assets within SharePoint or Google Docs.
Does Edge Delivery Services support Cloudflare?
Yes, you can run a Cloudflare CDN in front of Edge Delivery Services to add a custom domain or integrate Edge Delivery Services into an existing site.
Yes, you can run a Fastly CDN in front of Edge Delivery Services to add a custom domain or integrate Edge Delivery Services into an existing site.
Yes, you can run a Cloudfront CDN in front of Edge Delivery Services to add a custom domain or integrate Edge Delivery Services into an existing site.
Does Edge Delivery Services support Akamai?
Yes, you can run an Akamai CDN in front of Edge Delivery Services to add a custom domain or integrate Edge Delivery Services into an existing site.
Yes, Google Tag Manager can be integrated with Edge Delivery Services just like on any other website.
Yes, OneTrust can be integrated with Edge Delivery Services just like on any other website.
Yes, third-party translation tools can be integrated into Edge Delivery Services. While Edge Delivery Services natively supports translation features within content sources, additional translation services can be incorporated at the content source or CDN tier for more advanced localization needs.
Yes, integrating a third-party site search is common for large websites. The built-in sitemap feature is typically used to facilitate this integration. Edge Delivery Services includes out-of-the-box indexing, which provides a fast and simple search option for most websites.
Can I import content from other platforms to Edge Delivery Services?
Yes, Edge Delivery Services supports content migration from various platforms, including WordPress, Unsplash, Contentful, other AEM instances, and more. The AEM team will help you in the import process, ensuring your content from any CMS is converted.
How do I configure Edge Delivery Services with Dynamic Media and Smart Cropping?
What is the service level agreement (SLA) for Edge Delivery Services?
The SLA for Edge Delivery Services is the same as the SLA for AEM as a Cloud Service. You can check Adobe Status for availability of all Adobe services.
**Source:** [https://www.aem.live/developer/cli-reference](https://www.aem.live/developer/cli-reference)
--stop-other, --stopOtherStop other AEM CLI running on the above portDefault: true
--cache(Description missing in provided text)
--alpha-cache, --alphaCachePath to local folder to cache the responses (alpha feature, may be removed without notice)
--cachePath to local folder to cache the responses
--ui-repo, --uiRepoGit repository for the AEM Importer UI. A fragment may indicate a branch other than main.Default: "https://github.com/adobe/helix-importer-ui"
**Source:** [https://www.aem.live/docs/cdn-guide](https://www.aem.live/docs/cdn-guide)
Picking the right CDN
A Content Delivery Network makes sure that your visitors get your site served as fast as possible when entering your domain name. Adobe Experience Manager integrates with many popular CDN choices, but if you are unsure which one to pick, answer the questions below
AEM customers use Cloudflare Enterprise and benefit from fast and fine-granular purging, powerful extensibility with Cloudflare Workers, support for multiple backends, and zero-trust security support. It's also an all-around good CDN.
Cloudflare's free option is a great choice for smaller sites, as the free tier comes with included traffic and support for Cloudflare Workers. It does not support key-based purging, which means for some updates Adobe Experience Manager has to purge the entire site, making Cloudflare free unsuitable for large sites with frequent content updates.
Cloudfront is the CDN that is included in your Amazon Web Services contract. It is a passable CDN that is supported by Adobe Experience Manager, but many important features are missing such as support for fine-granular content purges. This makes Cloudfront unsuitable for sites with lots of content and a high frequency of updates.
If you are already a Fastly customer, then you know why Adobe Experience Manager integrates with it out of the box: a rock-solid and blazingly fast CDN with fine-grained push invalidation that you can configure using Fastly's VCL language.
Adobe Experience Manager as a Cloud Service bundles the Fastly CDN, which means it's included in your contract. Advanced configuration options require using configuration pipelines in Cloud Manager, so you combine the best of YAML with VCL.
Learn how to set up Adobe Managed CDN
As an Adobe Commerce customer, you have access to the bundled Fastly CDN. It's a great choice of CDN, rock-solid, blazingly fast, and, thanks to VCL, extremely configurable with plenty of public documentation.
Akamai is the market-leading CDN and if you are a customer, there is no reason not to use it with Adobe Experience Manager. Akamai supports push invalidation at reasonable speed and can combine sites with multiple backends, which helps when migrating a legacy site to fast edge delivery.
**Source:** [https://www.aem.live/docs/byo-cdn-setup](https://www.aem.live/docs/byo-cdn-setup)
BYO CDN Setup
Customers may use their own CDN to deliver AEM content under their own domain (aka BYO Production CDN). While customers are generally free to configure their CDN according to their own needs there are some settings mandated/recommended by Adobe Experience Manager:
Origin cache controlI.e. Cache TTL on the production CDN is controlled via origin cache control response headers. This should be enabled (if available).
Must be included in cache key
If you already have a CDN, follow the instructions below. If you are not sure which CDN to pick, follow our guide to CDN selection.
IMPORTANT: The production CDN setup should be validated and tested in a stage environment prior to going public.
Note: In case you have not yet completed the upgrade from hlx.live to aem.live, you can find links to the hlx.live-specific versions of the CDN documentation here.
**Source:** [https://www.aem.live/docs/byo-cdn-cloudfront-setup](https://www.aem.live/docs/byo-cdn-cloudfront-setup)
X-BYO-CDN-Type: cloudfront
Cache behavior
Cache key and origin requests
Click "create cache policy"
Create cache policy
Under "cache key settings", keep the defaults:
Apply Cache policy and origin request policy
After returning to the distribution properties, click the reload buttons next to the Cache policy and origin request policy dropdowns, so that the two newly-created policies show up. Next, select the new policies for both Cache policy and origin request policy.
Cache behavior: default
This will ensure that all requests from the AWS Cloudfront CDN to your AEM origin use the correct authorization.
NB: CloudFront does NOT support purging by cache tag/key. Purge by cache tag/key always triggers a purge all.Configuration properties:
**Source:** [https://www.aem.live/docs/authentication-setup-site](https://www.aem.live/docs/authentication-setup-site)
AEM Live supports token-based authentication. Site authentication is usually applied to both the preview and publish sites, but can also be configured to only protect either site individually.
Enabling Site Authentication for the publish sites (*.aem.live) will enforce authentication for all your site visitors (intranet). It will also prevent automatic PSI (Page Speed Insights) checks from running on your pull requests in GitHub. For use cases where your BYO CDN should use no (or different) authentication from your .live origin, you will need to configure preview only authentication or bypass authentication with an API_KEY.
Enable Authentication for the Preview and Publish Sites
All of the following instructions use the Configuration Service for your site, so follow the linked instructions to enable and authenticate, then perform the following API requests.
The auth token for the admin API obtained during login. This one is highly sensitive and cannot be used for site authentication.
The example above sets the site property which controls access to both aem.page and aem.live. This is the most restrictive approach. If you want to limit access to both aem.page and aem.live, POST to .../access/site.json. If you want to limit access to aem.page only, post to .../access/preview.json. In the unlikely case that you want to limit access to aem.live only, and keep aem.page, post to .../access/live.json.
If you have set tokens for site and either preview or live, then preview and live will override the site-wide settings.
With this change, nobody can access your site without the correct authorization header. This includes your CDN, and therefore every visitor to your site. To enable access again, you need to add the Authorization header to each origin request your CDN makes.
The CDN setup instructions explain how to enable the authorization header for each supported Content Delivery Network.
Accessing protected sites directly from a browser requires users to have an appropriate role defined in the project configuration and to sign in using the AEM Sidekick Extension.
Enforces authentication of the admin API for acme/website
Allows sidekick authenticated users that have a *@acme.com email to preview, publish, etc.
Allows performing admin API operations with an admin token with the JWT jti 1kLvEvoipnINAOGDP8NVl3IYbJy2qmUQa5b1Fe23S7tt depending on the included scopes.
**Source:** [https://www.aem.live/previous/authentication-setup-site](https://www.aem.live/previous/authentication-setup-site)
AEM Live supports out-of-the-box authentication using the Microsoft Identity Provider (IDP) and Microsoft accounts. Your site acts as an application to which the administrator of your Microsoft organization will need to grant access. Site authentication is usually applied to the preview and publish sites, but can also be configured to only protect the sites individually.
Enabling Site Authentication for the publish sites (*.hlx.live) will enforce authentication for all your site visitors (intranet). It will also prevent automatic PSI (Page Speed Insights) checks from running on your pull requests in GitHub. For use cases where your BYO CDN should use no (or different) authentication from your .live origin, you will need to configure preview only authentication or bypass authentication with an API_KEY..
If you use authentication, your BYO (production) CDN must not use (disable) caching, otherwise authentication is gradually circumvented.
If you haven’t done so already, install the Sidekick Extension.
With the site configuration sheet still open, click the Sidekick’s “Preview Button”:
This will copy your site configuration to both the preview and live stages of AEM, since configuration values are treated global. Authentication, by virtue of the access.allow statements you added in the previous step, should now be automatically enabled on your site.
Go to your site’s preview URL (https://main–<repo>--<owner>.hlx.page) or live URL (https://main–<repo>--<owner>.hlx.live). You should be redirected to the Microsoft Sign In page:
Search for the Franklin Admin:
Q: I have published the configuration limiting access to my site, but I can still see the index page without login, whereas sub-paths are protected.A: This is most likely a caching issue. You can resolve it by publishing the index document (e.g. index.docx) again.
Enable Authentication only for the Preview Site
It is possible to configure the access controls differently for the preview (*.hlx.page) and publish (*.hlx.live) sites by only applying the allow configuration property to one site. For example:
Accessing protected sites with an API_KEY
It is possible to obtain an API_KEY to access a protected site without the need to login.
In order to let the system trust your key, its API_KEY_ID needs to be configured on the project as well through the access.apiKeyId property.:
You can simply remove the apiKeyId again from the configuration if you no longer need or trust the respective APY_KEY.
Note: It is currently not possible to generate an api key self serviced. Please contact your Adobe Project Lead to generate one for your project if needed.
AEM allows development from forked repositories that point to the same content. This results in the ability to access the same content via different URLs. For example a site that has its primary repository at example/website can be accessed using https://main--website--example.hlx.page. Assuming a developer forks the repository to developer/ex-web, and keeping the same fstab.yaml, the same content can be accessed via https://main--ex-web--developer.hlx.page. This might be fine or even desirable during development. But once production content is published, it might be undesirable that the same content can be accessed using a different url (and potentially different website code).
In order to restrict which urls can be used to access the content, add a access.require.repository to your /.helix/config.xlsx. For example:
**Source:** [https://www.aem.live/business/reachout](https://www.aem.live/business/reachout)
**Source:** [https://www.aem.live/docs/config-service-setup](https://www.aem.live/docs/config-service-setup)
The Configuration Service is used to aggregate and deliver configuration for various consumers in the AEM architecture including: Client, Delivery, HTML Pipeline, and Admin Service.
Configurations stored in the client scope can be consumed from your site or the AEM Sidekick and control functionality and behavior for visitors and authors. All other configurations are internal to the AEM infrastructure and cannot be accessed directly.
The configuration is managed using REST calls to the Admin service (admin.hlx.page). See AEM Admin API for details of the API.
One of the new features that the configuration service can support is independent code and content definitions per site. A site is a combination of an org name and a site name. This is similar to the GitHub owner and repo tuple, but has no longer a relation to the GitHub project.
For example, a site named website of the org acme could have a code repository adobe/helix-website. The preview URL follows the same scheme, but using site and org instead. In this example: https://main--website--acme.aem.page.
With this new mechanism, it is now possible to have multiple sites that use different content, but use the same code repository. This feature is also known as “repoless”.
Any aem.live organization needs also to exist as github.com org, and at least one repository needs to be synced using AEM Code Sync. This ensures that the organization namespace is properly claimed by an entity that can also claim an org on github.com. The github.com org can exceptionally be created by Adobe or a trusted implementation partner on the customer’s behalf, but it must have at least one owner from the customer's organization.
For projects that want to use multiple sites with the same code repository (repoless), there must be one canonical site for which the org/site matches the github owner/repo. This is required for proper code-config association and CDN push invalidation.
In this example we will create two new sites, website and products of the acme org, which will both share the same github repository: acme/website. The content is managed in sharepoint, at a fictitious https://acme.sharepoint.com/sites/aem/Shared%20Documents/website and .../products.
Make sure that you are properly authenticated, then using the Admin API, we create the first site:
The new site is now available at https://main--website--acme.aem.page. Most likely only the 404.html is shown, as no content has been previewed yet.
Using the Admin API, we create the second site:
The new site is now available at https://main--products--acme.aem.page. Most likely only the 404.html is shown, as no content has been previewed.
Update Production CDN
Use this to configure the CDN settings:
Update Sidekick Configuration
Use this to customize the Sidekick:
Once you have enabled the configuration service, the configuration settings there override the settings you have in configuration files in your GitHub repository and your content source, so it is best to remove them:
First remove the files from github:
tools/sidekick/config.json
And after those are removed, check if the hlx.page preview page returns a 404. This means that the internal configuration of the repository based config is cleaned up. Then you can also unpreview and delete the configuration in /.helix folder in your content:
**Source:** [https://www.aem.live/docs/repoless](https://www.aem.live/docs/repoless)
If you have many similar sites that mostly look and behave the same, but have different content, you may want to share code across multiple sites. In the past, the best way to do this was to create multiple GitHub repositories, keep them somehow in sync, and run each site off a dedicated GitHub repository.
AEM supports running multiple sites from the same codebase without having to take care of code replication. This ability is also known as "repoless", because all but your first site don't need a GitHub repository of their own.
Repoless sites are enabled by the Configuration Service in Adobe Experience Manager, which introduces a couple of concepts such as Organization, Profile, Repository, Site, and Content Source. The following diagram shows how the pieces fit together.
Each site in Adobe Experience Manager belongs to an organization. This organization has the same name as an org on github.com, so that there is no naming conflict. An organization can have multiple sites, profiles, and users.
Profiles are a way to group and re-use important configurations such as headers, indexes, additional metadata, and so on. A profile can be used by multiple sites within an organization, so that there is consistency among them.
GitHub Repository
For each codebase in Adobe Experience Manager, there is one GitHub repository. By creating a first site that uses this repository through AEM Code Sync, this code will be made available to Adobe Experience Manager and can then be used by multiple sites. When updates are pushed to the GitHub repository, they apply to all sites that use this codebase.
The content that makes up a site is pulled from a content source when authors preview or publish content. Typical sources include Microsoft Sharepoint and Google Drive, or the bring-your-own-markup adapter.
The first step to creating a bunch of sites is to create a first site. This site can be used to serve content, but the most important job is to ensure that code is synchronized from your GitHub repository to all sites that use this codebase.
Note: Make sure that you are properly authenticated for all the calls to Admin API
Github Repository : https://github.com/{org}/{site}
Content Repository (Gdrive / Sharepoint) : https://{org}.sharepoint.com/sites/aem/Shared%20Documents/{site}
Contact Adobe to create the organization for you. Note: you will be asked to provide the URL to a github.com organization you own. Learn more.
Using the Admin API, we create the first site
The new site is now available at https://main--{site}--{org}.aem.page. Most likely only the 404.html is shown, as no content has been previewed yet.
Base site configured with code and content repository using the Admin API (see previous section)
Content Repository (Gdrive / Sharepoint) for new repoless site : https://{org}.sharepoint.com/sites/aem/Shared%20Documents/{site2}
Using the Admin API, we create new configuration for the first repoless site
The new site is now available at https://main--{site2}--{org}.aem.page. Most likely only the 404.html is shown, as no content has been previewed.
Additionally, you can use the Admin API to set other available advanced options to use within configuration management.
To view your new site during local development, use the ––url option on the aem up command to specify the new site’s url, like aem up ––url https://main––{site2}--{org}.aem.page .
When you start with Adobe Experience Manager, many settings are kept either with your content in the content source, or in the GitHub repository next to your code. With the Configuration Service there is now a central place for these kinds of settings.
Below gives you a comparison between how different areas are configured when we use the document mode (the traditional, distributed configuration) vs. using the Configuration Service API.
**Source:** [https://www.aem.live/developer/folder-mapping](https://www.aem.live/developer/folder-mapping)
Some best practices scenarios where folder mapping is useful:
Commerce websites generating product pages from a product information API
Sites using a combination of a large number of folder-mapped pages and frequently changing metadata. For such use cases, it is better to provide the content via different methods. Talk to your Adobe contact to learn more.
Generating non-cacheable content like user specific URLs. This can lead to cache pollution and possible security risks if content is unintentionally cached.
Folder-mapped Metadata
If the site has folder mapping configured, the metadata files within that folder will apply to all pages for that mapping. For example, if /templates/ is folder-mapped to /templates/default, metadata in /templates/default/metadata.xlsx will be applied to all pages below /templates/ if the URL pattern matches.
Changes to folder-mapped metadata are not reflected in the last-modified HTTP response header of pages within the mapped scope. By default, the date of the last modification of the default document will be used. If you rely on that header value to be updated based on metadata changes, which may be desirable for SEO or SEM purposes, you can influence* it by adding an explicit last-modified column. This allows you to set the desired date string or timestamp for select rows only while leaving the others unchanged. We recommend the ISO date format to ensure it’s both human-readable and timezone-safe. .
The global (and additional) metadata
There are some additional rules applied to bulk metadata for folder mapped pages, see Folder-mapped metadata in the bulk metadata documentation for details.
**Source:** [https://www.aem.live/developer/markup-reference](https://www.aem.live/developer/markup-reference)
While for most development tasks the DOM is the relevant interface for a developer, there are certain situations (eg. Auto Blocking) where a developer interacts with the raw HTML markup that is rendered by the Franklin pipeline on the server.
The metadata portion of the document consists of a list of <meta> tags, some of them correspond to well known HTML metadata or metadata data without defined semantics. See more in the metadata block specification.
which maps a metadata property named template to a value of docs.
The head.html portion of the document contains verbatim of what’s found in the head.html of the corresponding github branch.
All the content that semantically maps to document semantics of an individual page or fragment is found in the main-content content section of the markup. It consists of default content, sections and blocks.
It is important that both default content and any cell of a block can contain the following HTML tags and attributes.
There is special handling for links to AEM preview and live domains (hlx.page, hlx.live, aem.page, aem.live). Any link to one of these domains is rendered as a relative link. This allows authors to link to any of these domain from content pages and still work across preview, live, and production domains.
**Source:** [https://www.aem.live/developer/block-collection/metadata](https://www.aem.live/developer/block-collection/metadata)
Metadata Block
The Metadata table is handled by the pipeline service to add <meta> tags in the <head> of the HTML markup delivered from the service. It does not appear verbatim in the HTML markup. There should only be one Metadata table per page and while its placement doesn’t matter, by convention it is placed at the bottom of the document.
The metadata table is essentially following an intuitive name/value pair structure where the name is in the first column of the table and the value is in the second column.
There are a few special properties that behave according to the HTML specification and popular additional metadata schemas like og: and twitter:. The well known metadata properties include title, description, and image. See special metadata properties for the full list.
There are also special semantics for theme and template which get added as classes to the <body> element by the boilerplate code and are often used for styling and autoblocking.
The metadata table is processed as part of the HTML rendering service. There is no project code related to the processing.
**Source:** [https://www.aem.live/developer/block-collection/footer](https://www.aem.live/developer/block-collection/footer)
Footer (Block)
The footer block is loaded by default in the boilerplate project into the <footer> element.Out-of-the-box it provides a simple example for a footer but is likely to be extended or adjusted on the per project basis.
The footer block is usually not referenced by authors but is loaded automatically on every page.
The content for the footer is loaded as a fragment and is by default authored in a footer (or footer.docx) document.As footer structure and designs change rarely and are usually visually very different from the rest of the blocks on a site, it is often a good strategy to divide the content into sections and decorate specific classes onto the sections based on their sequence and apply CSS styling to those classes.
The footer document has its own lifecycle and when previewed or published applies to all pages that use a given navigation.
Boilerplate Block Code
**Source:** [https://www.aem.live/developer/block-collection/header](https://www.aem.live/developer/block-collection/header)
Header (Block)
The header block is loaded by default in the boilerplate project into the <header> element.Out-of-the-box it provides code for a responsive navigation but it is like most blocks very likely to be extended or adjusted on the per project basis.
The header block is usually not referenced by authors but is loaded automatically on every page.
The nav document has its own lifecycle and when previewed or published applies to all pages that use a given navigation.
**Source:** [https://www.aem.live/developer/block-collection/cards](https://www.aem.live/developer/block-collection/cards)
**Source:** [https://www.aem.live/developer/block-collection/section-metadata](https://www.aem.live/developer/block-collection/section-metadata)
The Section Metadata table is handled by boilerplate code internally to add data-*s attributes to the containing section.
Section Metadata table follows an intuitive name/value pair structure where the name is in the first column of the table and the value is in the second column.
As Section Metadata generally adds complexity for authors, it is recommended to avoid it, until it is really necessary.
The section metadata table is processed as part of the boilerplate code. There is no project code related to the processing.
**Source:** [https://www.aem.live/docs/authentication-setup-authoring](https://www.aem.live/docs/authentication-setup-authoring)
By default, authors don’t need to be logged in in order to use AEM via Sidekick. In order to enable authentication, it is sufficient to add relevant access-statements to your site configuration. Upon encountering said access-statements, the Sidekick will enforce authentication with the respective provider: Microsoft for Sharepoint based projects, and Google for Google Drive based projects.
Step 2: Login via Sidekick
The next time the Sidekick opens on a document, it will show a "Sign In" option:
In this case, ask an Active Directory admin of your organization to login via Sidekick or directly via the admin link: https://admin.hlx.page/auth/microsoft
Search for the AEM Content Integration Admin API:
When authentication is enabled for admin.hlx.page using the API endpoint with tools like curl will require to use a proper auth token. For one time ad-hoc use by developers it is very convenient to just copy/paste the x-auth-token header from your browser's network tab from an authenticated request sent by sidekick to admin.hlx.page and pass it into the curl via the -H option. eg:
cache:write
preview:read
preview:write
preview:delete
preview:list
preview:delete-forced
If you have set up the Configuration Service for your site, then you can use the following API operations to configure permissions for authors:
In each of these API requests, you will use the fields
**Source:** [https://www.aem.live/developer/sidekick-customization](https://www.aem.live/developer/sidekick-customization)
**Source:** [https://www.aem.live/docs/configuration](https://www.aem.live/docs/configuration)
Note: Activate the configuration using the Sidekick for your configuration changes to become active.
**Source:** [https://www.aem.live/docs/byo-cdn-adobe-managed](https://www.aem.live/docs/byo-cdn-adobe-managed)
Adobe Managed CDN
The following steps illustrate how to use the Adobe Managed CDN (part of Edge Delivery Services entitlement) to configure a property to deliver content from a site powered by Edge Delivery Services in Adobe Experience Manager Sites as a Cloud Service.
You must have a license with an Edge Delivery Services entitlement.
There are two deployment options for going live with Adobe Managed CDN
Setup an HTTP proxy from an existing AEM Sites as a Cloud Service environment. This is typically used when you already have an existing environment and you want to migrate part of a site to Edge Delivery Services. You can also add a new environment.
Setup a new Edge Delivery site independently of an AEM Sites as a Cloud Service environment. This is the approach used when you do not have an AEM author or publish environment and you want to use Edge Delivery Services on its own. See here for benefits.
Add a CDN configuration to map your domain to your Edge Delivery site. (This will be done differently depending on what deployment option you chose)
Point the DNS CNAME of your www site to cdn.adobeaemcloud.com and the A records of your apex to the IP addresses listed below.
This requires an existing AEM Sites as a Cloud Service environment that needs to be configured via configuration pipeline to proxy some (or all) paths on your domain to your Edge Delivery Site. (see how to define a proxy using originSelectors and how to run a Configuration Pipeline).
(Option 2) Setup an Edge Delivery site without an existing environment
In case you do not have an existing authoring/publish environment, follow the steps for setting up a new Edge Delivery site in Cloud Manager.
Push invalidation automatically purges content on the managed CDN whenever an author publishes content changes.
Content is purged by URL and by cache tag/key.
If your site is using the configuration service, see here how to update the CDN configuration.
After making changes to the configuration sheet, preview it with the Sidekick or publish it in the Sites console to activate the changes.
For www.example.com set the CNAME DNS record to cdn.adobeaemcloud.com (see details).
**Source:** [https://www.aem.live/developer/upgrade](https://www.aem.live/developer/upgrade)
If you are familiar with *.hlx.live for published content and *.hlx.page for previews, please note that we are introducing *.aem.live and *.aem.page as new domains for your sites.
With this change, we are also introducing several improvements while making sure everything works just as before. The most important benefit is that preview URLs will load faster on aem.page thanks to caching.
Try previews on aem.page
If your site works on aem.live, then previews will also work on aem.page. For instance, if you used to see your site on https://main--helix-website--adobe.hlx.page/ then your new URL would be https://main--helix-website--adobe.aem.page/.
Tell Sidekick to use aem.live and aem.page
Even though both hlx.page and aem.page work for previews now, Sidekick will always default to hlx.page.
Let's change this. In your Sharepoint or Google Drive folder, locate the .helix/config spreadsheet and add following values, replacing <owner with your GitHub organization and <repo> with your repository name:
cdn.live.host: main--<repo>--<owner>.aem.live
cdn.preview.host: main--<repo>--<owner>.aem.page
Preview the spreadsheet using Sidekick to activate the new configuration.After activating the configuration, please make sure the Sidekick preview action is opening urls with .aem.page.
Point your CDN to aem.live
In your CDN setup, change the origin URL or host name from hlx.live to aem.live and activate the change. If you experience any issues, then revert the origin URL or host name back to hlx.live and contact Adobe for assistance.
If you are using BYO DNS without BYO CDN
If you use custom domains without a custom CDN, please contact Adobe to perform the origin change to aem.live.
Check your GitHub repository for any references to hlx.page or hlx.live. If you find them, double-check the functionality, as the changed hostname may introduce CORS or other cross-origin issues. Update the references to aem.page or aem.live.
Code references to hlx.page and hlx.live in the sampleRUM() function, lib-franklin.js or aem.js do not need to be changed.
Check your content repository for any instances where you might have references for hlx.page or hlx.live in any content areas, including spreadsheets, for project-specific functionality.
Update link references around project documentation areas that may include, but not limited to, Block Library, Runbooks, Authoring Guides, and Pull Request Templates.
Many services like Google reCaptcha, Google Maps, Cloudflare Turnstile, etc. use the site domain or referrer domain to validate API tokens. If you have configured these services to allow your site on hlx.page or hlx.live, make sure to also allow aem.page and aem.live
**Source:** [https://www.aem.live/docs/deprecation](https://www.aem.live/docs/deprecation)
Custom domains without a custom CDN
We no longer accept new domains for the Bring-your-own-DNS service. Please use Adobe Managed CDN.
This feature is deprecated and has been replaced by Edge Delivery Services for AEM Forms.
AEM Sidekick v6
This version of the sidekick has been deprecated. Use the latest sidekick version instead.
**Source:** [https://www.aem.live/blog/hlx-is-now-aem-live](https://www.aem.live/blog/hlx-is-now-aem-live)
If you've been using Adobe Experience Manager for a short while, you may have wondered what the hlx.live and hlx.page in the preview and live URLs of your site mean. If you have been using AEM for a longer while, you may have wondered when *.hlx.live would follow the steps of aem up, www.aem.live, and AEM Sidekick.
New Domains: your site is now available under *.aem.live and previews are on *.aem.page
Improved Performance: Previews on *.aem.page are a bit faster than on *.hlx.page, thanks to better caching
Starting today, all new projects created from the tutorial, will use the new aem.live architecture. Existing projects can upgrade following these steps.
Edge Delivery Services for Adobe Experience Manager Sites as a Cloud Service started more than five years ago with Project Helix, and the acronym hlx could be found by our early adopters all over the place: in domains, user names, command line tools, and so on. With aem.live as the default, the name Helix is back to being an internal designator of the architecture version and the hlx.live and hlx.page domain names will see an eventual end of service.
Ready to make the switch? Upgrade your existing projects to aem.live today and start enjoying faster performance, advanced features, and a seamless AEM experience. For detailed instructions on how to upgrade, visit our upgrade guide or reach out to our team for assistance.
**Source:** [http://www.aem.live/](http://www.aem.live/)
**Source:** [http://www.aem.live/docs](http://www.aem.live/docs)
**Source:** [http://www.aem.live/docs/](http://www.aem.live/docs/)
**Source:** [http://www.aem.live/docs/sidekick](http://www.aem.live/docs/sidekick)
**Source:** [http://www.aem.live/blog](http://www.aem.live/blog)
**Source:** [http://www.aem.live/developer/tutorial](http://www.aem.live/developer/tutorial)
**Source:** [http://www.aem.live/home](http://www.aem.live/home)
**Source:** [http://www.aem.live/docs/faq](http://www.aem.live/docs/faq)
**Source:** [http://www.aem.live/developer/anatomy-of-a-franklin-project](http://www.aem.live/developer/anatomy-of-a-franklin-project)
**Source:** [http://www.aem.live/developer/anatomy-of-a-project](http://www.aem.live/developer/anatomy-of-a-project)
**Source:** [http://www.aem.live/developer/block-collection](http://www.aem.live/developer/block-collection)
**Source:** [http://www.aem.live/developer/spreadsheets](http://www.aem.live/developer/spreadsheets)
**Source:** [http://www.aem.live/developer/indexing](http://www.aem.live/developer/indexing)
**Source:** [http://www.aem.live/developer/keeping-it-100](http://www.aem.live/developer/keeping-it-100)
**Source:** [http://www.aem.live/developer/markup-sections-blocks](http://www.aem.live/developer/markup-sections-blocks)
**Source:** [http://www.aem.live/developer/favicon](http://www.aem.live/developer/favicon)
**Source:** [http://www.aem.live/docs/custom-headers](http://www.aem.live/docs/custom-headers)
**Source:** [http://www.aem.live/docs/authoring-guide](http://www.aem.live/docs/authoring-guide)
**Source:** [http://www.aem.live/docs/authoring](http://www.aem.live/docs/authoring)
**Source:** [http://www.aem.live/docs/bulk-metadata](http://www.aem.live/docs/bulk-metadata)
**Source:** [http://www.aem.live/docs/placeholders](http://www.aem.live/docs/placeholders)
**Source:** [http://www.aem.live/developer/sitemap](http://www.aem.live/developer/sitemap)
**Source:** [http://www.aem.live/docs/setup-customer-sharepoint](http://www.aem.live/docs/setup-customer-sharepoint)
**Source:** [http://www.aem.live/docs/go-live-checklist](http://www.aem.live/docs/go-live-checklist)
**Source:** [http://www.aem.live/docs/setup-byo-cdn-push-invalidation](http://www.aem.live/docs/setup-byo-cdn-push-invalidation)
**Source:** [http://www.aem.live/docs/byo-cdn-cloudflare-worker-setup](http://www.aem.live/docs/byo-cdn-cloudflare-worker-setup)
**Source:** [http://www.aem.live/docs/byo-cdn-akamai-setup](http://www.aem.live/docs/byo-cdn-akamai-setup)
**Source:** [http://www.aem.live/docs/byo-cdn-fastly-setup](http://www.aem.live/docs/byo-cdn-fastly-setup)
**Source:** [http://www.aem.live/docs/redirects](http://www.aem.live/docs/redirects)
**Source:** [http://www.aem.live/docs/auditlog](http://www.aem.live/docs/auditlog)
**Source:** [http://www.aem.live/docs/sidekick-security](http://www.aem.live/docs/sidekick-security)
**Source:** [http://www.aem.live/developer/sidekick-development](http://www.aem.live/developer/sidekick-development)
**Source:** [http://www.aem.live/docs/sidekick-library](http://www.aem.live/docs/sidekick-library)
**Source:** [http://www.aem.live/developer/cli-reference](http://www.aem.live/developer/cli-reference)
**Source:** [http://www.aem.live/docs/cdn-guide](http://www.aem.live/docs/cdn-guide)
**Source:** [https://www.aem.live/docs/setup-byo-cdn-push-invalidation-for-cloudfront](https://www.aem.live/docs/setup-byo-cdn-push-invalidation-for-cloudfront)
**Source:** [http://www.aem.live/docs/byo-cdn-adobe-managed](http://www.aem.live/docs/byo-cdn-adobe-managed)
**Source:** [http://www.aem.live/docs/config-service-setup](http://www.aem.live/docs/config-service-setup)
**Source:** [http://www.aem.live/docs/repoless](http://www.aem.live/docs/repoless)
**Source:** [http://www.aem.live/business/reachout](http://www.aem.live/business/reachout)
**Source:** [http://www.aem.live/docs/authentication-setup-authoring](http://www.aem.live/docs/authentication-setup-authoring)
**Source:** [http://www.aem.live/docs/configuration](http://www.aem.live/docs/configuration)
**Source:** [http://www.aem.live/developer/folder-mapping](http://www.aem.live/developer/folder-mapping)
**Source:** [http://www.aem.live/developer/markup-reference](http://www.aem.live/developer/markup-reference)
**Source:** [http://www.aem.live/developer/block-collection/metadata](http://www.aem.live/developer/block-collection/metadata)
**Source:** [http://www.aem.live/developer/block-collection/footer](http://www.aem.live/developer/block-collection/footer)
**Source:** [http://www.aem.live/developer/block-collection/header](http://www.aem.live/developer/block-collection/header)
**Source:** [http://www.aem.live/developer/block-collection/cards](http://www.aem.live/developer/block-collection/cards)
**Source:** [http://www.aem.live/developer/block-collection/section-metadata](http://www.aem.live/developer/block-collection/section-metadata)
**Source:** [http://www.aem.live/docs/byo-cdn-setup](http://www.aem.live/docs/byo-cdn-setup)
**Source:** [http://www.aem.live/docs/byo-cdn-cloudfront-setup](http://www.aem.live/docs/byo-cdn-cloudfront-setup)
**Source:** [http://www.aem.live/docs/authentication-setup-site](http://www.aem.live/docs/authentication-setup-site)
**Source:** [http://www.aem.live/developer/upgrade](http://www.aem.live/developer/upgrade)
**Source:** [http://www.aem.live/docs/deprecation](http://www.aem.live/docs/deprecation)
**Source:** [http://www.aem.live/blog/hlx-is-now-aem-live](http://www.aem.live/blog/hlx-is-now-aem-live)
**Source:** [https://www.aem.live/docs/byo-dns](https://www.aem.live/docs/byo-dns)
The most common way of going live with a AEM site is to use a custom Content Delivery Network (CDN). Our documentation provides instructions for the most common CDN providers and through your Slack support channel, the AEM team provides assistance.
If you do not have a CDN, we can provide you with assistance in setting up a custom domain without a CDN.
After making changes to the config sheet, preview it with the sidekick to activate the changes.
This ensures that the domain validation certificate is available before any traffic is directed to the CDN.
For www.example.com set the CNAME DNS record to hlxcdn.adobeaemcloud.com
**Source:** [https://www.aem.live/previous/byo-cdn-cloudflare-setup](https://www.aem.live/previous/byo-cdn-cloudflare-setup)
Select SSL/TLS from the left pane and Edge Certificates in the dropdown list:
NB: The X-Push-Invalidation: enabled request header enables the AEM push invalidation including long cache TTLs. Make sure you have successfully configured push invalidation for your project.
**Source:** [https://www.aem.live/docs/manual-forms-sheet-setup](https://www.aem.live/docs/manual-forms-sheet-setup)
**Source:** [https://www.aem.live/developer/forms](https://www.aem.live/developer/forms)
Edge Delivery Services for AEM Forms is a composable set of services that enables a rapid development environment where authors can update, publish, and launch new forms rapidly. These services deliver exceptional and high impact forms experiences that drive engagement and conversions. These forms experiences are easy to author and develop.
Create forms optimized for speed, performance, and higher conversions: Deliver forms experiences that load and render quickly and continuously monitor your forms performance through real use monitoring (RUM). These forms offer perfect core web vitals which results in faster loading times and optimized user experience that contributes to higher form completion and conversion rates.
Use developer friendly toolset: Edge Delivery Services for AEM Forms uses plain HTML, modern CSS, and vanilla JavaScript to create exceptional forms experiences, avoiding the steep learning curve of a specific framework. A developer with basic web development skills can customize and easily build form components and forms experiences. There is no need to wait for a pipeline to run, just check-in your code into GitHub and your changes are live.
Use Forms Submission Service: The Forms Submission Service lets you save form submissions directly to spreadsheets like OneDrive, SharePoint, or Google Sheets, even if the spreadsheet isn’t managed by Edge Delivery Services.
Note: To use form-related capabilities on your Edge Delivery Services Site, a valid AEM Forms license is required. Refer to the Product Description for licensing details.
Edge Delivery Services for AEM Forms allows for a high degree of flexibility in how you author forms on your website. You can author content and forms with WYSIWYG Authoring as well as Document-based Authoring. Edge Delivery Services for AEM Forms provide a forms block, known as Adaptive Forms Block to add a form to your Edge Delivery Services site.
The following diagram illustrates how you can edit forms in Microsoft Excel or Google Sheets (Document-based Authoring) and publish to Edge Delivery Services. It also shows the AEM publishing method using the WYSIWYG Authoring (Universal Editor)
Edge Delivery Services for AEM Forms uses GitHub so customers can manage and deploy code directly from their GitHub repository. For example, you can write forms in either Google Sheets or Microsoft Excel and the components of your forms can be developed by using CSS and JavaScript in a GitHub repository.
When your forms are ready, you can use the AEM Sidekick, a chrome browser extension, to preview and publish content updates.
The choice between Document-based Authoring and WYSIWYG Authoring depends on your needs: Use Document-based Authoring for simple, spreadsheet-like forms with basic fields and quick data connectivity, while WYSIWYG Authoring is ideal for complex forms requiring multiple panels, business logic, data integration, and AEM workflows.
Accessible components for a user-friendly experience.
Ability to create custom form components for specific needs.
Monitor your forms performance through real use monitoring (RUM).
Google reCAPTCHA integration for spam protection.
Integration with Adobe Workfront Fusion to triggering Adobe Workfront Fusion scenarios upon form submission.
Integration with various data sources for pre-populating forms and submitting data.
Edge Delivery Services for AEM Forms provides Adaptive Forms Block to allow you to create and render forms. You can style various components of the form as per your requirements. To get started.
Create or configure your AEM Edge Delivery Services Github Project
If you have an existing AEM Edge Delivery Services Github Project, you can integrate the Adaptive Forms Block into your current project to get started on form creation.
If you don’t have an existing AEM Edge Delivery Services Github Project, create a new AEM project pre-configured with Adaptive Forms Block.
Create a form and add it to your AEM Edge Delivery Services page
Publish and Deploy Forms
Build Custom Form Components
For more details about Adaptive Forms Block, check out AEM Forms Edge Delivery Services documentation.
**Source:** [http://www.aem.live/previous/sidekick](http://www.aem.live/previous/sidekick)
Using the AEM Sidekick (v6)
​​The AEM sidekick provides content authors with a toolbar offering context-aware options so that they can edit, preview, and publish their content directly from the pages of your website.
This document explains how to use the sidekick.
Please see the document Installing the AEM Sidekick for how to install and configure the sidekick.
The sidekick can be invoked in the following contexts:
To use the sidekick extension, navigate to a URL associated with your project. This can be one of the following:
A Preview URL (the domain name ending in .aem.page)
The sidekick extension can be toggled by clicking the Adobe Experience Cloud icon next to the address bar.
Adding projects to your sidekick configuration is optional for most use cases. The sidekick is able to auto-detect if a URL is associated with your project. If you want the sidekick to also recognize custom domains, such as your project’s production domain, you’ll need to persist the project in your sidekick configuration by clicking the + button on the right hand side..
The environment switcher on a sidekick in Google Docs.
This option takes you to the preview environment, which reflects the latest changes of the page rendered from the source document. You can also send preview URLs to stakeholders so they can review your content before it gets published. Note that this option is only enabled if the content you are looking at has been previewed before.
The preview URL follows the pattern https://branch--repo--org.aem.page/path.
branch, repo and org identify the location of your project’s underlying code in GitHub
The live URL looks almost identical to the preview URL, the only difference being in the 1st level domain: https://main--repo--org.aem.live/path
This environment can be a 3rd-party or “bring your own” CDN. Depending on the project setup, new content may only appear after a delay.
There are a number of actions that you can take on your content by conveniently using the sidekick toolbar. Actions that have not been executed since the content was last changed are badged with an orange indicator.
\ The preview action on a sidekick in Google Docs.
Preview is the predominant action in the editor. It (re)generates the preview page based on the current document and opens it in a separate tab.
The sidekick in a preview environment.
The Reload action is available in the preview environment only. It can be used to force a content refresh, for example if you have editor and preview open side by side while working on the content. The action is identical to the Preview action in the editor.
The Publish action is available in all three environments and makes the current preview version of the page available in the live and production environments.
The sidekick in a live environment.
Open the sidekick in Google Drive or Microsoft SharePoint and select one or more files to bulk preview and publish files and conveniently copy their URLs. You can also use this feature to preview and publish media like SVG or PDF files.
Limitation: in Microsoft SharePoint, larger selections (more than 60) may not be fully exposed to the sidekick and may therefore need to be split into smaller badges.
Selecting multiple documents in SharePoint or GDrive allows you to preview multiple documents en masse.
Bulk preview in Google Drive.
For a page without a source document (i.e. it was renamed or moved), the sidekick will show the following two actions when invoked in the preview environment.
Note: If you are signed in to the sidekick, you can skip deleting the underlying source document and simply hold down the Alt (Windows) or Option (Mac) key to bring up the Delete and Unpublish actions.
The sidekick on a preview page without a source document.
This Unpublish action will unpublish the page, but still keep it in the preview environment for reference.
Sharing the Sidekick
You can share the sidekick configuration for your project by clicking the share symbol at the top right. This will copy a shareable URL to your clipboard and allow you to paste it in a DM or email to a colleague. The share URL will enable the recipient to effortlessly install the sidekick for your project.
See the document Installing the AEM Sidekick for more information.
If you are a developer, you can customize the sidekick for your project.
**Source:** [https://www.aem.live/docs/sidekick-extension](https://www.aem.live/docs/sidekick-extension)
Installing the AEM Sidekick (v6)
This document explains how to install and configure the sidekick.
The sidekick is available as a browser extension in Chrome-based browsers and Safari and can be installed in a number of ways.
Use the sidekick configurator.
Manually install the sidekick as you would any other extension
If you already have the sidekick installed and need help using it, please see the document Using the AEM Sidekick Extension.
Using the Sidekick Configurator
In Safari or a Chrome-based browser, navigate to the link https://www.aem.live/tools/sidekick/
Provide the URL to the GitHub repository of your project and optionally a name for the project and click Go.
The sidekick supports multiple projects and providing a descriptive name helps managing the configurations.
In the new section Install the Sidekick extension and add this project that appears, click the Install Sidekick Extension for Chrome or Install Sidekick Extension for Safari.
If you have any issues installing the extension, please review the instructions in the section Manually Installing the Sidekick.
Manually Installing the Sidekick
Navigate to the sidekick extension in the Chrome Web Store.
Navigate to the sidekick extension in the App Store.
Check the box next to the sidekick extension.
Toggle the sidekick extension.
If your project requires you to sign in to use the sidekick extension, you need to enable 3rd-party cookies: Safari > Settings > Privacy > uncheck “Prevent cross-site tracking”
There are multiple ways to add projects to the sidekick extension:
See the section Using the Sidekick Configurator.
Navigate to a sharing URL starting with https://www.aem.live/tools/sidekick/?...
A colleague on the project can provide you with a sharing URL. See the document Using the AEM Sidekick Extension for details.
Navigate to a GitHub repository starting with https://github.com/...
Safari (mobile): Open Settings and tap Safari > Extensions > AEM Sidekick > Extension settings.
Add manually: enter the GitHub repository URL and other optional parameters for your project.
Project Name : Specify your project name here. This would give a name to the project configuration, making it easy to identify in the sidekick. This is an optional configuration.
Repository URL : Specify the Github repository of your project here. For e.g. https://github.com/hlxsites/wknd.
Bonus Tip : You can specify your repository branch here to have your project code picked from this repository branch when you open it up in your browser. For e.g. https://github.com/hlxsites/wknd/tree/mybranch
Production Hostname : Specify the production URL (the domain name being your project’s public host name). This would ensure that the sidekick is available in the browser when you open the site on the production domain. This is an optional setting.
Develop Sidekick Customizations locally
Test project configuration locally : Use this advanced setting for testing any local customizations in the sidekick. Read more about Sidekick Customizations here.
Local Development URL : Specify the url of your locally running server. Default value is http://localhost:3000
This can be used to test the API keys used in your CDN, and make sure that they have access to the origin. This option is likely to only be used by administrative staff for setup and debugging purposes.
Use the Sidekick Extension
Please see the document Using the AEM Sidekick to learn how to use the sidekick.
**Source:** [https://www.aem.live/previous/sidekick-extension](https://www.aem.live/previous/sidekick-extension)
**Source:** [http://www.aem.live/docs/sidekick-extension](http://www.aem.live/docs/sidekick-extension)
**Source:** [http://www.aem.live/previous/sidekick-extension](http://www.aem.live/previous/sidekick-extension)
**Source:** [https://www.aem.live/docs/scheduling](https://www.aem.live/docs/scheduling)
AEM offers a way to execute certain tasks, such as previewing, publishing or purging pages at certain times during the day or in certain periodic intervals. It also allows publishing a query index, which makes entries public in the JSON representation that may have only been available in the underlying Excel workbook or Google spreadsheet.The tasks to execute and the time they should be executed at are configurable with a crontab sheet, located in the project’s .helix folder, that looks as follows:
When you are finished making changes to your crontab sheet, activate it by previewing it. If there are any syntactical errors, a message will be displayed, and none of your tasks in that sheet will be scheduled.
You can run multiple tasks at the same time by separating them with a line feed in the cell. If you happen to have a lot of pages to preview, publish and possibly purge at the same time, consider using process as shown below.
preview
Preview a page given as second parameter, e.g.preview /documentpreview /spreadsheet.json
Process a previewed JSON document line by line, interpreting it as a list of commands and their arguments, where the columns are commands and the cell values are arguments.For example, given the following JSON document called /tasks.json:
Adding a command process /tasks.json to your crontab will preview and publish /document1, and then preview and publish /document2.
**Source:** [http://www.aem.live/docs/byo-dns](http://www.aem.live/docs/byo-dns)
**Source:** [http://www.aem.live/developer/forms](http://www.aem.live/developer/forms)
**Source:** [http://www.aem.live/developer/anatomy-of-a-helix-project](http://www.aem.live/developer/anatomy-of-a-helix-project)
**Source:** [http://www.aem.live/previous/byo-cdn-cloudflare-worker-setup](http://www.aem.live/previous/byo-cdn-cloudflare-worker-setup)
NOTE: The instructions linked on this page apply to the previous version of Edge Delivery Services and are provided for customers who have not upgraded to aem.live yet. The current version of this document is provided here.
This setup can be completely done in the browser by using the Cloudflare Dashboard only. If you are already familiar with Cloudflare Workers, Wrangler & GitHub and not afraid of entering commands in a terminal window you might want to follow the instructions here instead.
Note that surgical push invalidations are only supported on the Enterprise plan. On all other plans the entire cache of the site will be purged every time an author publishes a content change.For this walk-through we’ll use the Free plan.
Click on “Save and Deploy”:
**Source:** [http://www.aem.live/previous/byo-cdn-akamai-setup](http://www.aem.live/previous/byo-cdn-akamai-setup)
Do not enable Akamai mPulse Real Usage Monitoring. While the performance impact on most sites is negligible, for sites built for consistent high performance, enabling it will prevent reaching a Lighthouse Score of 100. In AEM, you have a Real User Monitoring service built-in, so that dual instrumentation will be unnecessary and is strongly discouraged.
Also, do not enable Akamai Bot Manager or similar Web Application Firewall offerings, as they markedly interfere with rendering performance and user experience. Your site on AEM is protected against bot attacks on the backend, so that this performance cost comes with negligible benefit.
**Source:** [https://www.aem.live/docs/rum](https://www.aem.live/docs/rum)
Adobe Experience Manager uses Operational Telemetry to gather operations data that is strictly necessary to discover and fix functional and performance issues on Adobe Experience Manager-powered sites. Operational Telemetry data can be used to diagnose performance issues. Operational Telemetry preserves the privacy of visitors through sampling (only a small portion of all page views will be monitored).
The Core Web Vitals (CWV) performance metrics Largest Contentful Paint (LCP), Interaction to Next Paint (INP) and Cumulative Layout Shift (CLS) that describe the visitor’s quality of experience.
The foundational performance metric Time to First Byte (TTFB) that describes the visitors's quality of experience
To identify and fix performance bottlenecks on customer sites
Operational Telemetry for Developers
**Source:** [https://www.aem.live/docs/operational-telemetry](https://www.aem.live/docs/operational-telemetry)
**Source:** [https://www.aem.live/developer/rum](https://www.aem.live/developer/rum)
Adobe Experience Manager uses Operational Telemetry to diagnose usage and performance of web sites running on Adobe Experience Manager. As a developer, you can use the Operational Telemetry APIs to observe additional events about how your site is used.
This document describes the key concepts of Real Use Monitoring, details the client-side APIs that you can use to send additional data to the Operational Telemetry collection service and alludes to the fact that the data can be queried.
If your website is not built using AEM Edge Delivery Services, it is recommended to set up Real Use Monitoring in standalone mode. To set up , simply add the following script to your pages.
For better performance, it is recommended loading the script after the Largest Contentful Paint (LCP) event
top – the page loading sequence has begun and first JavaScript code is being executed by the page. This event fires even before blocks are decorated or content is visible
viewblock – a block has scrolled into view and there is a chance that the content of that block is seen. The class name of the block will be shared in the source property.
viewmedia – an image or video has scrolled into view and there is a chance that the content of that block is seen. The URL of the image or video is shared in the target property.
**Source:** [https://www.aem.live/docs/rum-explorer](https://www.aem.live/docs/rum-explorer)
Every AEM Site, including Adobe Experience Manager Sites as a Cloud Service without Edge Delivery Services, collects metrics and data by default. This data is sampled, and used by Adobe to diagnose issues around performance, traffic acquisition, and conversion for customer sites.
Key metrics on the top left. These key metrics are split into business metrics (page views, visits, engagement) and performance metrics (Largest Contentful Paint, Cumulative Layout Shift, Interaction to Next Paint) and will update whenever you change the filters.
A chart on the bottom left that provides an at-a glance visualization of your data. The default visualization is to show page views and performance metrics over time.
A set of facets that allow you to drill down into the data on the right. Each facet comes with checkboxes that allow you to filter the full data set to only include matching page views and three kinds of metrics around performance, traffic acquisition, and engagement.
You can navigate to the top URLs bar chart from the URL facet in the sidebar. For each URL, you can see the distribution of performance metrics. Pages with good performance appear green, pages with poor performance red. For some pages there is not enough data, these are shown in gray.
Performance Focus
The default focus is the performance focus and it shows Largest Contentful Paint (LCP), Cumulative Layout Shift (CLS) and Interaction to Next Paint (INP).
Green indicators mean that this performance metric is in a good state, yellow means it needs improvement, and red means performance is poor.
Operational Telemetry does not track the user agents to preserve visitor privacy, but from the information available it can discern the broad device classes Mobile, Desktop, and Bot. Bot includes crawlers that access your site and execute JavaScript. The bot traffic you will see on the Operational Telemetry explorer is smaller than what you would see in your CDN statistics, as most bots do not execute JavaScript and do not try to mimic a visitor. An important exception are search engines, which do execute JavaScript and are visible in Operational Telemetry explorer.
You can see the CSS selector of the image (Media Source) and a preview of the image or video that has been seen (Media Target).
Facet: Viewblock
This facet allows you to identify the blocks that visitors have seen. The CSS selector includes the block name, and can include additional information such as dialog for elements that are fixed in the viewport and can't be scrolled away.
Whenever facet values have been selected in the sidebar and no conversion has been defined yet, the Engagement key metric area will feature a "redefine" button. Use the filters to select traffic that matches your defined criteria. In this example, we select visitors who have scrolled down far enough to see the footer of the page, so the criteria is a combination of the viewblock checkpoint and the Block CSS Selector (target).
**Source:** [http://www.aem.live/previous/byo-cdn-fastly-setup](http://www.aem.live/previous/byo-cdn-fastly-setup)
NB: The X-Push-Invalidation: enabled request header enables the push invalidation incl. long cache TTLs.
Your Fastly setup should not use Fastly’s Next Generation Web Application Firewall for requests that are going against hlx.live or any other Edge Delivery Services origin. Enabling WAF with Edge Delivery Services can lead to erroneous content being delivered.
**Source:** [http://www.aem.live/previous/byo-cdn-cloudfront-setup](http://www.aem.live/previous/byo-cdn-cloudfront-setup)
**Source:** [https://www.aem.live/docs/davidsmodel](https://www.aem.live/docs/davidsmodel)
A long time ago, in a galaxy far, far away, I got to a point where I realized that people had a lot of different options on how they could model content in a content repository specification that I was involved in.
The parameters and stakeholders feel very different today, as I am not primarily worried about the underlying infrastructure anymore but about the user experience of a person authoring content and reaching a great authoring experience across different content sources and to a lesser extent the ease of developing against those structures and being able have portable (block) code across projects and content sources.
This document should serve as a collection of “Content Modeling” or “Content Structure” best practices as they relate to Adobe Experience Manager and more importantly to an intuitive authoring experience across different authoring platforms. A good way of testing a content model, is to imagine an author working in different environments (eg. Word, Google Docs, AEM, Custom Authoring etc.) and making sure that the content model can easily be constructed in an intuitive manner across all possible content sources.
These “rules” are a reflection of lessons learned from first-hand authoring and authoring support and are rooted in the experiences working on real-world limitations of commonly used authoring environments like Microsoft Word Online or Google Docs, but also in the average knowledge of said tooling by the average author.
Rule #1: Blocks are not great for authoring
Generally blocks are not great as they are surfaced as tables on the authoring side. They provide a necessary framework for an author to indicate some special functionality or design for a certain component. For authors it is often easier to work in “Default Content” wherever possible.For developers blocks are a great way to componentize their work, so there is tension where the developer feels that having something in a block makes their lives easier, sacrificing authoring ease-of-use.
The number of blocks and block variants, as well as (section-) metadata that influence layout should be limited by a design system. Often variants or blocks can be inferred, meaning that for example a carousel containing a video or a quote with an image should not be its own (explicit) block or variant but can be inferred automatically from the content.
A lot of content that is referenced via URL (e.g. a video, modal, fragment or an embed) can often be auto blocked, and the author may just be able to paste the URL to get the desired result.
It is definitely an anti-pattern to have things that are represented natively as default content and put them into a block, so something like a Text, Heading or Image block yields a bad authoring perspective.
Rule #2: No nested blocks for authors
To a developer it might very often be tempting to nest complex structures, which in word document would lead to a table inside a table. As Rule #1 states that blocks are not desirable, nested blocks are definitely a lot worse.
Consider fragments (referencing other documents) or links (with auto blocking) to reduce the authoring complexity.
Generally we use a Column Span (merged cells) to denote the header with a block name in it. This is relatively straightforward and works well in word and google docs.There are definitely situations where more complex table structure make sense (eg. a portion of the block content being in two columns and another portion of the block content being in three columns) but it is important to understand that creating and managing these structures can be extremely difficult, especially in word online that has very enigmatic support for complex tables.
When referencing content sometimes developers think in references that are relative to host, the content repository or to their sharepoint / google drive. Authors (and most humans) often think of a URL as an opaque token that they copy/paste from their browser without deciphering them into protocol, hostname, pathname, etc.It is always advisable to just let authors work fully qualified URLs and let either AEM or a developer do the work of extracting eg. a pathname where needed. As a bonus the URL can and should link to something that is easily accessible for an author from their document.
I often find myself in a situation where a block has a list of references, something like a list of related articles, or a list of cards. In HTML a lot of those semantically should be considered lists (mostly <ul><il> combinations). For simple lists, something like some text (possibly with a link) or just regular links, a list in word or google docs may be ideal.
It turns out that list items that are more complex, are somewhere between “hard” to “practically impossible” for an author to keep that in a list in word or google drive.In that case it is much easier to have the list items be rows of a block table. A good example of that is cards block in the boilerplate project.
For simple lists where it is intuitive to have inferred semantics, eg. a related articles block in a blog post that just contains links to the articles that should be references, it may be easiest to just have a single table cell inside the block containing all the links and dropping the actual list in the word processor. From a code standpoint it is usually easy to just pull all the links from a block and not specifically worry about the details of a structure in that particular block.
In many design guides we find buttons as a common element across many blocks and default content. In many cases they are outlined in all their variations (eg. primary vs. secondary, sizes, colors, etc.) at the beginning of a design specification together with the specified colors and fonts.
In projects we found that it is intuitive for authors to treat links that are on a line by themselves as for a button. In many cases it is important to inherit from the block and section context that a particular button is in to make the authoring experience easy.
As an example, if a button (read, “link by itself on a line”) is a part of a hero block, it might assume a certain bigger size, or if a button is in a section that has an inverted background color it might need to automatically switch to a different foreground / background color combination.
There are cases where within a given section / block context the author needs to be offered a set of explicit choices (eg. primary vs. secondary button) and in those cases we use combinations of bold and italic, usually bold for an explicit primary button and italic for an explicit secondary button.
It is conceivable that within a given block / section context there are more than four options for an author to choose from, in which case other formatting options could be used like underline, strikethrough etc. however, this is extremely rare and usually an indication that a decision that should be made within the design system is delegated to the author, leading to a less intuitive authoring experience.
There are situations where this change results in too much a temporary SEO impact, in which case rewriting the URLs on the CDN may be the appropriate option, however this should only be done if there is a quantifiable business impact. long term it is more desirable to have a clean URL that maps directly to the corresponding file in sharepoint or gdrive.
In organizations this often happens naturally, and it is intuitive for organizations to break up their content teams similar to the structure of their URL space. In some cases the URL structure doesn’t align with authoring teams (and the corresponding access control groups). In such a case combining multiple AEM projects on the CDN tier tying together content from different sources may be the right approach if the complexity and size of a site (single domain) gets overwhelming.While your content source (Sharepoint and Google Drive) possibly supports complex access control models, it is desirable to keep Access Control as simple as possible from a management standpoint.
Particularly Sharepoint has best practices on access control complexity within a library, and creating access control complexity beyond that may yield undesirable results. In case you get to a place where it becomes unnatural to manage either the size of the content or the size and complexity in a single Site/Library or Shared Drive, it is likely that it makes sense to break things up into multiple different Site/Libraries or Shared Drives and blend the content together from different projects on the CDN.
Rule #9: Number of Blocks and Variants
Over the lifecycle of a website it is common that new blocks and variants are added. Especially for developers that are not very familiar with the existing block library of the project it is usually the easiest path to just add net new blocks or variants to make sure that there is no regression with existing content.
While it is probably not easy to avoid the sprawl of blocks and variants on projects that have a lot of functionality or justified requirements for a lot of visually diverse content within a single project, it is important to make sure that the core set of blocks and variant combinations that authors need to use commonly is limited. There are situations where special blocks are used infrequently on sites and often those are placed by developers initially, those blocks probably don’t need to be exposed to authors at the same level in documentation or a block library as the commonly used blocks.More generally, large block libraries and a lot of variant / section metadata combinations are less desirable. Maintaining a “minimum use” criteria for blocks and variants based on a content report is a good practice to deprecate and remove superfluous code from the block library that’s exposed to authors.
Rule #11: Use the block collection content models
The AEM Block Collection is a great source for well designed content models. If your block is producing a similar feature set as the one of the blocks in the Block Collection, the content model should be similar.
Along those lines, from an SEO standpoint it is only advisable to use fragments at times where having duplicate content is acceptable (meaning that the content inside a fragment doesn't carry significant SEO weight for that page), hence content that is relevant from an SEO standpoint should always be placed on the page directly.
It may be convenient at times to put extra information hidden away into image alt-texts, but this is only recommended in exceptional cases.Alt-texts often cannot be easily discovered by authors, there is very little indication about their existence in common document authoring environments (eg. word or google docs).Depending on the type of copy/paste operation the alt-text may be lost without the author noticing, and if the alt-text contains special semantics, authors will have to be familiar with specific semantics within the value of an alt-text of individual images on a per block basis.
There are situations where name/value pairs can be useful to indicate a configuration for a block similar to a section or page (via metadata). This should only be used in exceptional cases and largely for content that is not displayed as such, and is outside of the well established semantic model of document semantics. In section metadata processing the name value pairs get converted into data- attributes, which illustrates the model on how name/value pairs should be thought of in blocks that require configuration. Related to rule #1, it is definitely not recommended to map default content concepts and have name/value pairs for things like Heading, Image or Text.
**Source:** [https://www.aem.live/docs/setup-customer-sharepoint-user](https://www.aem.live/docs/setup-customer-sharepoint-user)
In order for the AEM service to access the authored content it needs a couple of information and setup. The AEM service (a cloud function) accesses the MS Graph API on behalf of a configured user. In order to do so, it needs to authenticate first in the context of an Application. This is important because the scopes given to the application define what permission the service has on the MS Graph API. For example, it should be allowed to read and write documents, but not to alter access control.
Click on “Connect User” and you should see a new login window, where you want to login with your technical user. This the the AEM Content Integration is requesting for more permissions to access sharepoint:
Once the user is registered, you should be able to preview a page.
Changing the user's password will invalidate the grant that is established when connecting the user. This will eventually cause an error in the sidekick. In order to prevent this, you need to reconnect the user, by clicking the disconnect button then connect it again.
**Source:** [https://www.aem.live/docs/setup-adobe-sharepoint](https://www.aem.live/docs/setup-adobe-sharepoint)
**Source:** [https://www.aem.live/docs/csp-strict-dynamic-cached-nonce](https://www.aem.live/docs/csp-strict-dynamic-cached-nonce)
Content Security Policy: strict-dynamic + (cached) nonce
This guide is very specific for mitigating Cross Site Scripting (XSS) attacks with a specific Content Security Policy configuration in AEM Edge Delivery Services and is not intended to be a general, exhaustive guide of all the Content Security Policy options and possibilities supported by the browser.
Important Note: Content Security Policies are meant as a last line of defense when other measures fail. It is not intended to replace the use of safe DOM APIs and proper sanitisation of user input by developers in the code. It will not cover every single attack path and it is not meant to. It is always recommended that developers code in a safe manner.
As a short summary: This content security policy will allow the execution of only those scripts which have the correct nonce value at top level (nonce component) and any script loaded by these and their descendants client-side, creating a trust chain, as long as the additional scripts are loaded via non-”parser-inserted” elements (strict-dynamic component). More information
Ease of deployment and maintenance on customer sites (through the use of strict-dynamic)
How well it fits in the AEM Edge Delivery Services architecture
The recommendation coming from the Google Lighthouse Report
This feature is currently available only for sites using version 5 of the AEM Edge Delivery Services architecture.
There are two components to the configuration:
Instructions below show how to mark trusted scripts in your repository and then how to configure the policy to be enforced.
After the enforcement is put in place, AEM will replace the aem part of the nonce in both the policy and the script attributes with a cryptographic random string, for every request that hits the rendering engine, generating new HTML markup from content. Once the HTML markup + headers is generated, it is cached on the CDN and is considered immutable.
Requests that hit the CDN cache will see the same nonce value until cache expiration.
Note: The content-security-policy-report-only header doesn’t offer any protection, it only allows you to test if there are any scripts which would be blocked when the policy is fully enforced through error messages.
This method can be useful for trying out the configuration in a branch, but has the disadvantage that it needs to be added to head.html and every other static HTML file from your repository.
If you are using Cloudflare as BYO CDN in front of AEM, please ensure that you are using the latest version of the Cloudflare Worker code, which removes the content-security-policy header for 304 response codes.
This ensures that the CDN does not return a content-security-policy header in a 304 response with a nonce value that conflicts with what your users already have in their browser cache.
Based on our current understanding and tests, no, that is not the case, given a set of assumptions, which hold true for typical sites implemented with AEM Edge Delivery Services.
Websites do not make modifications server-side to the HTML produced by AEM Edge Delivery Services (for example in the customer’s CDN).
Every new request that hits the AEM Edge Delivery Services’ HTML rendering pipeline will always receive a new nonce value.This effectively mitigates these types of attacks, because attackers trying to inject a <script> tag server side into the HTML cannot guess the new value of the nonce.
This type of Cross Site Scripting attack occurs client side, when the client side JavaScript injects user input (from query parameters, url fragments, author supplied information in HTML) without proper context specific encoding/sanitization into a unsafe DOM APIs which interpret the input as HTML or JavaScript, instead of text.
The list below shows which use of DOM APIs* are considered mitigated and which aren't.
Modern browsers should not execute <script> tags injected through these DOM APIs, according to the MDN documentation.
The following DOM APIs remain vulnerable, because looking up the value of the cached nonce can lead to a successful XSS.
The MDN documentation strongly discourages the use of these APIs.
whether the nonce is cached/known is irrelevant, scripts injected using this API are always executed when strict-dynamic.
usage of import API
It is important to note that CSPs don’t block every type of web attack and that’s why they are meant as an additional defense, rather than your main defense.
In AEM Edge Delivery Services the highly efficient use of the CDN cache is a key component of how Adobe delivers high performance, reliability and scalability.
With the current data outlined above, our understanding is that the theoretical disabling of the cache would benefit only a highly discouraged edge case (the usage of document.write / document.writeln), as the other cases don’t seem to depend on whether the nonce is cached or not.
There are a couple of reasons that make the use of hashes less efficient for this architecture:
The following research paper from Google has found the following problems, which we could confirm in practice for AEM Edge Delivery Services customers that did have host based content security policies:
We only apply the unique nonce value to scripts coming from head.html and static HTML files from your repository. These resources are considered trusted and controlled only by your developers. It is considered that if attackers can change these, they already can modify any code in your repository, thus trying to prevent XSS is no longer a concern. Scripts that could theoretically end up injected through any currently unknown method in the HTML will not receive the correct nonce value, even if they have the nonce="aem" attribute.
**Source:** [https://www.aem.live/5](https://www.aem.live/5)
**Source:** [https://www.aem.live/docs/teams](https://www.aem.live/docs/teams)
We create dedicated teams in Microsoft Teams for each AEM customer and invite business users, developers, and authors to it to answer your questions about authoring and development, coordinate your launch or migration, and help with best practices.
**Source:** [https://www.aem.live/docs/slack](https://www.aem.live/docs/slack)
We are available on dedicated Slack channels for AEM customers and the Adobe team is available to answer your questions. We create one Slack channel for each customer and invite business users, developers, and authors to the channel to coordinate your launch or migration, answer questions about authoring and development, and help with best practices.
**Source:** [http://www.aem.live/docs/setup-adobe-sharepoint](http://www.aem.live/docs/setup-adobe-sharepoint)
**Source:** [http://www.aem.live/docs/setup-customer-sharepoint-user](http://www.aem.live/docs/setup-customer-sharepoint-user)
**Source:** [http://www.aem.live/docs/limits](http://www.aem.live/docs/limits)
The following limits below are applied on preview operations for content that is ingested from Sharepoint or Google Drive. If exceeded most of them produce an error in sidekick for authors.
Other file types may be uploaded through code (eg. through GitHub) or depending on the use case created on the client-side (eg. .ics, etc.).
Rate Limits (number of preview operations per time)
AEM Code Sync/GitHub Limits
To keep the project size manageable we limit the number and size of files that we synchronize from your GitHub repository, as well as the number of active branches/refs. If you have more files in your repo use .hlxignore to avoid syncing them..
Rate Limits (number of deploy operations per time)
Rate limits are inferred from GitHub.
The following limits below are applied on preview operations for content that is ingested via a bring your own content source. If exceeded most of them produce an error in sidekick for authors.
Admin API Limits
The admin API is rate limited to 10 requests per second, per project for all operations. Throttled requests will receive a response with a 429 status code.
Use the respective bulk APIs for operating on large amounts of resources.
**Source:** [http://www.aem.live/docs/slack](http://www.aem.live/docs/slack)
**Source:** [http://www.aem.live/docs/teams](http://www.aem.live/docs/teams)
**Source:** [http://www.aem.live/developer/block-collection/video](http://www.aem.live/developer/block-collection/video)
**Source:** [http://www.aem.live/developer/ue-tutorial](http://www.aem.live/developer/ue-tutorial)
This tutorial will get you up-and-running with a new Adobe Experience Manager (AEM) project, authored in Universal Editor and publishing to Edge Delivery. In about thirty minutes, you will have created your own site and be able to create, preview, and publish your own content, styling, and add new blocks.
Use the project boilerplate to create your code repository
The fastest and easiest way to get started following AEM best practices is to create your repository using the Boilerplate GitHub repository as a template.
This tutorial uses the standard AEM project boilerplate, which is the best solution for many projects. However you can also use the Commerce project boilerplate, if your AEM Authoring with Edge Delivery Services project needs to integrate with Adobe Commerce. The steps remain the same.
Navigate to the GitHub page of the boilerplate appropriate for your project.
For most projects: https://github.com/adobe-rnd/aem-boilerplate-xwalk
For projects that integrate with Adobe Commerce: https://github.com/adobe-rnd/aem-boilerplate-xcom
Click on Use this template and select Create a new repository.
You will need to be signed in to GitHub to see this option.
By default, the repository will be assigned to you. Adobe recommends leaving the repository set to Public. Provide a repository name and description and click Create repository.
In a new tab in the same browser, navigate to https://github.com/apps/aem-code-sync and click Configure.
Click Configure for the org where you created your new repository in the previous step.
On the AEM Code Sync GitHub page under Repository access, select Only select repositories, select the repository that you created in the previous step, and then click Save.
Once AEM Code Sync is installed, you receive a confirmation screen. Return to the browser tab of your new repository.
You now have your own GitHub repository for developing your own Edge Delivery Services project, based on Adobe’s best-practices boilerplate.
Now that you have your GitHub project, you need to link the repository to your AEM authoring instance.
In your new GitHub project, click the fstab.yaml file to open it and then the Edit this file icon to edit it.
Changing the mount point tells Edge Delivery Services where to find the content of the site.
Return to the root of your repository and click on paths.json and then the Edit this file icon.​​
The default mapping will use the name of the repository. Update the default mappings as required for your project, for example /content/<site-name>/:/ and similar, and click Commit changes….
The mappings tell Edge Delivery Services how to map the content in your AEM repository to the site URL.
With your GitHub project set up and linked to your AEM instance, you are ready to create and publish a new AEM site using Edge Delivery Services.
Download the latest AEM authoring with Edge Delivery Services site template from GitHub appropriate to your project.
For most projects: https://github.com/adobe-rnd/aem-boilerplate-xwalk/releases
For projects that integrate with Adobe Commerce: https://github.com/adobe-rnd/aem-boilerplate-xcom/releases
Upload the AEM authoring with Edge Delivery Services site template that you downloaded from GitHub.
GitHub URL - Use the URL of the GitHub project you created in the previous step.
Publishing Your New Site to Edge Delivery Services
Now that you have a working Edge Delivery Services project with AEM authoring, you can begin customizing it by creating and styling your own blocks.
**Source:** [https://www.aem.live/developer/universal-editor-blocks](https://www.aem.live/developer/universal-editor-blocks)
Creating Blocks Instrumented for use with the Universal Editor
Learn how to create blocks instrumented for the Universal Editor when using AEM authoring as your content source by adding components, loading component definitions in the Universal Editor, publishing pages, implementing block decoration and styles, bringing the changes to production, and verifying them.
To create your blocks, you will need some existing knowledge of AEM authoring with Edge Delivery Services projects as well as the Universal Editor. You should also already have access to Edge Delivery Services and be familiar with its basics including:
Adding a New Block to Your Project
Let’s build a block to render a memorable quote on your page.
To simplify this example, all changes are made to the main branch of the project repository. Of course for your actual project, you should follow development best practices by developing on a different branch and reviewing all changes via pull request before merging to main.
Adobe recommends that you develop blocks in a three-phased approach:
Create the definition and model for the block, review it, and bring it to production.
Create content with the new block.
Implement the decoration and styles for the new block.
The following quote block example follows this approach.
Create Block Definition and Model
Clone the GitHub project locally that you created in the Getting Started – Universal Editor Developer Tutorial and open it in an editor of your choice.
Edit the component-definition.json file at the root of the project and add the following definition for your new quote block and save the file.
Edit the component-models.json file at the root of the project and add the following model definition for your new quote block and save the file.
Edit the component-filters.json file at the root of the project and add the quote block to the filter definition to allow the block to be added to any section and save the file.
Committing to main is for illustrative purposes only. Follow best practices and use a pull request for actual project work.
Create content with the block
Now that your basic quote block is defined and committed to the sample project, you can add a quote block to an existing page.
In the Universal Editor, select a section. In the properties panel, tap or click the Add icon and then select your new Quote block from the menu.
The page is reloaded and the quote block is added to the bottom of the selected section with the default content specified in the component-definitions.json file.
The quote block can be selected and edited as any other block either in-place or in the properties panel.
Style the block
Now that you have a working quote block you can apply styling to it.
Create a quote folder under the blocks folder.
In the new quote folder, add a quote.js file to implement block decoration by adding the following JavaScript and save the file.
In the quote folder, add a quote.css file to define the styling for the block by adding the following CSS code and save the file.
Return to your browser tab of the Universal Editor where you were editing the page of your project and reload the page to view your styled block.
See the now styled quote block on the page.
Congratulations! You now have a fully working and styled quote block. You can use this example as a basis for designing your own project-specific blocks.
Block options
If you need a block to look or behave slightly differently based on certain circumstances (but not different enough to become a new block in itself), you can let authors choose from block options.
By adding a classes property to the block, the property is rendered in the table header for simple blocks, or as value list for items in a container block.
This guide had you commit directly to the main branch for simplicity’s sake. For experimentation in a sample repository, this is usually not an issue. For actual project work, you should follow development best practices by developing on a different branch and reviewing all changes via pull request before merging to main.
When you are not developing on the main branch, you can append ?ref=<branch> in the Universal Editor location bar to load the page from your branch. <branch> is the branch name as it would be used for your project’s preview or live URLs, e.g. https://<branch>--<repo>--<owner>.aem.page.
Blocks for AEM authoring and document-based authoring
On certain projects, you may want to support both AEM authoring as your content source using the Universal Editor as well as document-based authoring. To minimize development time and ensure the same site experience, you can create one set of blocks to support both use cases.
In AEM authoring, you declare a model and provide naming conventions. Data is then rendered in table-like block structures using Edge Delivery in the same way as if the table would have been created manually using document-based authoring.
To achieve this, certain assumptions are made such as for a simple block like a teaser that all properties and groups of properties are rendered in 1…n rows with a single column each. For blocks that have 1…n items (such as carousel and cards) the items are appended after these rows with one row each and a column for each property/group of properties.
If you follow the same approach for document-based authoring you can reuse your AEM authoring blocks.
The following example of a teaser block follows the recommended approach and could be used between document-based and AEM authoring.
Now that you know how to create blocks, it is essential to understand how to model content in a semantic way to achieve a lean developer experience.
**Source:** [https://www.aem.live/developer/ue-tutorial](https://www.aem.live/developer/ue-tutorial)
**Source:** [https://www.aem.live/developer/component-model-definitions](https://www.aem.live/developer/component-model-definitions)
Projects using AEM authoring as a content source inherit the majority of the mechanics of any other Edge Delivery Services project, independent of the content source or authoring method.
In AEM, this content is implemented as components with very simple, pre-defined models, which include everything that can be serialized in Markdown and HTML.
The model of these components is part of the boilerplate for projects with AEM authoring as the content source.
Blocks are used to create richer content with specific styles and functionality. In contrast to default content, blocks do require additional semantics.
Blocks are essentially pieces of content decorated by JavaScript and styled with a stylesheet.
Block model definition
When using AEM authoring as your content source, the content of blocks must be modelled explicitly in order to provide the author the interface to create content. Essentially you need to create a model so the authoring UI knows what options to present to the author based on the block.
The component-models.json file defines the model of blocks. The fields defined in the component model are persisted as properties in AEM and rendered as cells in the table that makes up a block.
Note that not every block must have a model. Some blocks are simply containers for a list of children, where each child has its own model.
It is also necessary to define which blocks exist and can be added to a page using the Universal Editor. The component-definitions.json file lists the components as they are made available by the Universal Editor.
It is possible to use one model for many blocks. For example, some blocks may share a model that defines a text and image.
For each block, the developer:
Must use the core/franklin/components/block/v1/block resource type, the generic implementation of the block logic in AEM.
Must define the block name, which will be rendered in the block’s table header.
The block name is used to fetch the right style and script to decorate the block.
The model ID is a reference to the component’s model, which defines the fields available to the author in the properties panel.
The filter ID is a reference to the component’s filter, which allows to change the authoring behavior, for example by limiting which children can be added to the block or section, or which RTE features are enabled.
All of this information is stored in AEM when a block is added to a page. If either the resource type or block name are missing, the block will not render on the page.
WARNING: While possible, it is not necessary or recommended to implement custom AEM components. The components for Edge Delivery Services provided by AEM are sufficient and offer certain guard rails to ease development.
The components provided by AEM render a markup that can be consumed by helix-html2md when publishing to Edge Delivery Services and by aem.js when loading a page in the Universal Editor. The markup is the stable contract between AEM and the other parts of the system, and does not allow for customizations. For this reason, projects must not change the components and must not use custom components.
Block structure
The properties of blocks are defined in the component models and persisted as such in AEM. Properties are rendered as cells in the block’s table-like structure.
Simple blocks
In the simplest form, a block renders each property in a single row/column in the order the properties are defined in the model.
Key-value block
In other cases however, the block is read as a key-value pair-like configuration.
An example of this is the section metadata. In this use case, the block can be configured to render as a key-value pair table. Please see the section Sections and Section Metadata for more information.
Container blocks
Both of the previous structures have a single dimension: the list of properties. Container blocks allow adding children (usually of the same type or model) and hence are two-dimensional. These blocks still support their own properties rendered as rows with a single column first. But they also allow adding children, for which each item is rendered as a row and each property as a column within that row.
In the following example, a block accepts a list of linked icons as children, where each linked icon has an image and a link. Notice the filter ID set in the data of the block in order to reference the filter configuration.
Creating semantic content models for blocks
With the mechanics of block structure explained, it is possible to create a content model that maps content persisted in AEM one-to-one to the delivery tier.
Early in every project, a content model must be carefully considered for every block. It must be agnostic to the content source and authoring experience in order to allow authors to switch or combine them while reusing block implementations and styles. More details and general guidance can be found in David’s Model (take 2). More specifically, the block collection contains an extensive set of content models for specific use cases of common user interface patterns.
NOTE: Block implementations can deconstruct the content and replace the block with a client-side-rendered DOM. While this is possible and intuitive for a developer, it is not the best practice for Edge Delivery Services.
Class names - The classes property is treated as block options and rendered in the table header for simple blocks, or as value list for items in a container block. It is useful if you want to style a block differently, but don’t need to create an entirely new block.
For example, a teaser component may allow the author to only create a subtitle, title, and a single paragraph description combined with a maximum of two call-to-action buttons. Grouping these elements together yields a semantic markup that can be styled without further action.
Sections and section metadata
The same way a developer can define and model multiple blocks, they can define different sections.
The content model of Edge Delivery Services deliberately allows only a single level of nesting, which is any default content or block contained by a section. This means in order to have more complex visual components that can contain other components, they have to be modelled as sections and combined together using auto-blocking client side. Typical examples of this are tabs and collapsible sections like accordions.
A section can be defined in the same way as a block, but with the resource type of core/franklin/components/section/v1/section. Sections can have a name and a filter ID, which are used by the Universal Editor only, as well as a model ID, which is used to render the section metadata. The model is in this way the model of the section metadata block, which will automatically be appended to a section as a key-value block if it is not empty.
The model ID and filter ID of the default section is section. It can be used to alter the behavior of the default section. The following example adds some styles and a background image to the section metadata model.
The following example defines a tab section, which can be used to create a tabs block by combining consecutive sections with a tab title data attribute into a tabs block during auto-blocking.
Page metadata
Documents can have a page metadata block, which is used to define which <meta> elements are rendered in the <head> of a page. The page properties of pages in AEM as a Cloud Service map to those that are available out-of-the-box for Edge Delivery Services, like title, description, keywords, etc.
Before further exploring how to define your own metadata, please review the following documents to understand the concept of page metadata first.
Bulk metadata
It is also possible to define additional page metadata in two ways.
Metadata spreadsheets
It is possible to define metadata on a per path or per path pattern basis in a table-like way in AEM as a Cloud Service. There is an authoring UI for table-like data available that is similar to Excel or Google Sheets.
Many of the default page properties available in AEM are mapped to the respective page metadata in a document. That includes for example title, description, robots, canonical url or keywords. Some AEM-specific properties are available as well:
It is also possible to define a component model for custom page metadata, which will be made available to the author in the Universal Editor.
To do so, create a component model with the ID page-metadata.
**Source:** [https://www.aem.live/docs/authoring-tabular-data](https://www.aem.live/docs/authoring-tabular-data)
For any AEM with Edge Delivery Services site, there is a need to maintain lists of tabular data such as for key-value mappings. These can be lists of many different values such as metadata and redirects. Edge Deliver Services allows you to maintain such tabular lists using an intuitive tool: the spreadsheet. AEM translates these spreadsheets into JSON files that can easily be consumed by your website or web application.
Configurations such as for CDN setups
This document uses the example of redirects to illustrate how to create such spreadsheets. See the previously-linked topics in the Edge Delivery Services documentation for details of each use case.
TIP: For more information on how spreadsheets in general work with Edge Delivery Services, please see the document Spreadsheets and JSON.
Open the root of your project in GitHub.
Either commit to main or create a pull request as per your process.
TIP: For more information about path mappings, please see the document Path Mapping for Edge Delivery Services.
Configuration - Such as for cache invalidation
For Configuration, Headers and Metadata make sure to add a mapping to publish them to their default locations:
Metadata: /metadata.json
NOTE: You do not need to create a spreadsheet to manage indexing for AEM as a Cloud Service with Edge Delivery Services projects. If you wish to create your own indices, please follow this documentation to create your own helix-query.yaml file.
**Source:** [https://www.aem.live/docs/configuration-templates](https://www.aem.live/docs/configuration-templates)
You must have already created your Edge Delivery Services project with AEM as your authoring source. Please see the tutorial for more information.
CDN
This tab allows you to select which CDN you use with your project and define its options.
CDN Vendor - Define which CDN service you will use with your project. Options vary depending on which service you select.
This tab allows you to define additional metadata resources for your project.
Additional Metadata - Provide a path for a metadata sheet
For additional information, please see the document Bulk Metadata for more information.
For example, you may have a single API key for your CDN for your organization. However your individual, localized sites would have different host names. You can set the API key in the blueprint, which is rolled out to your localized sites. For each site, you can break inheritance for the host name and set it for each site.
For more information on how to set up MSM for your Edge Delivery Services with AEM authoring project, please see the document Multi site management with AEM authoring as your content source.
Configuration templates support a reasonable subset of configurations that are common and possible. There may be edge cases that configuration templates do not cover.
**Source:** [https://www.aem.live/developer/repoless-multisite-manager](https://www.aem.live/developer/repoless-multisite-manager)
You can use MSM to create an entire content structure for your brand across locales and languages, authoring the content centrally. Your localized sites can then each be delivered by Edge Delivery Services, leveraging a central code base.
In order to leverage MSM on Edge Delivery Services with AEM authoring, you must enable the repoless feature.
This document assumes that you have already created a basic localized site structure for your project. It uses the following structure for the website brand with a presence in Switzerland and Germany as an example.
Content in language-masters is the source of Live Copies for the localized sites: Germany (de) and Switzerland (ch). The goal of this document is to create Edge Delivery Services sites that all use the same code base for each localized site.
Create new Edge Delivery Services sites for your localized pages.
Update cloud configuration in AEM for your localized sites.
That is, you will have a configuration for the root of the website brand’s content (/content/website) used by the blueprints and a configuration used by each localized site (Switzerland and Germany).
In the Create Configuration dialog, provide a descriptive Name for your localized site (such as Switzerland) and for the Title use the same title of the localized size (in this case ch).
Create configurations for each localized site you need. In the case of website, you would need to create a configuration for de as well alongside the ch configuration.
Once the configurations are created, you need to ensure that the localized sites use them.
Select the localized site such as Switzerland.
In Cloud Configuration field, use the path browser to select the configuration you created for your localized site such as Switzerland under /conf/website/ch.
Assign the respective configurations to the additional localized sites. In the case of website, you would need to assign the /conf/website/de configuration to the Germany site as well.
Create new Edge Delivery Services sites for your localized pages
To connect more sites to Edge Delivery Services for a multi-region, multi-language site setup, you must set up a new aem.live site for each of your AEM MSM sites. There is a 1:1 relationship between AEM MSM sites and aem.live sites with a shared Git repository and code base.
For this example, we will create the site website-ch for the Swiss presence of website, whose localized content is under the AEM path /content/website/ch.
Adapt the admin block to define the users who should have full administrative access to the site.
Verify that the public configuration of your new site is working by calling https://main--website-ch--<your-github-org>.aem.page/config.json and verifying the content of the returned JSON.
Repeat the steps to create additional localized sites. In the case of website, you would need to create a website-de site for the German presence as well.
Update Cloud Configurations in AEM for Your Localized Pages
Your pages in AEM must be configured to use the new Edge Delivery Sites you created in the previous section for your localized presence. In this example, content under /content/website/ch needs to know to use the website-ch site you created. Similarly content under /content/website/de needs to use the website-de site.
Sign into the AEM author instance and go to Tools → Cloud Services → Edge Delivery Services Configuration.
Select the configuration that was automatically created for your project and then the folder that was created for the localized page. In this case, that would be Switzerland (ch).
In the Edge Delivery Services Configuration window:
Provide your GitHub organization in the Organization field.
Visit your new Edge Delivery Services site for that localized page at https://main--website-ch--<your-github-org>.aem.page.
**Source:** [https://www.aem.live/developer/repoless-authoring](https://www.aem.live/developer/repoless-authoring)
By default, AEM is tightly bound to your code repository, which meets the majority of use cases. However you may have multiple sites that differ mostly in their content, but could leverage the same code base.
Rather than creating multiple GitHub repositories and running each site off a dedicated GitHub repository while keeping them in sync, AEM supports running multiple sites from the same codebase.
This simplified setup, which eliminates the need for code replication is also known as “repoless”, because all but your first site don’t need a GitHub repository of their own.
There are several steps to activate repoless functionality for your project. Please substitute your own site and GitHub org information appropriately.
Validate that the public configuration has been set and is available with a cURL command similar to the following.curl 'https://main--<your-aem-project>--<your-github-org>.aem.live/config.json'
Sign into the AEM author instance and go to Tools → Cloud Services → Edge Delivery Services Configuration and select the configuration that was automatically created for your site and tap or click Properties in the tool bar.
In the Edge Delivery Services Configuration window, select the Authentication tab and copy the value for the technical account ID.
Since you now use the configuration service, you can remove fstab.yaml and paths.json from your Git repository.
Now you are ready to make the necessary changes to your Edge Delivery Services in AEM.
In the Edge Delivery Services Configuration window, change project type to aem.live with repoless config setup and tap or click Save & Close.
Visit your published site at https://main--<your-aem-project>--<your-github-org>.aem.page/ and verify that the changes are properly reflected.
The most common issue is the page component fails with 404 errors.
component-definition.json etc. can not be loaded
**Source:** [https://www.aem.live/developer/repoless-environments](https://www.aem.live/developer/repoless-environments)
In this example, we are assuming that a production site has already been created for the project called wknd whose GitHub repo is also called wknd.
Create new Edge Delivery Services sites for your production environment.
Create New Edge Delivery Services Sites for Your Production Environment
Verify that the public configuration of your new site is working by calling https://main--website-prod--<your-github-org>.aem.page/config.json and verifying the content of the returned JSON.
Your production AEM must be configured to use the new Edge Delivery Sites you created in the previous section for a dedicated production site. In this example, content under /content/website on your production environment needs to know to use the website-prod site you created.
Sign into the AEM production instance and go to Tools → Cloud Services → Edge Delivery Services Configuration.
Visit your new Edge Delivery Services site for that page at https://main--website-prod--<your-github-org>.aem.page.
Once you have configured your project with repoless staging and production environments, you can manage code for them independently. The following diagram illustrates the relationship of the content in your various environments in AEM, Edge Delivery Services sites, and your GitHub repositories.
**Source:** [https://www.aem.live/developer/authentication-setup-site-for-aem-authoring](https://www.aem.live/developer/authentication-setup-site-for-aem-authoring)
aem.live supports token-based authentication. When using AEM authoring as your content source, site authentication is usually applied to both the preview and publish sites, but can also be configured to only protect either site individually.
In the Edge Delivery Services Configuration window, select the Authentication tab, provide the Site Authentication Token, which you copied previously.
**Source:** [https://www.aem.live/developer/authoring-path-mapping](https://www.aem.live/developer/authoring-path-mapping)
To be able to use AEM authoring as your content source and publish your content to Edge Delivery Services, you must set up your project’s path mapping. This mapping has two purposes.
It controls which content (pages, sheets, assets, etc.) are published to Edge Delivery Services.
The second entry controls the mapping of the .helix/config.json to the corresponding spreadsheet page in the AEM authoring repository.
In this example, all pages stored under /content/aem-boilerplate/... will be publicly accessible on the Edge Delivery Services site directly under https://main--my-site--org.aem.live/.....
TIP: All tabular data managed as spreadsheets (e.g. metadata, redirects, and taxonomy) are typically published as .json API URLs on Edge Delivery Services. To do so, they must be individually listed in the mapping configuration. Please see the document Using Spreadsheets to Manage Tabular Data for more information.
The includes configuration controls which content paths are actually replicated to Edge Delivery Services. It can hold any array of paths as well and typically contains the site’s top-level root page.
Assets used on Edge Delivery Services pages are typically published alongside the webpage. They will be exported from the AEM authoring instance to Edge Delivery Services automatically.
TIP: If you have a use case where you want assets published directly to Edge Delivery Services (for example you would like images or PDFs to be directly accessible by their URLs outside of a page context), you must add the DAM paths to the includes section of the configuration as well. For example, if an asset root folder such as /content/dam/my-site/documents containing a set of PDF should be publicly accessible via /assets/..., an entry must be added to the includes section of the configuration.
If the project does not use the configuration service, the paths mapping is configured via a paths.json file in your project’s GitHub repository.
See https://github.com/adobe-rnd/aem-boilerplate-xwalk/blob/main/paths.json for an example.
**Source:** [https://www.aem.live/developer/anatomy-of-a-helix-project](https://www.aem.live/developer/anatomy-of-a-helix-project)
**Source:** [https://www.aem.live/docs/authoring-taxonomy](https://www.aem.live/docs/authoring-taxonomy)
These tags are useful not only for you and your authors in organizing your content, but can also be for your readers as well. Tags and their taxonomy can be used in components on the page to help your readers navigate your content.
TIP: Please see the document Model Definitions, Fields, and Component Types for more information about the AEM Tag field available to the Universal Editor, which can work with your taxonomy.
Like when managing and publishing tabular data for your Edge Delivery Services site, you need to update your paths.json file of your project to allow publication of your taxonomy data.
**Source:** [http://www.aem.live/developer/da-tutorial](http://www.aem.live/developer/da-tutorial)
You have node / npm installed for local development.
Document Authoring (DA) is an alternative to SharePoint or Google Drive that provides a document-based authoring interface focused on the AEM Document model (Blocks, Sections, etc.). It provides an SDK, APIs, and built-in Adobe technologies.
The fastest and easiest way to get started following AEM best practices is to create your repository using the AEM Block Collection GitHub repository as a template. You can find it here: https://github.com/aemsites/da-block-collection
Click the Use this template button and select Create a new repository, and select the user or org you would like to own this repository.
The only remaining step in GitHub is to install the AEM Code Sync GitHub App on your repository by visiting this link: https://github.com/apps/aem-code-sync/installations/new. This app will sync code changes to AEM.
Copy your GitHub repo URL. In our example, this would be: https://github.com/da-sites/da-tutorial
Upon landing back in GitHub, paste the code snippet and commit the changes. You can close the GitHub tab when you are finished committing your changes.
Edit and preview your content
One of the unique features of DA is the ability to get a live preview of your document. Click the preview tab to expand the live preview pane.
Once the live preview pane is open, change the document. Below, we have changed the congrats text. You will see your changes reflected in the preview pane on the right.
Preview your content from DA
In addition to the AEM Sidekick, DA provides the ability to preview and publish your content. Select the paper airplane in the top right of the page and click preview.
Your page will open in a new tab with your changes. You are now looking at a staged, or preview, version of your page.
Publish your content using AEM Sidekick
The next step is to publish the page using AEM Sidekick. If you have not already done so, install the AEM Sidekick Chrome extension.
Navigate back to your previewed page and toggle the Sidekick extension to see Sidekick at the bottom of your page. Click the Publish button to push your page live.
**Source:** [https://www.aem.live/developer/font-fallback](https://www.aem.live/developer/font-fallback)
Loading a custom font (a font which is not known by default by all browsers) can easily introduce some delays in the loading sequence and a CLS (Cumulative Layout Shift) problem. This is true for the first page load on your site, until the font is cached by the browser.
The idea of the font fallback is to scale a browser default font so that when applied to the content of a page, the content takes up the same "space" with the font fallback and with the custom font. Like this, you can swap one with the other without a layout shift. If you use a default font that looks “similar” enough to the custom font, those few milliseconds of first-time page load will look really close to the experience you want to provide with the custom font. You can then defer the custom font loading or at least make it non-blocking in the loading sequence.
Edge cases
You will find more technical details and other tools directly In the extension repository: https://github.com/adobe/helix-font-fallback-extension
**Source:** [http://www.aem.live/developer/block-collection/headings](http://www.aem.live/developer/block-collection/headings)
According to Web best practices there should only be a single Heading 1 per page, which will also be used as the default title for the document.
As headings are default content they are styled in project or block CSS code. There is usually no JavaScript code used.
**Source:** [http://www.aem.live/developer/block-collection/text](http://www.aem.live/developer/block-collection/text)
The first portion of the first text paragraph serves as the default description for the a page if nothing else is specified in metadata.
As text is Default Content it is styled in project or block CSS code. There is usually no JavaScript code used.This code is included in boilerplate, there is no need to copy it.https://github.com/adobe/helix-project-boilerplate/blob/27e8571592220da8ded7c8a7e5064d982f7cfe76/styles/styles.css#L45-L51
**Source:** [http://www.aem.live/developer/block-collection/images](http://www.aem.live/developer/block-collection/images)
The first image on a page will automatically become the image that is used in metadata (for social media and messaging applications) unless defined otherwise in metadata.
As images are considered Default Content they are styled in project or block CSS code. There is usually no JavaScript code used.This code is included in boilerplate, there is no need to copy it.
**Source:** [http://www.aem.live/developer/block-collection/lists](http://www.aem.live/developer/block-collection/lists)
As lists are considered Default Content they are styled in project or block CSS code. There is usually no JavaScript code used.This code is included in Boilerplate, there is no need to copy it.
**Source:** [http://www.aem.live/developer/block-collection/links](http://www.aem.live/developer/block-collection/links)
As links are considered Default Content they are styled in project or block CSS code. There is usually no JavaScript code used.There is no link related styling code in the boilerplate project.
**Source:** [http://www.aem.live/developer/block-collection/buttons](http://www.aem.live/developer/block-collection/buttons)
Bold and Italic (<strong> and <em>) and possibly combinations thereof are used to specify certain types of buttons. There are often primary and secondary buttons and the default styling is usually defined for default content and/or specified by a containing block, and Bold and Italic can be used to specify alternative variations of buttons.
As Buttons are considered Default Content they are styled in project or block CSS code.
There is Javascript code for decoration purposes that is included in the default boilerplate behavior and it usually remains unchanged.Decoration CodeThe CSS Styling is very project specific and gets adjusted as needed for a project or block by block.
**Source:** [http://www.aem.live/developer/block-collection/code](http://www.aem.live/developer/block-collection/code)
Formatting something in word or gdoc as a fixed font (eg. Courier New) will automatically output a <code> element or a <code> and <pre> block for multiline.
**Source:** [http://www.aem.live/developer/block-collection/sections](http://www.aem.live/developer/block-collection/sections)
Sections are the top level grouping mechanism in documents, think of them as containers for a set of default content and blocks. Learn more about the Document Structure here.
Technically a section just introduces a <div> wrapper in the markup delivered around all the blocks and default content contained in the section.
In most cases generic sections don’t have much styling code beyond project specific box layout (eg. margins, padding, max-width) and are sometimes augmented with section metadata to control styling (often background colors or images).
**Source:** [http://www.aem.live/developer/block-collection/icons](http://www.aem.live/developer/block-collection/icons)
While some icons need to be in the code (icons referenced in blocks for example), there are times when authors need to add and reference new icons and update them on an ongoing basis. These icons can and should live with the content under an /icons/ folder in the content source (eg. Sharepoint or Google Drive). These icons can also be referenced the exact same way using the :<iconname>: notation. This will allow marketers to add and update icons they need for content without any dependency on a code change.
**Source:** [http://www.aem.live/developer/block-collection/hero](http://www.aem.live/developer/block-collection/hero)
**Source:** [http://www.aem.live/developer/block-collection/columns](http://www.aem.live/developer/block-collection/columns)
**Source:** [http://www.aem.live/developer/block-collection/embed](http://www.aem.live/developer/block-collection/embed)
**Source:** [http://www.aem.live/developer/block-collection/fragment](http://www.aem.live/developer/block-collection/fragment)
**Source:** [http://www.aem.live/developer/block-collection/table](http://www.aem.live/developer/block-collection/table)
**Source:** [http://www.aem.live/developer/block-collection/accordion](http://www.aem.live/developer/block-collection/accordion)
**Source:** [http://www.aem.live/developer/block-collection/breadcrumbs](http://www.aem.live/developer/block-collection/breadcrumbs)
This code is included in the header block in AEM Block Collection, simply copying the .css file and the .js file will add this block to your project.
Block Code
**Source:** [http://www.aem.live/developer/block-collection/carousel](http://www.aem.live/developer/block-collection/carousel)
**Source:** [http://www.aem.live/developer/block-collection/modal](http://www.aem.live/developer/block-collection/modal)
The modal is not a traditional block. Instead, links to a /modals/ path automatically create a modal.
This code is included in AEM Block Collection, simply:
Block CodeScripts Code
**Source:** [http://www.aem.live/developer/block-collection/quote](http://www.aem.live/developer/block-collection/quote)
**Source:** [http://www.aem.live/developer/block-collection/search](http://www.aem.live/developer/block-collection/search)
This code is included in AEM Block Collection, simply copying the .css file and the .js file will add this block to your project.
**Source:** [http://www.aem.live/developer/block-collection/tabs](http://www.aem.live/developer/block-collection/tabs)
**Source:** [http://www.aem.live/developer/block-collection/form](http://www.aem.live/developer/block-collection/form)
**Source:** [http://www.aem.live/developer/block-party/](http://www.aem.live/developer/block-party/)
The Block Party is a place for the AEM developer community to showcase what they have built on AEM sites. It also allows others to avoid reinventing the wheel and reuse these blocks / code snippets / integrations built by the community and tweak the code as necessary to fit their own projects.
If you are an AEM Developer and would like to submit your cool block / code snippet or integration, please enter your submission using this form.
Sidekick plugindylandepass
Sidekick Library
Othersdkuntze
This is a GitHub workflow that publishes a page from a defined location(s) to a defined base directory with a YYYY/MM/DD/ structure based on the publish time. This mimics the WordPress publishing flow for sites that are migrated from that platform.
Blockbstopp
This search block ranks search results. Rank is based on which index property terms were found, and order within rank is based on number of total matches.
Blockakasjain2
Photo gallery block displays images in a grid layout. When an image is clicked, it opens a modal with options for Slideshow, Next/Previous navigation, thumbnails for quick selection, and image title, if provided.
This component makes it easy for users to browse through a collection of images in a visually engaging way.
Plugin that will help users to view Scheduled actions and Schedule Preview Publish, UnPublish actions
Sidekick library generator
This is a tool to generate the sidekick library. It scrapes the whole site and generates the examples from the actual usage of the block in the site.
Faintly - HTML Templating for AEM Blocks
Faintly is an HTML templating library meant to be used with AEM Edge Delivery for rendering blocks. Its syntax is inspired by and may faintly resemble that of Sightly/HTL.
Blockmeejain
Blockasthabh23
This block retrieves and displays details of AEM community events, including YouTube video recordings, which are added to Google Sheets through Zapier Automation.
BlockTekno-Point
The WYSIWYG Table block simplifies table creation in the Universal Editor, allowing for dynamic column and row management. Each top-level  defines a row, and nested  elements represent the cells in that row. This approach eliminates the need to update the component model for new columns, streamlining content editing and enhancing flexibility.
Blockkronnox
BlockRitwikSrivastava
This block allows you to add hotspots over an image, with full control over their position. Authors can easily configure the top and left coordinates directly within the document. Hotspot content can include text, images, or videos.
Blockyugandhar02
Video block
Use this block for placing videos on your webpage. Supports placing videos in cards, columns, banner, modal etc. with poster image. Can be used to deliver videos from AEM Dynamic Media.
AEM Edge Delivery blocks as web components
Easily convert an Edge Delivery block to a web component to be used in other sections of the site that are not on AEM Edge Delivery. This can be useful when you have part of the site on AEM Edge Delivery and another part on a different platform so that you can reuse the same header and footer from AEM across the site.
Blockmiakobchuk
Lottie player integration
Shows how to add a lottie-player animation without negatively affecting lighthouse score by leveraging placeholders and delayed.js.
Sidekick pluginshsteimer
Sidekick pluginusman-khalid
Accessibility Mode
This plugin adds a button in the sidekick to enable "Accessibility Mode" on a given Franklin page, which audits the page from a content perspective and reports on things like missing alt text on images, ease of readability and other accessibility items.
It is also extendable to create custom checks, which can be used to promote correct block usage and adhering to style guidelines, for example. There is an example of this in the repo which checks for too many instances of a block on a page and reports on it.
It can be used by content authors to view the page and address any content or accessibility related issues as a preflight check before publishing.
Easy way to view logs for your AEM Edge Delivery project
AEM Expressions allow users to transform AEM documents into templates by adding simple expressions with parameters. These expressions then become HTML elements that display dynamically fetched content. It is also possible to use expressions as decorators to style and augment content around the insertion point. This turns expressions into reusable fragments that can be placed inside top level AEM blocks.
RSS Feed generator Github Workflow
This Github Workflow updates the RSS feed XML every time a new page is published.
Sidekick pluginherzog31
Block and Section Scheduling
This code lets you schedule blocks or sections. Simply add a date or date range as row to your block or section metadata table and your content will only be displayed after the date or within the range.
This comes with a Sidekick extension, which allows to you preview past or future content.
Blockshsteimer
Blockdave-fink
This is a simple content block to compare two images with a slider to show or hide the left or right image.
Blockniekraaijmakers
Tabs block based on sections that are auto-blocked in scripts.js
Supports "nesting" blocks in the tab block as well as section metadata such as styles.
Tab block logic controlled partially by css
Blockjalagari
Form Block
Form Block with various capabilities
- Google Recaptcha Integration
Load CSS and JS specific to a template, allowing for template specific styling and auto-blocking, without intermingling that code into global scripts/styles.
Note: because the template js is loaded before blocks are loaded, but after sections/blocks are decorated, auto blocking needs to be done with that in mind (that is, build and decorate your blocks, and add them to a section, but do not load them).
ffetch is a small wrapper around the JavaScript fetch function that helps you deal with the AEM Content API when building a composable application. It makes it easy to fetch content from a AEM Index, apply lazy pagination, follow links to pages, and even pull page metadata. With ffetch you get all the ease of creating a headless application without the peformance baggage of headless SDKs and the complexity of headless APIs.
This approach is setting a CSP in a way that is only transported over the wire once and then cached on the client.
Script to add modals to your franklin page. This uses the new(ish) native  element.
**Source:** [https://www.aem.live/developer/block-party/submission](https://www.aem.live/developer/block-party/submission)
AEM Block Party
With Block Party, we would like to give our passionate developer community a place to showcase what they have built on AEM sites. It also allows others to avoid reinventing the wheel and reuse these blocks / code snippets / integrations built by the community and tweak the code as necessary to fit their own projects.
If you are an AEM developer and would like to submit your cool block / code snippet or integration, please enter your submission in the form below:
**Source:** [https://www.aem.live/docs/architecture](https://www.aem.live/docs/architecture)
Edge Delivery Services and document-based authoring are part of the next generation of Adobe Experience Manager’s composable architecture. A key aspect of this architecture is to enable customers to create great experiences using the infrastructure and processes that already enable their success.
At the highest level, Adobe Experience Manager is an on origin service that you plug in to your existing Content Delivery Network (CDN). There are out of the box integrations with Akamai, Cloudflare, Fastly, and Amazon Cloudfront.
The AEM stack itself is engineered for high performance and availability. In order to achieve best possible availability, all delivery services are run in two fully redundant edge providers, have fully redundant storage infrastructure, and are constantly monitored for performance.
Your customer-specific infrastructure like CDNs, DNS, TLS certificates, etc.
Adobe’s edge compute layer
Adobe’s storage layer for edge delivery
In the visitor-facing tier of this architecture, Edge Delivery Services, customers use their existing CDNs, DNS, certificates, etc. which is then delivering the AEM-produced experience to all modern web browsers, native mobile applications, chat bots, or other backend applications.
The central tier consists of the experience composition service, a dual-stack (for maximum availability) architecture that serves content stored in highly optimized formats for experience delivery. The storage layer is made up of Content Bus for structured and unstructured content, Media Bus for assets and media, and Code Bus for the code of the site.
The core publishing process is facilitated by the Admin service for preview and publishing and consists of two key steps, both triggered by authors through the sidekick.
The preview operation in sidekick will pull content from the configured content source such as Sharepoint or Google Drive, or Adobe Experience Manager Sites. This integration is based on the standardized delivery format for structured and unstructured content and can be extended to other third-party content providers. Once the content has been pulled from the originating repository, it will be stored in AEM’s storage layer, separated by structured, unstructured content, assets, and media.
In a second step, authors can publish content. This operation takes the previewed content and makes it available to the delivery tier of our infrastructure. The most important step here is to purge the CDN. AEM will purge every layer of the caching infrastructure, thanks to its deep integration with content delivery networks.
Like content, AEM uses code from your customer-provided repositories. Unlike content, code is taken from GitHub, using the AEM code sync app for GitHub that has been installed during the initial tutorial.
This integration pulls code from all active branches, enabling effective parallel development and scalable testing. When code is merged into the main branch, the CDN will be purged of all affected resources, making deployments fast and easy.
Internally AEM separates different resources needed to assemble and deliver a website based on their corresponding lifecycle and manages them separately.Content (text in documents and spreadsheets, PDFs, SVGs, redirects, etc.) follow lifecycle states of preview and publish have stages of preview and publish. Content is immediately available to all Code branches on the corresponding .aem.page and .aem.live URLs depending on their previewed / published state.
Media (images, and videos uploaded or copy/pasted into a document) is using Content Addressable Storage internally, meaning that every asset is only stored once with a unique hash following the media_ prefix. Media is accessible on all branch URLs across .aem.page and .aem.live as soon as it is added to the system via a preview operation of the asset itself or a document that contains the asset. Since the hash is produced from the binary content of the asset itself, it is immutable and can be cached permanently.
**Source:** [https://www.aem.live/docs/staging](https://www.aem.live/docs/staging)
Many organizations also require in their guidelines the creation of a dedicated staging environment. In this guide we discuss the role of staging environments and best practices for implementing them.
Each repository running on *.aem.live has as many testing environments as there are branches. As long as you enable the GitHub branch protection rules require a pull request before merging, require status checks to pass before merging, and require branches to be up to date before merging, each of your feature branches will be up to date with the main branch before it can be merged and will accurately reflect the nature of your published site.
The practice of setting up a staging environment emerged at a time when computing resources were scarce, and an entire development team had to share a single environment to test their changes. This could lead to adverse effects, for instance a breaking bug in one branch could block all other development from progressing.
With dedicated branches for each feature and fix, and a virtually unlimited number of preview environments for these branches, this is no longer an issue and the workaround of a dedicated staging environment is no longer needed.
In content management, discussions of staging environments are complicated by the fact that authors want to preview their content before being published and developers want to preview their code changes before being merged. With the separation of *.aem.page for content previews and *.aem.live for published content, we provide this ability to authors.
In order to make previewing content as fast as possible, *.aem.page uses different caching rules from *.aem.live, with one being optimized for immediacy, the other for high cacheability.
This means that *.aem.page and *.aem.live behave differently, and consequently *.aem.page should not be used as a staging environment for code. It is a preview environment for content.
You can preview code in all places
As you sometimes need to preview code that refers to content that has not yet been published, the *.aem.page environment supports the same branch-based creation of testing environments.
For the vast majority of customers, rule 1: “you probably don’t need a staging environment” applies. In case you are applying complex configurations, rewrite rules, or even custom edge code in your content delivery network (CDN), it is highly advisable to set up a staging environment for the CDN.
Use your main branch on *.aem.live as the origin – your intent is to test the CDN, not AEM-specific code which has been tested on the *.aem.live testing environment. You want to work with real content and accurate caching rules, so use *.aem.live as the origin
Flush caches deliberately. Through the built-in CDN integration, publishing content to *.aem.live and merging code into the main branch will surgically purge the cache to your production CDN. You should ensure that your staging CDN will be purged when appropriate
Setting up a staging CDN is something that is only advised to a small subset of customers. An even smaller subset will have the need to test the interaction between client-side code and CDN configuration.
Following the guideline that there should be as many staging “environments” as there are active branches, it is recommended to set up a staging CDN that mirrors the *.aem.live URL structure, so that ref.examplestage.com will point to ref–-site--example.aem.live., allowing each developer to access a dedicated testing environment that combines client-side code and CDN-side configuration in one accessible place.
Following the reasoning above, creating a separate staging branch and mapping this to a separate CDN site is not advisable.
**Source:** [https://www.aem.live/docs/security](https://www.aem.live/docs/security)
This security guide covers Edge Delivery Services in Adobe Experience Manager Sites as a Cloud Service, the Admin API for Edge Delivery Services, the Sharepoint integration, and the developer tooling for Edge Delivery Services. There is a separate security guide for the AEM Sidekick. Familiarity with the overall architecture is recommended and assumed for the rest of this guide.
Write operations (preview or publish) require project details (GitHub owner, repository, branch and, if configured, an access token) and content paths be included in requests. This is required to inform the Admin Service which source document to fetch and where to store the processed content in the Content Hub. Similarly, a content request coming from a customer’s CDN must include the project details and path in its URL structure so the delivery service knows which content to deliver.
Adobe uses scaled trunk-based development for continuous deployment of AEM Sites as a Cloud Service. We push incremental changes to aem.live as soon as they pass our rigorous reviews and automated testing.
Preview and Delivery
aem.live applies strict path filtering on the edge for any content it delivers to help reduce potential attack surface. This path filtering is functionally equivalent to a web application firewall (WAF) and prevents thousands of attacks every minute.
The deep integration of the edge layer and the underlying services that make up delivery and preview ensures maximum security and high performance without the overhead of a dedicated web application firewall.
All requests and usage of the preview and publish services are subject to rate and volume limits that are applied on a project-by-project basis and continuously monitored. This prevents denial-of-service attacks (DoS), in the form of distributed denial of service (DDoS) attacks, and self-inflicted Denial of Service attacks through misconfigured monitoring, bots, and crawlers. The vast majority of attacks prevented fall into the latter category..
Edge Delivery services enforces TLS and HTTP Strict Transport Security (HSTS) to help ensure that every request is effectively secured.
Site authentication, once enabled, ensures that only authorized requests can be made to the preview and publish tiers of an AEM site. Requests are required to present one of a list of configured site tokens to be permitted. Users can issue and revoke tokens through the Admin API.
The Content Hub is where all published content, media, and code is stored. For this tier, we rely on active/active replication in a multi-cloud setup. Unlike traditional approaches to disaster recovery where like active/standby or multi-region deployments, an active/active multi-cloud setup ensures that any content, media, or code that gets previewed or published is stored redundantly in at least two different cloud providers with different, but functionally identical software stacks.
The active/active deployment means that during normal operations, the workloads are split roughly equally between our cloud providers and only in an outage of one the remaining providers will pick up the load.
The delivery service itself is also deployed redundantly, so in case of an outage at one cloud provider, Adobe can plan to switch to the other and resume delivery instantaneously, if possible. The intended recovery time objective (RTO) for this service is 15 minutes.
The Admin API strictly requires authentication for all administrative operations and can be set up to require authentication for content operations like previewing or publishing through the sidekick. This requirement extends to the use of the AEM Sidekick.
admin.role.author: This role allows a user to update content in the Preview environment
admin.role.publish: This role allows a user to update content in the Preview and Live environments
The Admin API is currently a single-cloud deployment. In case of an outage in this service, the intended RTO is 12 hours. Adobe regularly conducts disaster recovery tests to validate that both delivery and API services can be restored well within their respective intended RTOs.
All requests and usage of the Admin API are subject to rate and volume limits that ensure smooth operation of the service. In addition to the published limits, Adobe can apply secondary limits on a case-by-case basis.
Backend Integrations
Please see Sharepoint integration (application) or Sharepoint integration (delegated), depending on your setup.
The AEM Code Sync GitHub application uses GitHub permissions to provide access to your GitHub repository, so that code can be made available for serving in the code bus. Following permissions are requested:
read access to metadata – so that code gets assigned to the correct Code Bus space for your repository
read/write access to checks – so that the pull request status can be set when the Pagespeed Insights performance test passes
read/write access to content – so that content can be replicated to the Code Bus. Write access is required to send repositotry_dispatch events and trigger GitHub actions
read/write access to deployments – so that each branch in your GitHub repository can correspond to a deployment on aum.live
read/write access to pull requests – so that Adobe can suggest code updates, if required
The Code Sync GitHub app will not perform writes to your repository, but raise PRs, so that your approval will be given for each code change.
AEM Sidekick
The AEM Sidekick is a browser extension installed via Chrome Web Store or Apple App Store and helps authors preview and publish their content. See Sidekick Security for more detailed information.
The AEM Command Line Application is installed via npm and requires access to the developer's file system, so that the site under development can be previewed using code from the developer's working copy.
It also requires network access to *.aem.live and *.aem.page, and validates all requests using Transport Layer Security (TLS) against the node.js certificate store. When man-in-the-middle attacks or tampering with request routing are detected, the command line application refuses to serve a preview site.
Perform load tests incl. simulated (D)DoS attacks only against production infrastructure, which includes your CDN
**Source:** [https://www.aem.live/docs/limits](https://www.aem.live/docs/limits)
**Source:** [https://www.aem.live/docs/global](https://www.aem.live/docs/global)
The Edge Delivery Services architecture for Adobe Experience Manager makes use of redundant content delivery networks (CDNs) to ensure high availability with low latency. The cacheable components of your sites are delivered directly from globally-distributed points of presence (POPs).
The two highest priorities in delivering web experiences are availability and performance. For this reason, we use multiple content delivery networks to provide the Adobe Experience Manager service. Multiple CDNs so that, in the rare case of a CDN outage, we can switch the full delivery stack to a separate CDN to provide continued high availability.
Each CDN uses dozens to thousands of different points of presence (POPs): high-performance caching servers located at critical internet junctures in global locations, close to population centers. These POPs cache the content served for your websites and make it available to “nearby” visitors, minimizing the inherent network latency of interactions.
In order to ensure this global availability, your cacheable content has to be globally distributed to the same extent that it is published to global visitors. Each of the core storage areas of the AEM content hub (media, content, code) is therefore equally globally-distributed to be within reach of those global visitors.
The Edge Delivery Services architecture is designed for global publication of information that would normally appear on public sites. Site owners are responsible for ensuring that the information they choose to publish is in compliance with applicable laws or regulations. Likewise, the data we collect for Operational Telemetry is deliberately limited for the sake of privacy and compliance.
**Source:** [https://www.aem.live/docs/china](https://www.aem.live/docs/china)
Can I serve visitors in China with Edge Delivery Services?
Edge Delivery Services in Adobe Experience Manager requires a customer-managed Content Delivery Network (BYOCDN) to serve content to visitors in China
Adobe Experience Manager Edge Delivery Services is using two redundant global content delivery networks (CDNs) to deliver experiences across the world. However, certain regions require using a local CDN to serve the content within that region.
To account for this, customers should use customer-managed CDN (BYOCDN) in China to serve visitors from China. CDN operators in China require customers to provide an Internet Content Provider (ICP) license or ICP recordal.
The API for previewing and publishing content on admin.hlx.page – this API is typically available from within China, but often has increased latency
The preview URLs on aem.page – this host is available most of the time, but disruptions have been observed
Edge Delivery Services consume source code from GitHub. Developers collaborating through GitHub from China may experience network latency which is out of Adobe’s control.
Edge Delivery Services in Adobe Experience Manager are currently operated outside of China. For customers that require all AEM servers to be hosted in China due to various reasons including, but not limited to, compliance such as Multi-Level Protection Scheme (MLPS), data residency, Baidu SEO, etc. Adobe Managed Services for Adobe Experience Manager are available in China.
**Source:** [https://www.aem.live/docs/translation-and-localization](https://www.aem.live/docs/translation-and-localization)
This results in an information architecture that looks something like this…
From the outside: SEO impact and visitor impact
The duplication of content from a public web and SEO perspective is very undesirable as it pollutes public search indexes with redundant information and makes a company lose control of where their audience is sent from the SERP, as search engines will use multiple signals to identify the canonical URLs of a piece of content.
In the past a lot of systems have optimized that ability to create and manage a lot of duplicate content. Given the above statement on the problem of duplicate content this clearly seems like the wrong approach. Beyond creating a subpar SEO and site visitor experience this also contributes to an amplified management problem as content is copied around many times, and no matter how good the tools are this leads to potential conflicts and issues that could have been avoided.
Best Practices around Translation and Localization
Automatically detecting the language and the market is only a relatively small portion of any multi language and multi market architecture. It cannot be done perfectly and therefore the user should always have the opportunity to self select themselves into a particular market (and language) and keep that decision persisted on their device. There is also legislation that forbids geofencing, which further deemphasizes the importance of automatically trying to detect markets.
Detecting a user's market / region is often needed to make sure that the content is localized, but also making sure that commercial offers, currency, legal context with respect to privacy etc. are set up the right way and the website responds correctly. Once the market is detected or selected that’s what will be used for all external services that are market specific as well, for example E-Commerce systems.Usually a good indication is some form of geo IP or the browser Geo Location API. This should be done completely separately from the language of the content that the consumer is interacting with. It is good practice to allow a user to self select themselves with a region switcher into a different market/region and persist that information on the visitors device.
Since a lot of the content in AEM is based on content that is created in word, google docs and spreadsheets there is a broad range of translation support available. There is built-in support for machine translation in both Microsoft Office and Google Workspace applications but since Office formats are extremely common for all translation services and providers there are existing integrations for bulk translation and translation memories that are readily available.
At scale, in situations where translation processes are standardized with internal, bespoke tooling or APIs for very large organizations with a continuous flow of translation needs, we recommend using Microsoft Office or Google Workspace Automation and APIs to connect those.
Market specific content should be hosted in the corresponding folder identifying the market, country or region. This is particularly valuable if only a small fraction of the content is localized.
The goal of this setup is that only content that is actually localized exists for any given market.
Depending on SEO and other needs it may be more advisable to expose the external URLs per locale or decorate the market/region specific content on the same URL, but in many cases it may make sense to expose the market in externally visible URL, something like /en/ca/ for the Canadian homepage.
The technical implementation of that is usually quite straight forward and relies on a AEM index of all the content that has been localized and made available for a particular market and either an eventhandler for click events and/or rewriting of href attributes, as well as some observation for a given market in content fragment or similar fetch requests.
In an example where a website uses english content written the US market as the default and has some minimal content eg. the homepage (index), localized nav and footer that is localized for the UK market the content structure would something like this (in sharepoint):
This translates to a corresponding URL space of www.mycompany.com/en/ for the US homepage and www.mycompany.com/en/uk/ for the UK homepage. For a visitor from the UK market (detected or self-selected as mentioned above) the localized nav and footer are loaded independently of where they navigate on the site.A UK visitor to www.mycompany.com/en/brands would see the localized navigation and footer with the corresponding links to additional UK content where needed. Beyond that all the inline links in the /en/ content, that point to content that is also available in the /en/uk/ tree (eg. the homepage in this case) would be dynamically rewritten to point to the corresponding localized version.The sitemap with HREFLang support would look something like this:
**Source:** [http://www.aem.live/docs/%20https://www.aem.live/docs/byo-cdn-setup](http://www.aem.live/docs/%20https://www.aem.live/docs/byo-cdn-setup)
**Source:** [http://www.aem.live/docs/dev-collab-and-good-practices](http://www.aem.live/docs/dev-collab-and-good-practices)
**Source:** [https://www.aem.live/developer/placeholders](https://www.aem.live/developer/placeholders)
Note: the placeholders feature has been moved to the block-collection repository and is not part of the boilerplate.
You can import fetchPlaceholders in your block’s JS or scripts.js and use it as follows to retrieve placeholder strings. You probably have some function or logic in your project to determine the language of the current page based on its path or metadata. In this example, we’ll simply hardcode it to en. This means it will fetch a placeholders sheet in the en folder. Omitting the argument will assume there’s a placeholders sheet in the root folder.
**Source:** [http://www.aem.live/docs/operational-telemetry](http://www.aem.live/docs/operational-telemetry)
**Source:** [http://www.aem.live/developer/rum](http://www.aem.live/developer/rum)
**Source:** [http://www.aem.live/docs/rum-explorer](http://www.aem.live/docs/rum-explorer)
**Source:** [https://www.aem.live/developer/block-collection/text](https://www.aem.live/developer/block-collection/text)
**Source:** [https://www.aem.live/developer/block-collection/headings](https://www.aem.live/developer/block-collection/headings)
**Source:** [https://www.aem.live/developer/block-collection/images](https://www.aem.live/developer/block-collection/images)
**Source:** [https://www.aem.live/developer/block-collection/lists](https://www.aem.live/developer/block-collection/lists)
**Source:** [https://www.aem.live/developer/block-collection/links](https://www.aem.live/developer/block-collection/links)
**Source:** [https://www.aem.live/developer/block-collection/buttons](https://www.aem.live/developer/block-collection/buttons)
**Source:** [https://www.aem.live/developer/block-collection/code](https://www.aem.live/developer/block-collection/code)
**Source:** [https://www.aem.live/developer/block-collection/sections](https://www.aem.live/developer/block-collection/sections)
**Source:** [https://www.aem.live/developer/block-collection/icons](https://www.aem.live/developer/block-collection/icons)
**Source:** [https://www.aem.live/developer/block-collection/hero](https://www.aem.live/developer/block-collection/hero)
**Source:** [https://www.aem.live/developer/importer](https://www.aem.live/developer/importer)
It is good practice to make example imports of each page type you wish to import. You can thereby confirm that the authors find the resulting structures intuitive. This also allows parallelization of the content import with the development work for blocks and styling. If you are using document-based authoring, you can do this by creating manual imports using copy/paste from the source website into a Word or Google Docs document.
Structuring your content in an intuitive manner is an important step in an AEM project. See the documents Markup, Sections, Blocks and Auto Blocking and David’s Model, Second take for more information.
The bottom-left of the importer window displays your current version of the importer UI as well as the AEM CLI tool.
Content Import Path defines where in your destination repository the content will be stored. This must be under /content.
Asset Import Path defines wherein your destination repository assets will be stored. This must be under /content/dam.
The Page preview frame at the bottom of the middle panel shows you the page you are importing. The page is loaded in an iframe and served via the local proxy server. While AEM tries to remove all security settings, it is possible that the page does not fully render like the original due to CORS issues. This is usually fine in 90% of the cases. In the remaining cases, there are different solutions that can be attempted such as starting your browser with disabled security settings. Please contact the AEM team for assistance in such cases.
The Preview tab in the right panel shows you an approximation of how the import will appear.
The AEM Importer transforms the HTML into markdown as a first step and then the markdown into a docx file, HTML, or JCR repository depending on your selected authoring method. The Markdown tab shows you the markdown from that intermediate step.
To further customize the import process, you can create a tools/importer/import.js file. This file defines all of your own rules to convert your content. If you change and save the import.js file, the import is automatically re-executed. In this way, you can preview your changes while you are developing the transformation rules.
It is highly recommended that you read the GitHub documentation for the importer to learn more and review code snippets to create your own import.js. Note that any rules you add to your own import.js file are in addition to the default behavior of the importer. Additional options for the import are also documented in detail there.
With a set of rules (such as to remove header and footer, reorganize the hero section, create blocks, insert metadata, etc.), you can create an import that contains the essential content of the page and that fits perfectly in a Word document, content package, or HTML depending on your authoring method. You can use this content as the base of your new site by:
During the process, you can download an Excel report with the list of pages imported and some process information (import success, 404, 301, etc.). At the end of the process, this report file contains everything the importer has done and can be used for further analysis such as to find pages with errors. Or it can be used for page processing such as previewing and publishing.
After providing a URL and clicking Crawl, the tool will open the provided URL, try to identify the links on the page, and recursively visit all those links that are on the same host. It is basically navigating the site and collecting all the URLs it finds. For a large website, it can take a lot of time. If the website consumes a lot of resources / memory, it may even crash the browser. In such cases, hiding the preview and/or disabling the Javascript in the options can help.
**Source:** [https://www.aem.live/developer/da-tutorial](https://www.aem.live/developer/da-tutorial)
**Source:** [https://www.aem.live/tools/sidekick/](https://www.aem.live/tools/sidekick/)
Sidekick Configurator
Install the Sidekick and add this project
Clicking the button below will open a separate window with instructions on how to install the Sidekick Extension.
Install Sidekick for Chrome
If you experience any trouble installing the Sidekick Extension, please let us know in the AEM Community on Discord or your dedicated Slack channel with Adobe.
Your Sidekick is not configured for this project yet
Once added, you will be able to use the Sidekick with any web page or source document associated with this project.
Your Sidekick is configured for this project
Click the logo in your toolbar to show or hide it while browsing your project. If you don’t see it, click the puzzle piece to reveal all installed extensions and pin AEM Sidekick to your toolbar.
If you want to remove this project from your Sidekick again, click the button below:
Do you need help using the Sidekick?
**Source:** [https://www.aem.live/docs/aem-assets-sidekick-plugin](https://www.aem.live/docs/aem-assets-sidekick-plugin)
Adobe Experience Manager Assets Sidekick Plugin
With the Experience Manager Assets Sidekick plugin, you can use assets from your Experience Manager Assets repository while authoring documents in Microsoft Word or Google Docs.
The Sidekick plugin for Assets supports access to:
Assets Sidekick Plugin for Content Authors
Open up the Sidekick browser extension and find the “My Assets” button.
Please see the document Configuring AEM Assets Sidekick Plugin to configure this plugin.
When hovering over assets, you will see the info icon, which shows additional asset metadata.
After using the Sidekick to preview and publish the document, the new asset is displayed as part of your web page
Delivering Assets via Dynamic Media with OpenAPI
Using the Assets Sidekick plugin, you can also include Dynamic Media delivery with OpenAPI. This offers a number of benefits.
For more information on capabilities offered by Dynamic Media with OpenAPI, please see the Dynamic Media with OpenAPI capabilities documentation.
An Assets Cloud Service environment where Dynamic Media with Open API is enabled.
The AEM Assets sidekick plugin enabled with copy reference for image assets enabled as documented here.
Dynamic Media with OpenAPI is now in an Early Adopter program. Please reach out to your account team or Adobe support Slack channel for more information.
Open the Sidekick and the Assets Selector and choose a repository with the prefix “Delivery-” in the repository switcher and filter for image assets.
Preview the site and the link is rendered as an image.
Additional image transformations like, crop, rotate, flip, etc. are available using Dynamic Media with OpenAPI by appending query parameters at the end of the URL copied from the AEM Asset Selector. Available query parameters are detailed in the Assets Delivery API documentation.
Open the Sidekick and the Assets Selector and choose a repository with the prefix “Delivery-” in the repository switcher and filter for video assets.
The link is pasted as an embed block, which includes a hyperlink.
Preview the site and the video block and link are rendered as a video.
Open the Sidekick and the Assets Selector and choose a repository with the prefix “Delivery-” in the repository switcher and filter for the asset you want to select.
Preview the site and verify that the PDF link is rendered.
If all looks good, publish the document. Clicking on the PDF link in the published page should open up the PDF delivered from AEM Asset Dynamic Media Open API delivery in a new tab.
Customizing the AEM Assets Sidekick Plugin
The AEM Assets Sidekick Plugin can be customized to better fit your project’s specific needs. Available customization options include:
Customizing block structure including block title, number of rows, columns etc. that gets copied over to the document when copying an asset from the assets addon to it.
Please see the document Configuring Adobe Experience Manager Assets Sidekick Plugin for details on customization and extension options available.
**Source:** [https://www.aem.live/developer/configuring-aem-assets-sidekick-plugin](https://www.aem.live/developer/configuring-aem-assets-sidekick-plugin)
Configuring Adobe Experience Manager Assets Sidekick Plugin
Learn how to configure the Adobe Experience Manager Assets Sidekick plugin, so you can use assets from your Experience Manager Assets repository while authoring documents in Microsoft Word or Google Docs.
For information on the authoring experience while using the Sidekick plugin, please see Adobe Experience Manager Assets Sidekick Plugin.
Configure Your Sidekick
To enable the Assets plugin in your Sidekick, you must create a configuration in your project’s GitHub.
Open your project in GitHub and locate the Sidekick configuration file at tools/sidekick/config.json.
For more details, please refer to this document on extending AEM Sidekick.
Commit the configuration to your project's Github repo.
Open up the AEM sidekick in a Microsoft Word or Google Doc project document. You should see the My Assets button. The label of the button will depend on your configuration.
You can optionally customize the Assets Sidekick plugin by specifying query parameters in the asset selector URL in the Sidekick config.json file. The following parameters are supported:
Use this parameter to toggle the rail view of the asset selector. By default, the rail view is used, which is more compact and offers search-only experience. If you set the parameter to ?rail=false, a tree view left panel is shown with the repository folder hierarchy allowing users to browse for assets in addition to searching.
The Asset Selector component leverages micro-frontend Asset Selector that is instrumented to integrate with Sidekick. To learn more, please see the Micro-Frontend Asset Selector documentation.
Use this parameter to extend the Assets Sidekick by specifying the complete URL where the configuration is hosted. This is useful for scenarios where the configuration resides at a different location than the project's domain. To configure extConfigUrl, include it in the sidekick JSON configuration of the extension.
If the configuration is hosted on an Edge Delivery Services project, refer to the documentation for detailed instructions on configuring CORS for hosted configurations.
You can customize the AEM Assets Sidekick plugin using extension points to meet your custom requirements. These extension points enhance the plugin's functionality and adapt it to your organization's unique demands.
blockName
This extension point defines the block name for different MIME types.
This configuration allows users to change the Block Name for Video type assets from default “Embed” to “Core Embed”.
blockTemplate
This extension point defines the template structure used for displaying video blocks, allowing flexibility in the structure of the block that gets copied to the Word document to align it with the block structures used in your site authoring.
The following example demonstrates how to configure the blockTemplate for video assets:
This configuration would result in a block like the following example copied to the Word document when the asset is pasted. It has the poster image and the video URL and the block’s header row has been styled.
blockName: Represents the name of the video block
This extension point allows you to set up custom search filters to make it easier to find and narrow down assets based on its metadata, such as tags, status, type etc.
The name attribute should be changed depending on the repository.
For the delivery repository: property=metadata.application.xcm:keywords.id
This configuration replaces any delivery domain with its corresponding CDN-mapped or custom domain.
Customization of the Assets Sidekick plugin including its extension points is done by the sidekick’s project configuration file. There are two options for defining this configuration file:
In this option, the configuration file should be defined at the following path within your Edge Delivery Services project:
Additionally, ensure that the Assets Sidekick Plugin configuration includes the following parameter set to true:
This configuration is the same as described in the section Configure Your Sidekick.
Option 2: Host Configuration Externally and Pass It to the Assets Sidekick Plugin
You can host the configuration file at any accessible URL and pass it to the Assets Sidekick plugin. You do this by utilizing the extConfigUrl parameter to specify the URL from which the configuration will be fetched. This configuration is the same as described in the section Advanced Configuration.
This is particularly useful for scenarios where you want page authors to be shown only a subset of assets from your assets repository based on the context of the web page they are authoring such as showing locale or region-specific assets based on the locale of the page authored.
Ensure the Sidekick configuration has both passReferrer and passConfig flags set to true.
For more detail and reference configurations, please see the readme of the Assets Selector to help you adapt and deploy these configurations in your project based on your use cases and extension requirements.
**Source:** [https://www.aem.live/developer/byo-git](https://www.aem.live/developer/byo-git)
Edge Delivery Services recommends using GitHub or GitHub Enterprise Cloud to host and deploy project code for frictionless adoption and seamless integration. If you are already an AEM customer and your organization is unable to use GitHub for the source code, you can now use Cloud Manager as an intermediary and configure your own git based repository service there.
The following git based repository vendors are currently supported via Cloud Manager:
GitHub Enterprise (self-hosted version only)
Adobe Hosted Repository (via Cloud Manager)
Note: Edge Delivery Services expects a main branch to be present in your repository for production code.
Before you can configure your external repository, you need to have an aem.live org registered in the configuration service and have an admin user who can perform updates to the site configuration. An easy way to get started is to follow the developer tutorial. Once your site is up and running, contact an Adobe representative to create the aem.live org for you and add the administrative user(s).
Please note: even if you don’t use github.com as the source repository, the name of the aem.live org still needs to exist as a github.com org controlled by you. This ensures that nobody can (ab)use the same organization name.
As a first step, configure your external repository in Cloud Manager. If you are new to AEM, see here for an introduction and to find out how to access Cloud Manager.
Once the repository ownership is confirmed and the status is set to ready, you will need to set up a webhook for your git repository. This will allow Cloud Manager to receive push event notifications whenever changes are made to your repository. You can find the webhook details in Cloud Manager, and they are unique for each repository.
The webhook requires an API key, which is the same key used for interacting with any Cloud Manager API. For more details on generating the Cloud Manager public API key, refer to the public documentation. Additionally, a webhook secret must be configured in your git vendor solution when creating the webhook. This secret will be used to sign each event sent to Cloud Manager.
If your git repository is not publicly accessible, you can request a list of IPs used by Cloud Manager. To do this, send an email to cloudmanager_byog@adobe.com from the email address associated with your Adobe ID. Be sure to specify which Git platform you want to use and whether you are using a private, public, or enterprise repository structure.
Once you select the "Bring your own Git" option, a pop-up window will appear prompting you to choose the repository you wish to use as the source code for the site.
Once the repository is selected, Cloud Manager will provide a secret that must be added in your site configuration. Be sure to copy the secret and store it securely, as it won't be visible again in Cloud Manager. If you reconfigure the site, Cloud Manager will generate a new secret.
Next, you need to add the code repository to your site configuration. If you are new to Edge Delivery Services, it is recommended that you familiarize yourself with the Admin API.
You will need to replace <org> and <site> with your actual values from the configuration service, and <program-id> and <repository-id> with the actual values from Cloud Manager. The latter details can be easily found in the “Configure Webhook” section of the repository.
You also need to create a secret named "cm-byog" using the Admin API. The value of this secret should be the one provided by Cloud Manager in the previous step.
This action will update your Edge Delivery Site with the code from your private git repository and the selected branch. For more details about the sync jobs, you can use the following Admin API.
Browse your site at https://main–{site}--{org}.aem.pageto ensure the initial synchronization from your external repository has worked as expected.
To test continuous code synchronization, make a change to one of your code files (ideally something easy to spot in the browser) and push it to the main branch of your external repository and ensure the change is reflected on your AEM Site.
Note: Code synchronization happens asynchronously and your changes may not be reflected immediately. Disable your browser cache or use an incognito window for testing to circumvent your browser’s cache and force it to fetch all resources from the server.
**Source:** [https://www.aem.live/docs/exploring-blocks](https://www.aem.live/docs/exploring-blocks)
Exploring blocks
Blocks are a foundational concept behind adding form and function to sections of a page. If you followed along with the tutorial, you will know that you can create simple content structures with just text and images. When you want to group pieces of content, add a bit more structure, or add more complex functionality, blocks can help you achieve these goals.
Example blocks ideas
A block can really be anything you choose, but here are a few possible use cases:
Blocks are built using tables in Google Docs or Microsoft Word. These tables are converted to Markdown and rendered as simple divs when requesting HTML.
To create a block, you only need a table with at least one row & one column:
In order to give some context to our block, we will add a name to the first row + column:
We now have a CSS class that we can use to either style our block or attach functionality with Javascript. Of course, an empty div with a class is not tremendously useful.
Decorating blocks
The concept of decorating blocks is to perform several optional tasks:
Add any aria or accessibility attributes you need.
For our use case, we’ll decorate the block to add a few classes to help with styling and add an event handler for interactivity:(Copy the following code to blocks/accordion/accordion.js)
Let’s also add some CSS:(Copy the following code to blocks/accordion/accordion.css)
**Source:** [https://www.aem.live/developer/web-components](https://www.aem.live/developer/web-components)
Web Components
Web Components are a collection of web standards that allow the creation and use of reusable, modular functionality in web sites and web apps. They can be used in Adobe Experience Manager projects.
There are three distinct web standards that make up Web Components. In order of relevance for AEM projects, these are:
Depending on how Web Components are written, their code and styles can be largely isolated from the rest of the page, which allows custom elements written by different teams to coexist on the same page, as well as sharing components between independent projects or teams.
How to use Web Components in AEM projects?
To activate a Web Component, you need to load the JavaScript code that defines it and have your AEM blocks code generate the corresponding custom HTML elements.
The code loading is similar to adding any existing JavaScript/CSS code to your project, but please read the “performance concerns” section below to avoid surprises.
The following paragraph uses a publication-time AEM block that leverages GitHub’s relative-time Web Component to display the page publication time in a friendly format:
Reusing existing code makes total sense to compute friendly relative time strings like “two days ago”, “five hours ago”, so a Web Component is helpful, as our publication-time AEM block only needs to output something like:
To let the relative-time Web Component do all the (somewhat) hard work.
From a coding standpoint, we only need to make the relative-time component code available and write the pretty simple glue code in the AEM publication-time block.
Performance concerns, loading and lifecycle
To keep your Web Performance at the required level, your pages need to be frugal about how much JavaScript and CSS code they load, and if needed control when that loading occurs.
If your Web Components are written with performance in mind, there’s no reason for them to be less performant than AEM blocks, which are also backed by client-side JavaScript. Unfortunately, this cannot be taken for granted and you should test the performance of any Web Component before using it.
The AEM blocks code needs to translate the AEM semantic HTML to generate the custom HTML elements, but that’s no different from generating other HTML elements, so shouldn’t significantly affect performance.
If you want to use components from an existing library, you should make sure to load only JavaScript and CSS code that the current page actually requires, to avoid any extra baggage. Some libraries do that naturally, and others will require jumping through hoops to repackage their components in an optimized way. Your mileage may vary, and as always you’ll need to measure results to verify that the components code does not hamper performance.
You also need to be aware of the AEM Three-Phase-Loading principle, and if needed explicitly define when your Web Components code and styles are loaded.
One nice feature of Web Components that helps with lazy loading is that they take care of the asynchronicity and lifecycle concerns. Provided your components use the lifecycle callbacks in the correct way, it does not matter whether their code becomes active before or after the corresponding elements are added to the DOM, the browser does the right thing.
**Source:** [https://www.aem.live/developer/target-integration](https://www.aem.live/developer/target-integration)
Configuring Adobe Target Integration
This article will walk you through the steps of setting up an integration with Adobe Target so you can personalize your pages via the Adobe Target Visual Experience Composer (VEC). Before you go further, please also check our native Experimentation capabilities.
We support 2 different ways of integrating with Adobe Target. The recommended future-proof approach is via the Adobe Experience Platform WebSDK, but we also support the legacy Adobe Target at.js approach.
Adobe Target lets you modify the content of an existing page based on the personalization parameters you define in Adobe Target Visual Experience Composer (VEC) or equivalent. The rules will be dynamically evaluated server-side and Adobe Target will deliver a list of page modifications that will be applied to the rendered page after the blocks have been decorated.
Page modifications are done on the final page markup after the blocks have been decorated. So if you want to change block behaviors based on modifications that Adobe Target will be doing (like setting a CSS class or attribute), you’ll have to leverage the MutationObserver API
Adobe Target will be modifying blocks after they have been decorated and shown on the page. In most cases, this is not an issue as applying the modifications takes only a few milliseconds, but if you run complex code snippets this will likely trigger some page flickering and impact the user experience
The roundtrip to the Adobe Target backend services to obtain the list of page modifications that need to be applied is done during the eager phase and will impact the overall LCP. The first call to the endpoint is also typically slower, while subsequent calls will be on a warmed-up service with cached responses
Since the instrumentation has an overhead, we recommend only enabling it on selected pages that are meant to be experimented on or personalized. The easiest is to add a page metadata, like Target: on that will act as a feature flag.
In our tests, you can expect a baseline performance impact as below. To this you’d also need to add the overhead of more complex page modifications, especially when using custom JavaScript snippets.
Adobe Experience Platform WebSDK
To enable Adobe Target integration in your website using the Adobe Experience Platform WebSDK (aka alloy), please follow these steps in your project:
Start by following the steps to Use Adobe Target and Web SDK for personalization, and skip all steps related to actual instrumentation at the code level
Make sure to note down the Adobe IMS Organization Identifier (orgId) as well as the Adobe Experience Platform Datastream Id (datastreamId, formally edgeConfigId) you want to use. You can get those following the WebSDK configuration documentation (orgId, edgeConfigId).
In your GitHub repository for the website, add the alloy.js file.
Adjust the path to the library and set the correct values for your datastreamId, formally edgeConfigId, and orgId as per step 2.
Setup up an experiment in Adobe Target and preview the page
Add the Target metadata property to your page to trigger the instrumentation, or adjust the getMetadata condition in the code above to your needs. You can typically import getMetadata from aem.js or equivalent in your project if it isn’t yet available in your scripts.js
If the instrumentation is properly done, you should see a call to https://edge.adobedc.net/ee/v1/interact in your browser’s Network tab when you load the page. Whether the page is actually modified or not will depend on the configuration you set in Adobe Target
To enable Adobe Target integration in your website using the legacy at.js approach, please follow these steps in your project:
In your GitHub repository for the website, add the at.js file. We have an optimized version for AEM Edge Delivery Service that you can fetch at https://atjs--wknd--hlxsites.hlx.live/scripts/at.fix.min.js until it is made publicly available
**Source:** [https://www.aem.live/docs/experimentation](https://www.aem.live/docs/experimentation)
Experiment variants are the easiest way to get started with experimentation. This approach uses the page you already have as the control, you then create a challenger page that will replace the control for some of your visitors. In your challenger page, you can test different variants of your hero blocks, different page layout or call-to-action (CTA) placements and verbiage.
As long as you stay within the established design language of your website and use existing block functionality you should be able to set up an experiment variant and send it to production in a matter of a few minutes using your established authoring tools.
Preview and publish the challenger page using the sidekick and when you are done authoring the challenger page, the URL of the published challenger will be used in the next section - setting up the experiment.
As soon as you have your challengers ready to go, all you need to do is to go back to the control page and add some metadata indicating that this page is now part of a test.
There are two metadata rows that need to be added for an experiment variant.
You can override the traffic split via metadata. For more information, see https://github.com/adobe/aem-experience-decisioning/wiki/Experiments#authoring
Preview and Stage your Experiment Variants
As soon as you are ready to preview and stage your experiment you can preview the control page with the additional metadata. Whenever you are previewing a page that has a running experiment, you will see the experimentation overlay in your .hlx.page preview environment that lets you switch between the variants and gives you confidence that your test is setup correctly and ready to be launched.
The data collection to measure the effectiveness of each variant is based on Real User Monitoring.
To send your experiment to production and collect data about the performance of each variant, the only step left is to publish the control page as well as each of the challenger pages.
Some experiments include changes across multiple pages. If you would like to run experiments across multiple pages, all you need to make sure is to use the same experiment ID in metadata across multiple pages and in case you have multiple challengers, make sure that your challenger URLs in the Experiment Variants metadata field are sequenced corresponding to their challengers across pages.
When running experiments, it is usually best practice to exclude the variants from the sitemap and ensure they are not indexed by search engines, as the page could be seen as duplicate content and negatively impact SEO.
If you centralize all experiments in a dedicated folder, like /experiments: make sure your bulk metadata.xlsx sheet contains a row with /experiments/** as path, and a robots column with the value noindex,nofollow.
If you keep the experiment control and variants with the regular content: add a robots entry in the page metadata for each variant, with the value noindex,nofollow.
**Source:** [http://www.aem.live/blog/testing-in-aem](http://www.aem.live/blog/testing-in-aem)
Components are rendered dynamically based on authored content, which can vary wildly. Different authors structure pages differently, introducing inconsistencies that automated tests struggle with. What works locally might fail in CI/CD due to rendering differences or timing issues. And DOM structures change often due to styling or layout updates, breaking tests even when functionality is intact.
Focus your efforts on areas that carry real weight: backend logic, reusable libraries, critical user journeys like login or checkout, and integrations that tie systems together. These are the pillars of your application’s reliability.
On the other hand, let go of the urge to validate every pixel. Visual tweaks on content-heavy pages, components that shift frequently, or purely aesthetic elements rarely justify the overhead. They tend to break often, demand constant updates, and offer little in return.
**Source:** [http://www.aem.live/blog/byom-content-overlays](http://www.aem.live/blog/byom-content-overlays)
Between them, Eric Van Geem and Lars Auffarth published 13,000 pages dynamically. No manual authoring. No static builds. Just pure, automated content delivery at scale through Edge Delivery's new BYOM and content overlay capabilities.
The cabinet hums with electricity. Neon pixels spell out "CHOOSE YOUR FIGHTER" as two champions materialize on screen. This isn't Street Fighter or Mortal Kombat. It's the Edge Delivery Services arena, where developers battle the final boss: dynamic publishing at massive scale.
[PLAYER 2] THE APP BUILDER MAGEName: Lars AuffarthClass: Serverless SorcererPower Level: 3,000 product pagesAffiliation: Adobe AllianceUltimate Attack: Edge Worker Price Strike
Eric opens with a devastating infrastructure combo. His Azure Cosmos DB stores 10,000 fighter profiles, each one waiting to enter the arena. The combo sequence: Cosmos DB Change Feed → Azure Function Trigger → Service Bus Queue → Timer Function → Helix Admin API → Vercel Overlay Server. When a profile updates in the database, his automated pipeline springs to life, throttling requests to respect API limits while maintaining relentless pressure on the content delivery boss.
His secret weapon? A Node.js Express server deployed on Vercel that acts as the overlay endpoint. When Edge Delivery requests /people/marty-mcfly, Eric's server fetches the data, merges it with a template, and returns pixel-perfect HTML. No manual intervention. No content duplication. Just pure, automated publishing fury.
Lars counters with native Adobe magic. His App Builder actions orchestrate a symphony of serverless functions. The spell components: Commerce API Webhook → App Builder Orchestrator → BYOM Renderer → Edge Worker Price Injection. Three thousand product pages dance to his command, each one updating automatically when backend data shifts.
His finishing move deploys edge workers that inject live pricing after page load—a technique so advanced it bends the rules of static delivery. While Eric's approach handles everything at publish time, Lars splits the attack: static content from BYOM, dynamic pricing from the edge. The boss never sees it coming.
Here's where the game gets interesting. Despite choosing different characters and tech stacks, both players discovered the same hidden mechanics. They mastered the template pattern, using HTML templates with placeholder replacement to transform data into pages. They both configured content overlays in Edge Delivery's config, unlocking the secret passage to dynamic publishing. They learned the 404 wisdom—returning proper 404s for missing content instead of taking soft 404 boss damage. They respected the semantic block architecture, generating Edge Delivery-compatible markup that flows through the same rendering pipeline. And perhaps most importantly, they achieved total automation, eliminating manual publishing entirely.
But every fighter has unique abilities. Eric's Azure style gives him a self-hosted overlay server for maximum control. He can show visual proof of his victories with live sitemap.xml and query-index.json files. His architecture stays simpler for non-Adobe environments, with direct database integration patterns that any cloud warrior can understand.
Here's the secret: don't just memorize their button combos. Study how Eric leveraged his Azure expertise. Notice how Lars maximized Adobe's native capabilities. The best architects don't carbon copy moves—they understand the underlying mechanics and craft their own fighting style. Maybe you're a Google Cloud Platform warrior with Cloud Functions and Firestore ready to strike. Perhaps you're a Cloudflare champion with edge compute mastery. Your unique strengths are your special moves.
These championship rounds wouldn't be possible without last week's game update by Farhan. When folder mapping got deprecated, it opened the door for Content Overlays and BYOM to become the new meta. These tools delivered what folder mapping promised but couldn't achieve: true dynamic publishing with proper SEO, hard 404s, and unlimited scale.
Ready to study their techniques? Eric's full walkthrough includes Azure setup, Vercel deployment, and live examples. Lars's strategy guide covers App Builder patterns, edge worker integration, and enterprise scaling.
**Source:** [http://www.aem.live/blog/folder-mapping-deprecated](http://www.aem.live/blog/folder-mapping-deprecated)
I fell in love with folder mapping when it solved an impossible problem: serving 5,000+ dynamic stock pages with one elegant template. No more managing thousands of individual pages. No more content duplication nightmares. Just pure operational efficiency—deploy changes instantly across your entire collection by modifying one file.
But folder mapping betrayed me. Google Search Console started reporting hundreds of phantom pages as valid content when they were actually errors. Search results displayed generic template titles instead of real content. Crawl budgets disappeared into soft 404 black holes. The solution I'd loved was systematically sabotaging the SEO performance it was meant to support.
Then I discovered something better. Content overlay with the API for Edge Delivery Services delivers folder mapping's promises without its compromises—pre-published dynamic pages that exist when they claim to exist, proper 404 responses for invalid requests, and search engines that can actually crawl and index your content correctly.
Folder mapping did address immediate operational concerns. Authors no longer needed to create duplicate templates or manually manage thousands of similar pages. A financial website, for instance, could serve thousands of stock pages using one carefully crafted template that fetched real-time data for each requested stock symbol. The efficiency gains were substantial: content authors could deploy changes instantly across their entire dynamic page collection by modifying just one template, ensuring consistent design and reduced maintenance overhead.
As implementations scaled in production environments, we discovered that the map is not the territory. Folder mapping's elegant conceptual model—one template serves all pages—broke down when it encountered the harsh realities of web architecture. The two critical failings emerged: phantom pages being classified as valid content by search engines, and search results displaying generic template titles instead of actual content.
These weren't minor technical inconveniences. They were actively sabotaging the SEO performance folder mapping was meant to support. Every soft 404 misled search engines about content availability. Every generic title reduced click-through rates from search results. The solution was systematically undermining the success of the sites it powered.
Folder mapping is now deprecated due to the fundamental SEO and architectural issues outlined above. The core problem was that folder mapping stitched content together at delivery time—every request triggered dynamic content generation, creating the soft 404 violations and search engine confusion that plagued implementations at scale.
Content overlays offer a better approach. Instead of stitching content at delivery time, content overlays combine content when previewing and publishing. This fundamental shift in timing eliminates the architectural compromises that made folder mapping problematic.
The benefits are substantial. Content overlays provide explicit preview and publish operations, giving authors control over when content becomes available. They leverage the solid content bus infrastructure for scalable delivery, ensuring consistent performance as implementations grow. Most importantly, they deliver reliable SEO results because content is delivered in the markup on the first fetch, with minimal impact on crawl budget.
Content overlays work through the Bring Your Own Markup (BYOM) concept, which allows external services to generate HTML markup directly for the content bus. When a user requests a page, the system delivers a proper 200 response for valid content or a legitimate 404 for non-existent pages. Search engines can crawl and index content correctly because the content actually exists when it claims to exist, with appropriate titles and metadata in place from the start.
Configure your site using the Helix Admin API to set up content overlays
Implement your service (edge worker, App Builder action, or third-party service) that generates HTML markup following AEM Edge Delivery Services semantics
Request Initiation: A request for preview or publish is made via the API for Edge Delivery Services for a specific page
If you're currently using folder mapping, reach out to Adobe to discuss the deprecation timeline and migration path for your specific implementation. For teams facing similar large-scale dynamic content challenges, explore content overlays and BYOM as the architectural foundation for your solution—they deliver the operational efficiency of folder mapping without the SEO compromises.
**Source:** [https://www.aem.live/developer/byom](https://www.aem.live/developer/byom)
Edge Delivery Services is independent of the authoring tooling and supports multiple content sources. This means you could provide your own content source and publish the content from a repository you already have to AEM without having to migrate the content first.
The API that enables it is called Bring Your Own Markup (BYOM). It uses HTML as the standard data format.
The data format for BYOM is HTML - in fact, it is the same semantic HTML structure used by Edge Delivery Services when rendering your website.
For each page that is previewed, your BYOM service must return an HTML response. This means that the HTML must follow the semantics of sections, blocks and default content.
Extra elements such as span tags, data attributes, or styles are removed when content is ingested. Page metadata can be provided via the common meta tags in the HTML head or via a metadata block with the page content.
Image source URLs within the content must be accessible by Edge Delivery Services. The images will be downloaded and ingested during the preview of the page. Image source can be an absolute URL or relative to the page.
Structured data in the form of spreadsheets can be provided via BOYM as well. The data is provided as a JSON. The format of the JSON has to follow the Edge Delivery Services sheet format.
**Source:** [https://www.aem.live/blog/folder-mapping-deprecated](https://www.aem.live/blog/folder-mapping-deprecated)
**Source:** [http://www.aem.live/blog/toms-developer-dilemma](http://www.aem.live/blog/toms-developer-dilemma)
The Martin-Gropius-Bau sticks out in my commute to Adobe's Berlin office: a russet neo-Renaissance masterpiece from 1881. Martin built it after the Paris Commune, when Berlin thought good architecture could prevent revolutions, every frieze an argument for order.
Why AI Gets Stuck on Old CMS Architecture
Yesterday in our internal Slack, Bruce (one of your AI engineers) and I unpacked a question that keeps coming up: why do LLMs struggle with traditional CMS architectures?
Here's the problem: traditional CMS gives developers tremendous flexibility with deep nesting, recursive fragments, and complex component trees. But when you're teaching an AI with limited context windows, that flexibility becomes debilitating.
Traditional systems use primitives like "file" and "folder" with no inherent semantics. Edge Delivery uses native HTML semantics - the same language AIs already understand from billions of web pages.
Then there's transparency. With traditional systems, you're debugging server-generated HTML you can't see behind bundled dependencies. With Edge Delivery, open DevTools and everything's right there - unminified, unobfuscated, fully transparent.
The final killer? Development loop speed. Traditional setups take minutes to see changes. Edge Delivery updates in the blink of an eye. For AI agents that need frequent iteration to bridge the gap between an 80% solution and the 99% you'll actually deploy, this speed isn't just convenient - it's essential.
Tom's been living this problem every day. What started as a simple observation - that developing complex components in Edge Delivery meant jumping between Google Sheets, GitHub, and a local dev server - turned into something bigger.
His framework, documented in The Edge Delivery Services Developer Dilemma and How One Framework Solved It, does three things that made me stop and say "well, that's brilliant":
AI-native architecture - gives your favorite coding assistant full visibility into code, content, and data
Preserves what makes Edge Delivery fast - you still get those 100/100 Lighthouse scores
The architecture that AI dreams of (not the architecture that AI hallucinates of)
Remember what makes Edge Delivery special architecturally? We use HTML semantics natively, keep structures flat and simple, and make everything transparent and open source. Tom's framework doubles down on these principles.
Instead of fighting the platform to get sophisticated components, his dual-directory structure lets you:
For me, Tom's blog isn't just another technical post - it's a blueprint for pushing Edge Delivery further than most people thought possible.
The repository is live at on GitHub, and I can guarantee this: your next Edge Delivery project will be easier because of what Tom figured out here.
**Source:** [http://www.aem.live/blog/organizing-source-code-ensemble](http://www.aem.live/blog/organizing-source-code-ensemble)
Imagine needing to launch four websites rapidly - while maintaining quality, consistency, and performance. One of our customers faced this exact challenge. They implemented AEM Edge Delivery Services (Helix 5), which enabled them to develop all four sites using a single codebase. This resulted in faster, more efficient deployment with reduced complications.
Why AEM Edge Delivery Services (Helix 5)?
One client needed to launch four websites with unique branding but shared core functionality. Using Helix 5, they utilized a single component library instead of building each site from scratch. This provided faster development, theme-based customization, cross-site consistency, and simpler maintenance. While traditional methods would have required months, the shared codebase approach launched all four websites much faster with fewer complications.
With Helix 5, everything is handled through the Admin API, streamlining updates and ensuring consistency across all sites.
Building Components: Keep It Simple
Developing components in Helix 5 is all about reusability and flexibility. Instead of building custom components for every project, you can create a single set of modular pieces that work across different sites.
Best Practices for Component Development
Avoid hardcoded values to maintain scalability and prevent future design limitations.
Organize components consistently with standard Edge Delivery Services structures—no need for overengineering.
Templates are assigned using metadata by simply specifying the template name in the Metadata table, meaning no extra coding is required.
With Helix 5, configurations are managed via the Admin API, eliminating the need for manual file updates.
Sample API Request:
API Response Example:
Each website's theme is assigned in the Metadata table, like this:
A function in scripts.js dynamically loads the corresponding CSS file based on the metadata:
By referencing these variables, components adapt automatically to the active theme:
This approach ensures components remain reusable and adaptable across different sites without requiring individual modifications. Because all components reference these variables, switching themes is effortless!
Saves time by reusing components.
Minimizes redundant code while allowing site-specific customization.
It represents a major leap forward for edge Delivery Services, enabling the use of a single codebase across multiple websites. By centralizing development into a shared component library, Helix 5 eliminates redundancy while supporting multiple themes and configurations. This structured approach significantly enhances efficiency, scalability, and maintainability in modern web development.
**Source:** [http://www.aem.live/docs/sidekick-errors](http://www.aem.live/docs/sidekick-errors)
AEM Sidekick Errors
In case of a problem, AEM Sidekick will display an appropriate error message. The following table contains all possible error messages and their likely root causes.
For more information on backend error codes and error message templates from the Admin API, see Admin Errors.
See a complete list of all messages in GitHub.
**Source:** [http://www.aem.live/developer/admin-errors](http://www.aem.live/developer/admin-errors)
**Source:** [http://www.aem.live/docs/architecture](http://www.aem.live/docs/architecture)
**Source:** [http://www.aem.live/docs/staging](http://www.aem.live/docs/staging)
**Source:** [http://www.aem.live/docs/security](http://www.aem.live/docs/security)
**Source:** [http://www.aem.live/docs/global](http://www.aem.live/docs/global)
**Source:** [http://www.aem.live/docs/china](http://www.aem.live/docs/china)
**Source:** [http://www.aem.live/docs/unsupported](http://www.aem.live/docs/unsupported)
As a composable architecture, AEM embraces integrations with customer’s preferred infrastructure, be it Content Delivery Networks, Content Authoring and Content Repositories, or Web Optimization and Analytics software.
There are a number of integration patterns that have proven to be problematic for security, availability and performance reasons. These patterns are generally discouraged by Adobe. Refer to this document for an outline of integration patterns that are frequently causing issues for AEM customers.
Adobe Experience Manager supports a wide set of Content Delivery Networks (CDNs) and offers deep integrations, including optimized time-to-live (TTL) and surgical invalidation upon content or code update.
For CDNs not included in this list, following common problems can be observed:
Caching relies on fixed TTLs, slowing down the rollout of content updates and code changes
Caching is often misconfigured or disabled, increasing time-to-first-byte (TTFB) and decreasing web performance
To rectify this, we recommend customers to switch to a supported CDN. Every Adobe Experience Manager license includes access to an Adobe-managed, supported CDN and we provide a guide for picking the right supported CDN.
Adobe Experience Manager supports various security configurations and integrations with Web Application Firewalls (WAFs) and security tools. However, certain security practices have proven to be problematic for performance and reliability.
TLS interception introduces multiple challenges that can severely impact your site's performance and security posture. The additional processing required for intercepting and re-encrypting traffic creates noticeable latency, while improper certificate handling can introduce new security vulnerabilities rather than preventing them.
Finally, incomplete rollout of custom Certificate Agency (CA) certificate to developers, causing certificate rejection issues in the AEM CLI.
We recommend implementing end-to-end encryption without intermediate TLS termination points, utilizing modern security features built into supported CDNs.
While WAFs are essential for security, certain implementations can negatively impact site performance.
Web Application Firewalls can introduce performance challenges through synchronous request processing, complex pattern matching rules, inefficient geographic routing, and interference with CDN caching. These factors combine to create unnecessary latency and diminish the performance benefits of your content delivery architecture.
For optimal security and performance, consider using Adobe's built-in WAF security features or implementing WAF solutions through supported CDN providers.
**Source:** [http://www.aem.live/docs/publishing-from-authoring](http://www.aem.live/docs/publishing-from-authoring)
NOTE: Up to a maximum of 5000 paths published from the authoring UI or by workflows are permitted per day. Integrations that create bulk-publication work loads are not supported. If your project requires higher capacity, please propose it for the VIP Program.
A publish event is pushed to the Adobe pipeline queue.
The Edge Delivery Services publish service forwards the relevant events to Edge Delivery Services admin API.
Edge Delivery pulls and ingests semantic HTML from AEM author.
By default, the Edge Delivery Services admin API is not protected and can be used to publish or unpublish documents without authentication. In order to configure authentication for the admin API as documented in Configuring Authentication for Authors, your project must be provisioned with an API_KEY, which grants access to the publish service. Please reach out to the Adobe team on Slack for guidance.
**Source:** [https://www.aem.live/docs/unsupported](https://www.aem.live/docs/unsupported)
**Source:** [https://www.aem.live/previous/sidekick](https://www.aem.live/previous/sidekick)
**Source:** [https://www.aem.live/previous/byo-cdn-cloudflare-worker-setup](https://www.aem.live/previous/byo-cdn-cloudflare-worker-setup)
**Source:** [https://www.aem.live/previous/byo-cdn-akamai-setup](https://www.aem.live/previous/byo-cdn-akamai-setup)
**Source:** [https://www.aem.live/previous/byo-cdn-fastly-setup](https://www.aem.live/previous/byo-cdn-fastly-setup)
**Source:** [https://www.aem.live/previous/byo-cdn-cloudfront-setup](https://www.aem.live/previous/byo-cdn-cloudfront-setup)
**Source:** [https://www.aem.live/docs/%20https://www.aem.live/docs/byo-cdn-setup](https://www.aem.live/docs/%20https://www.aem.live/docs/byo-cdn-setup)
**Source:** [https://www.aem.live/tools/sidekick/library.html?plugin=blocks&path=/block-collection/embed&index=0](https://www.aem.live/tools/sidekick/library.html?plugin=blocks&path=/block-collection/embed&index=0)
**Source:** [https://www.aem.live/developer/block-collection/fragment](https://www.aem.live/developer/block-collection/fragment)
**Source:** [https://www.aem.live/tools/sidekick/library.html?plugin=blocks&path=/block-collection/fragment&index=0](https://www.aem.live/tools/sidekick/library.html?plugin=blocks&path=/block-collection/fragment&index=0)
**Source:** [https://www.aem.live/docs/universal-editor-assets](https://www.aem.live/docs/universal-editor-assets)
When editing content for the Universal Editor, you of course can select assets from AEM Assets. When you publish your content to Edge Delivery Services, the related AEM Assets content is published as well.
To ensure this seamless behavior, AEM and Edge Delivery Services must have proper access to AEM Assets in order to publish. This includes:
When publishing pages from AEM to Edge Delivery Services, a technical account is used. This account, with a name in the format <hash>@techacct.adobe.com, is created automatically as a user in AEM by Cloud Manager whenever you first publish a page created with the Universal Editor.
Generally assuring that your technical account has access to your assets in AEM Assets is sufficient for publishing your assets along with your pages to Edge Delivery Services.
If you wish to publish pages with non-image assets such as PDFs or videos to Edge Delivery Services.
If you wish to publish image assets to Edge Delivery Services independently of pages.
**Source:** [https://www.aem.live/developer/block-collection/video](https://www.aem.live/developer/block-collection/video)
**Source:** [https://www.aem.live/developer/gtm-martech-integration](https://www.aem.live/developer/gtm-martech-integration)
Configuring Google Analytics & Tag Manager Integration
This article will walk you through the steps of setting up an integration with Google Analytics (GA) and Google Tag Manager (GTM) . This will let you automatically track page view and custom events, along with any other tags configured in your GTM containers.
Choosing the Right Integration
This document covers integration with Google's marketing technology stack(Google Analytics 4, Google Tag Manager).
Looking for Adobe Experience Cloud integration instead?See our Adobe Experience Cloud Integration guide.
When to Use This Integration
Integration Comparison
Integration Overview
The Google Analytics & Tag Manager integration provides a streamlined marketing technology stack that enables:
Performance-optimized loading aligned with AEM EDS phases
This integration is designed to work seamlessly with AEM Edge Delivery Services while maintaining optimal performance and user experience.
The integration splits the traditional monolithic GTM approach into optimized phases:
In a traditional GTM implementation, one container is used to initialize tracking and load all other containers. This approach typically has a performance impact on the initial page load, degrading the Core Web Vitals (CWV).
This optimized approach attaches tracking actions to the Edge Delivery Services phases. By splitting up the loading of the libraries and containers, we have minimized the impact on page performance, while maintaining page event tracking.
Performance Benefits
Maintained tracking accuracy while optimizing performance
Test your container in preview mode before deploying
Follow the technical steps in the aem-gtm-martech GitHub repository.
Privacy Considerations: The integration includes built-in consent management support. Default consent is set to require explicit user permission before tracking begins.
Step 3: Deploy Your Code
Commit and push your code branch to trigger the deployment.
Step 4: Test the Integration
GTM Preview Mode
Use GTM's preview mode to debug tag firing
The integration provides comprehensive privacy controls:
Consent callback integration: Works with popular consent management platforms
Check GTM preview mode for trigger debugging
Performance degradation:
GTM Preview Mode: Real-time tag debugging
GA4 DebugView: Real-time event monitoring
Browser DevTools: Network and console monitoring
Alternative Integration Options
Adobe Experience Cloud: Adobe MarTech Integration
GitHub Repository: adobe-rnd/aem-gtm-martech
**Source:** [https://www.aem.live/developer/gtm-martech-integration/demo](https://www.aem.live/developer/gtm-martech-integration/demo)
Custom Metadata on page view
Tagging for section & block loading events
Tagging for sections & blocks entering the viewport
Columns block
Or you can just view the preview
Preview content at 100% fidelity, get predictable content velocity, and shorten project durations
Say goodbye to complex APIs spanning multiple languages. Anyone with a little bit of HTML, CSS, and JS can build a site on AEM.
Peak performance
Use AEM's serverless architecture to meet any traffic need. Use AEM's PageSpeed Insights Github action to evaluate every Pull-Request for Lighthouse Score.
**Source:** [https://www.aem.live/developer/cloudflare-zero-trust](https://www.aem.live/developer/cloudflare-zero-trust)
A previously setup Edge Delivery Services site, for this demo, we’ll use a site called zero-trust-site in the aemsites github org.
If you don’t already have a site to use, create an Edge Delivery Website by following our developer tutorial.
Create a site access token, this token can be used to restrict access to your edge delivery site.
The .page and .live origins will now be protected. Users wanting to access the site directly via these origins will now need to sign into the sidekick.
Open the Cross-Origin Resource Sharing (CORS) settings and enable Bypass options requests to origin to let Edge Delivery handle CORS.
Note: Some of the values below are considered sensitive and must be kept confidential; ensure they are securely stored and never committed to a public repository in GitHub.
Ensure you have the correct account_id set. To find your account_id visit the Websites Dashboard in Cloudflare, select your site and it will be listed on the right hand side of the dashboard under API.
Update the ORIGIN_HOSTNAME to the edge delivery origin host name (for instance main--zero-trust-site--aemsites.aem.live)
**Source:** [https://www.aem.live/docs/byo-cdn-cloudflare-worker-wrangler-setup](https://www.aem.live/docs/byo-cdn-cloudflare-worker-wrangler-setup)
Fork or create a new GitHub repository using this template.Clone the repository and follow the instructions in the README. You can skip directly to step 2.After completing all steps you should be all set.
**Source:** [https://www.aem.live/developer/github-actions](https://www.aem.live/developer/github-actions)
Using GitHub Actions to handle Publication Events
Franklin has a lightweight integration with GitHub actions that allows you to run a GitHub actions workflow whenever a page or sheet in Franklin has been published or unpublished. As GitHub actions is a powerful runtime for all kinds of integrations, you can use it as a springboard to further integrations, for instance using WebHooks, API calls, or even other GitHub workflows.
Franklin can send resource-published and resource-unpublished events to your GitHub repository, where they can trigger a GitHub actions workflow
From there, you can perform further processing, apply conditions, call other APIs or workflow steps
The key starting point is to listen for the repository_dispatch event https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows#repository_dispatch
